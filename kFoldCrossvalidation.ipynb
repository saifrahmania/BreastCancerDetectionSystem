{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "os.environ[\"TERM\"] = \"xterm\"\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization,Conv1D,GRU,BatchNormalization, ReLU\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from array import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers  import Adam #only keras.optimizers use korle error dey\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "      \n",
    "%matplotlib inline\n",
    "from numpy import mean\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dropout, Flatten, Activation, Dense\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df['diagnosis']= label_encoder.fit_transform(df['diagnosis'].map({'M':1,'B':0})) \n",
    "df['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=df['diagnosis']\n",
    "inputs = df.drop(columns=['diagnosis','id','Unnamed: 32'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "inputs=scaler.fit_transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of samples in each class\n",
    "class_counts = df['diagnosis'].value_counts()\n",
    "\n",
    "# Print the class counts\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(targets.shape)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.09706398],\n",
       "        [-2.07333501],\n",
       "        [ 1.26993369],\n",
       "        ...,\n",
       "        [ 2.29607613],\n",
       "        [ 2.75062224],\n",
       "        [ 1.93701461]],\n",
       "\n",
       "       [[ 1.82982061],\n",
       "        [-0.35363241],\n",
       "        [ 1.68595471],\n",
       "        ...,\n",
       "        [ 1.0870843 ],\n",
       "        [-0.24388967],\n",
       "        [ 0.28118999]],\n",
       "\n",
       "       [[ 1.57988811],\n",
       "        [ 0.45618695],\n",
       "        [ 1.56650313],\n",
       "        ...,\n",
       "        [ 1.95500035],\n",
       "        [ 1.152255  ],\n",
       "        [ 0.20139121]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.70228425],\n",
       "        [ 2.0455738 ],\n",
       "        [ 0.67267578],\n",
       "        ...,\n",
       "        [ 0.41406869],\n",
       "        [-1.10454895],\n",
       "        [-0.31840916]],\n",
       "\n",
       "       [[ 1.83834103],\n",
       "        [ 2.33645719],\n",
       "        [ 1.98252415],\n",
       "        ...,\n",
       "        [ 2.28998549],\n",
       "        [ 1.91908301],\n",
       "        [ 2.21963528]],\n",
       "\n",
       "       [[-1.80840125],\n",
       "        [ 1.22179204],\n",
       "        [-1.81438851],\n",
       "        ...,\n",
       "        [-1.74506282],\n",
       "        [-0.04813821],\n",
       "        [-0.75120669]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.reshape(569,30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy1 = []\n",
    "knn_precision1 = []\n",
    "knn_recall1 = []\n",
    "knn_f11 = []\n",
    "svc_accuracy1 = []\n",
    "svc_precision1 = []\n",
    "svc_recall1 = []\n",
    "svc_f11 = []\n",
    "rf_accuracy1 = []\n",
    "rf_precision1 = []\n",
    "rf_recall1 = []\n",
    "rf_f11 = []\n",
    "ridge_accuracy1 = []\n",
    "ridge_precision1 = []\n",
    "ridge_recall1 = []\n",
    "ridge_f11 = []\n",
    "gbc_accuracy1 = []\n",
    "gbc_precision1 = []\n",
    "gbc_recall1 = []\n",
    "gbc_f11 = []\n",
    "xgb_accuracy1 = []\n",
    "xgb_precision1 = []\n",
    "xgb_recall1 = []\n",
    "xgb_f11 = []\n",
    "lr_accuracy1 = []\n",
    "lr_precision1 = []\n",
    "lr_recall1 = []\n",
    "lr_f11 = []\n",
    "dt_accuracy1 = []\n",
    "dt_precision1 = []\n",
    "dt_recall1 = []\n",
    "dt_f11 = []\n",
    "lda_accuracy1 = []\n",
    "lda_precision1 = []\n",
    "lda_recall1 = []\n",
    "lda_f11 = []\n",
    "qda_accuracy1 = []\n",
    "qda_precision1 = []\n",
    "qda_recall1 = []\n",
    "qda_f11 = []\n",
    "nb_accuracy1 = []\n",
    "nb_precision1 = []\n",
    "nb_recall1 = []\n",
    "nb_f11 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold No:   1\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   2\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   3\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   4\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   5\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   6\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   7\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   8\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   9\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   10\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "num_folds=10\n",
    "epochs = 60\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "num_folds=10\n",
    "epochs = 60\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    print(\"Fold No:  \",fold_no)\n",
    "    \n",
    "    print(\"KNN\")\n",
    "\n",
    "    knn_steps = [('scaler', StandardScaler()),\n",
    "         ('knn', BaggingClassifier(KNeighborsClassifier()))]\n",
    "    knn_pipeline = Pipeline(knn_steps)\n",
    "\n",
    "    knn_parameters = dict(knn__base_estimator__metric = ['euclidean', 'manhattan', 'minkowski'],\n",
    "                    knn__base_estimator__weights =  ['uniform', 'distance'],\n",
    "                    knn__base_estimator__n_neighbors = range(2,15),\n",
    "                    knn__bootstrap = [True, False],\n",
    "                    knn__bootstrap_features = [True, False],\n",
    "                    knn__n_estimators = [5])\n",
    "\n",
    "\n",
    "    knn_cv = GridSearchCV(knn_pipeline,\n",
    "                    param_grid = knn_parameters,\n",
    "                    cv = epochs,\n",
    "                    scoring = 'accuracy',\n",
    "                    n_jobs = -1,\n",
    "                    )\n",
    "\n",
    "    knn_cv.fit(inputs[train], targets[train])\n",
    "    knn_targets_pred = knn_cv.predict(inputs[test])\n",
    "    knn_accuracy=accuracy_score(targets[test],knn_targets_pred)\n",
    "    knn_precision = precision_score(targets[test],knn_targets_pred)\n",
    "    knn_recall = recall_score(targets[test],knn_targets_pred)\n",
    "    knn_f1=f1_score(targets[test],knn_targets_pred)\n",
    "    knn_accuracy1.append(knn_accuracy)\n",
    "    knn_precision1.append(knn_precision)\n",
    "    knn_recall1.append(knn_recall)\n",
    "    knn_f11.append(knn_f1)\n",
    "\n",
    "    print(\"SVC\")\n",
    "\n",
    "    svc_steps = [('scaler', StandardScaler()),\n",
    "         ('svc', SVC())]\n",
    "    svc_pipeline = Pipeline(svc_steps)\n",
    "\n",
    "    svc_parameters = dict(svc__kernel = ['poly', 'rbf', 'sigmoid'],\n",
    "                      svc__gamma =  [0.0001, 0.001, 0.01, 0.1],\n",
    "                      svc__C = [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20])\n",
    "\n",
    "\n",
    "    svc_cv = GridSearchCV(svc_pipeline,\n",
    "                      param_grid = svc_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1)\n",
    "\n",
    "    svc_cv.fit(inputs[train], targets[train])\n",
    "    svc_targets_pred = svc_cv.predict(inputs[test])\n",
    "    svc_accuracy=accuracy_score(targets[test],svc_targets_pred)\n",
    "    svc_precision = precision_score(targets[test],svc_targets_pred)\n",
    "    svc_recall = recall_score(targets[test],svc_targets_pred)\n",
    "    svc_f1=f1_score(targets[test],svc_targets_pred)\n",
    "    svc_accuracy1.append(svc_accuracy)\n",
    "    svc_precision1.append(svc_precision)\n",
    "    svc_recall1.append(svc_recall)\n",
    "    svc_f11.append(svc_f1)\n",
    "\n",
    "    print(\"Random Forest\")\n",
    "    \n",
    "\n",
    "    rf_steps = [('scaler', StandardScaler()),\n",
    "         ('rf', RandomForestClassifier(random_state = 0))]\n",
    "    rf_pipeline = Pipeline(rf_steps)\n",
    "\n",
    "    rf_parameters = dict(rf__n_estimators = [10,100],\n",
    "                      rf__max_features = ['sqrt', 'log2'],\n",
    "    )\n",
    "\n",
    "\n",
    "    rf_cv = GridSearchCV(rf_pipeline,\n",
    "                      param_grid = rf_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1)\n",
    "\n",
    "    rf_cv.fit(inputs[train], targets[train])\n",
    "    rf_targets_pred = rf_cv.predict(inputs[test])\n",
    "    rf_accuracy=accuracy_score(targets[test],rf_targets_pred)\n",
    "    rf_precision = precision_score(targets[test],rf_targets_pred)\n",
    "    rf_recall = recall_score(targets[test],rf_targets_pred)\n",
    "    rf_f1=f1_score(targets[test],rf_targets_pred)\n",
    "    rf_accuracy1.append(rf_accuracy)\n",
    "    rf_precision1.append(rf_precision)\n",
    "    rf_recall1.append(rf_recall)\n",
    "    rf_f11.append(rf_f1)\n",
    "\n",
    "    ##Start from here \n",
    "\n",
    "    print(\"Ridge Classifier\")\n",
    "\n",
    "    ridge_steps = [('scaler', StandardScaler()),\n",
    "         ('ridge', RidgeClassifier())]\n",
    "    ridge_pipeline = Pipeline(ridge_steps)\n",
    "\n",
    "    ridge_parameters = dict(ridge__alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "\n",
    "    ridge_cv = GridSearchCV(ridge_pipeline,\n",
    "                      param_grid = ridge_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0)\n",
    "\n",
    "    ridge_cv.fit(inputs[train], targets[train])\n",
    "    ridge_targets_pred = ridge_cv.predict(inputs[test])\n",
    "    ridge_accuracy=accuracy_score(targets[test],ridge_targets_pred)\n",
    "    ridge_precision = precision_score(targets[test],ridge_targets_pred)\n",
    "    ridge_recall = recall_score(targets[test],ridge_targets_pred)\n",
    "    ridge_f1=f1_score(targets[test],ridge_targets_pred)\n",
    "    ridge_accuracy1.append(ridge_accuracy)\n",
    "    ridge_precision1.append(ridge_precision)\n",
    "    ridge_recall1.append(ridge_recall)\n",
    "    ridge_f11.append(ridge_f1)\n",
    "\n",
    "    print(\"Gradient Boosting\")\n",
    "\n",
    "    gbc_steps = [('scaler', StandardScaler()),\n",
    "         ('gbc', GradientBoostingClassifier())]\n",
    "    gbc_pipeline = Pipeline(gbc_steps)\n",
    "\n",
    "    gbc_parameters = dict(gbc__n_estimators = [10,100,200],\n",
    "                      gbc__loss = ['deviance', 'exponential'],\n",
    "                      gbc__learning_rate = [0.001, 0.1, 1, 10]\n",
    "    )\n",
    "\n",
    "\n",
    "    gbc_cv = GridSearchCV(gbc_pipeline,\n",
    "                      param_grid = gbc_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0\n",
    "                      )\n",
    "\n",
    "    gbc_cv.fit(inputs[train], targets[train])\n",
    "    gbc_targets_pred = gbc_cv.predict(inputs[test])\n",
    "    gbc_accuracy=accuracy_score(targets[test],gbc_targets_pred)\n",
    "    gbc_precision = precision_score(targets[test],gbc_targets_pred)\n",
    "    gbc_recall = recall_score(targets[test],gbc_targets_pred)\n",
    "    gbc_f1=f1_score(targets[test],gbc_targets_pred)\n",
    "    gbc_accuracy1.append(gbc_accuracy)\n",
    "    gbc_precision1.append(gbc_precision)\n",
    "    gbc_recall1.append(gbc_recall)\n",
    "    gbc_f11.append(gbc_f1)\n",
    "\n",
    "    print(\"XGBoost\")\n",
    "\n",
    "    xgb = XGBClassifier(max_depth = 5,\n",
    "                        min_child_weight = 1,\n",
    "                        gamma = 0.3,\n",
    "                        subsample = 0.8,\n",
    "                        colsample_bytree = 0.8,\n",
    "                        learning_rate = 0.1,\n",
    "                        reg_alpha=0.05,\n",
    "                        disable_default_eval_metric = True)\n",
    "\n",
    "    xgb.fit(inputs[train], targets[train])\n",
    "    xgb_targets_pred = xgb.predict(inputs[test])\n",
    "\n",
    "    xgb_accuracy=accuracy_score(targets[test],xgb_targets_pred)\n",
    "    xgb_precision = precision_score(targets[test],xgb_targets_pred)\n",
    "    xgb_recall = recall_score(targets[test],xgb_targets_pred)\n",
    "    xgb_f1=f1_score(targets[test],xgb_targets_pred)\n",
    "    xgb_accuracy1.append(xgb_accuracy)\n",
    "    xgb_precision1.append(xgb_precision)\n",
    "    xgb_recall1.append(xgb_recall)\n",
    "    xgb_f11.append(xgb_f1)\n",
    "\n",
    "    print(\"Logistic Regression\")\n",
    "\n",
    "    lr_steps = [('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression())]\n",
    "\n",
    "    lr_pipeline = Pipeline(lr_steps)\n",
    "\n",
    "    lr_parameters = dict(lr__C = np.logspace(-3,3,7),                  \n",
    "                      lr__penalty = [\"l1\",\"l2\"])\n",
    "    lr_cv = GridSearchCV(lr_pipeline,\n",
    "                      param_grid = lr_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0\n",
    "                      )\n",
    "    lr_cv.fit(inputs[train], targets[train])\n",
    "    lr_targets_pred = lr_cv.predict(inputs[test])\n",
    "\n",
    "    lr_accuracy=accuracy_score(targets[test],lr_targets_pred)\n",
    "    lr_precision = precision_score(targets[test],lr_targets_pred)\n",
    "    lr_recall = recall_score(targets[test],lr_targets_pred)\n",
    "    lr_f1=f1_score(targets[test],lr_targets_pred)\n",
    "    lr_accuracy1.append(lr_accuracy)\n",
    "    lr_precision1.append(lr_precision)\n",
    "    lr_recall1.append(lr_recall)\n",
    "    lr_f11.append(lr_f1)\n",
    "\n",
    "    print(\"Decision Tree\")\n",
    "\n",
    "    dt = DecisionTreeClassifier()\n",
    "\n",
    "    dt.fit(inputs[train], targets[train],sample_weight=None)\n",
    "    dt_targets_pred = dt.predict(inputs[test])\n",
    "\n",
    "    dt_accuracy=accuracy_score(targets[test],dt_targets_pred)\n",
    "    dt_precision = precision_score(targets[test],dt_targets_pred)\n",
    "    dt_recall = recall_score(targets[test],dt_targets_pred)\n",
    "    dt_f1=f1_score(targets[test],dt_targets_pred)\n",
    "    dt_accuracy1.append(dt_accuracy)\n",
    "    dt_precision1.append(dt_precision)\n",
    "    dt_recall1.append(dt_recall)\n",
    "    dt_f11.append(dt_f1)\n",
    "\n",
    "    print(\"Linear Discremental Analysis\")\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    lda.fit(inputs[train], targets[train])\n",
    "    lda_targets_pred = lda.predict(inputs[test])\n",
    "\n",
    "    lda_accuracy=accuracy_score(targets[test],lda_targets_pred)\n",
    "    lda_precision = precision_score(targets[test],lda_targets_pred)\n",
    "    lda_recall = recall_score(targets[test],lda_targets_pred)\n",
    "    lda_f1=f1_score(targets[test],lda_targets_pred)\n",
    "    lda_accuracy1.append(lda_accuracy)\n",
    "    lda_precision1.append(lda_precision)\n",
    "    lda_recall1.append(lda_recall)\n",
    "    lda_f11.append(lda_f1)\n",
    "\n",
    "    print(\"Quadratic Discremental Analysis\")\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "    qda.fit(inputs[train], targets[train])\n",
    "    qda_targets_pred = qda.predict(inputs[test])\n",
    "\n",
    "    qda_accuracy=accuracy_score(targets[test],qda_targets_pred)\n",
    "    qda_precision = precision_score(targets[test],qda_targets_pred)\n",
    "    qda_recall = recall_score(targets[test],qda_targets_pred)\n",
    "    qda_f1=f1_score(targets[test],qda_targets_pred)\n",
    "    qda_accuracy1.append(qda_accuracy)\n",
    "    qda_precision1.append(qda_precision)\n",
    "    qda_recall1.append(qda_recall)\n",
    "    qda_f11.append(qda_f1)\n",
    "\n",
    "    print(\"Naive Bayes\")\n",
    "\n",
    "    nb= GaussianNB()\n",
    "\n",
    "    nb.fit(inputs[train], targets[train])\n",
    "    nb_targets_pred = nb.predict(inputs[test])\n",
    "\n",
    "    nb_accuracy=accuracy_score(targets[test],nb_targets_pred)\n",
    "    nb_precision = precision_score(targets[test],nb_targets_pred)\n",
    "    nb_recall = recall_score(targets[test],nb_targets_pred)\n",
    "    nb_f1=f1_score(targets[test],nb_targets_pred)\n",
    "    nb_accuracy1.append(nb_accuracy)\n",
    "    nb_precision1.append(nb_precision)\n",
    "    nb_recall1.append(nb_recall)\n",
    "    nb_f11.append(nb_f1)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgKnnAccuracy = mean(knn_accuracy1)\n",
    "avgKnnPrecision = mean(knn_precision1)\n",
    "avgKnnRecall = mean(knn_recall1)\n",
    "avgKnnF1 = mean(knn_f11)\n",
    "avgSvcAccuracy = mean(svc_accuracy1)\n",
    "avgSvcPrecision = mean(svc_precision1)\n",
    "avgSvcRecall = mean(svc_recall1)\n",
    "avgSvcF1 = mean(svc_f11)\n",
    "avgRfAccuracy = mean(rf_accuracy1)\n",
    "avgRfPrecision = mean(rf_precision1)\n",
    "avgRfRecall = mean(rf_recall1)\n",
    "avgRfF1 = mean(rf_f11)\n",
    "avgRidgeAccuracy = mean(ridge_accuracy1)\n",
    "avgRidgePrecision = mean(ridge_precision1)\n",
    "avgRidgeRecall = mean(ridge_recall1)\n",
    "avgRidgeF1 = mean(ridge_f11)\n",
    "avgGbcAccuracy = mean(gbc_accuracy1)\n",
    "avgGbcPrecision = mean(gbc_precision1)\n",
    "avgGbcRecall = mean(gbc_recall1)\n",
    "avgGbcF1 = mean(gbc_f11)\n",
    "avgXgbAccuracy = mean(xgb_accuracy1)\n",
    "avgXgbPrecision = mean(xgb_precision1)\n",
    "avgXgbRecall = mean(xgb_recall1)\n",
    "avgXgbF1 = mean(xgb_f11)\n",
    "avgLrAccuracy = mean(lr_accuracy1)\n",
    "avgLrPrecision = mean(lr_precision1)\n",
    "avgLrRecall = mean(lr_recall1)\n",
    "avgLrF1 = mean(lr_f11)\n",
    "avgDtAccuracy = mean(dt_accuracy1)\n",
    "avgDtPrecision = mean(dt_precision1)\n",
    "avgDtRecall = mean(dt_recall1)\n",
    "avgDtF1 = mean(dt_f11)\n",
    "avgLdaAccuracy = mean(lda_accuracy1)\n",
    "avgLdaPrecision = mean(lda_precision1)\n",
    "avgLdaRecall = mean(lda_recall1)\n",
    "avgLdaF1 = mean(lda_f11)\n",
    "avgQdaAccuracy = mean(qda_accuracy1)\n",
    "avgQdaPrecision = mean(qda_precision1)\n",
    "avgQdaRecall = mean(qda_recall1)\n",
    "avgQdaF1 = mean(qda_f11)\n",
    "avgNbAccuracy = mean(nb_accuracy1)\n",
    "avgNbPrecision = mean(nb_precision1)\n",
    "avgNbRecall = mean(nb_recall1)\n",
    "avgNbF1 = mean(nb_f11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.975439</td>\n",
       "      <td>0.975811</td>\n",
       "      <td>0.957600</td>\n",
       "      <td>0.966320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.971898</td>\n",
       "      <td>0.973881</td>\n",
       "      <td>0.944353</td>\n",
       "      <td>0.958571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.966541</td>\n",
       "      <td>0.962765</td>\n",
       "      <td>0.944181</td>\n",
       "      <td>0.952529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.964818</td>\n",
       "      <td>0.983534</td>\n",
       "      <td>0.919356</td>\n",
       "      <td>0.948863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.964818</td>\n",
       "      <td>0.966789</td>\n",
       "      <td>0.936997</td>\n",
       "      <td>0.951189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.961278</td>\n",
       "      <td>0.962424</td>\n",
       "      <td>0.932649</td>\n",
       "      <td>0.946862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.957863</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.895649</td>\n",
       "      <td>0.940198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liner Discriminant Analysis</td>\n",
       "      <td>0.956109</td>\n",
       "      <td>0.990238</td>\n",
       "      <td>0.891865</td>\n",
       "      <td>0.937899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quadratic Discremenant Analysis</td>\n",
       "      <td>0.952538</td>\n",
       "      <td>0.936580</td>\n",
       "      <td>0.934328</td>\n",
       "      <td>0.933787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.927976</td>\n",
       "      <td>0.899446</td>\n",
       "      <td>0.907644</td>\n",
       "      <td>0.902442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Baies</td>\n",
       "      <td>0.927820</td>\n",
       "      <td>0.905975</td>\n",
       "      <td>0.889567</td>\n",
       "      <td>0.896683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Accuracy  Precision    Recall  F1_score\n",
       "6               Logistic Regression  0.975439   0.975811  0.957600  0.966320\n",
       "1         Support Vector Classifier  0.971898   0.973881  0.944353  0.958571\n",
       "5                           XGBoost  0.966541   0.962765  0.944181  0.952529\n",
       "0                               KNN  0.964818   0.983534  0.919356  0.948863\n",
       "4      Gradient Boosting Classifier  0.964818   0.966789  0.936997  0.951189\n",
       "2                     Random Forest  0.961278   0.962424  0.932649  0.946862\n",
       "3                  Ridge Classifier  0.957863   0.990476  0.895649  0.940198\n",
       "8       Liner Discriminant Analysis  0.956109   0.990238  0.891865  0.937899\n",
       "9   Quadratic Discremenant Analysis  0.952538   0.936580  0.934328  0.933787\n",
       "7                     Decision Tree  0.927976   0.899446  0.907644  0.902442\n",
       "10                      Naive Baies  0.927820   0.905975  0.889567  0.896683"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ensembling = pd.DataFrame({\n",
    "    'Model'       : ['KNN','Support Vector Classifier','Random Forest','Ridge Classifier','Gradient Boosting Classifier','XGBoost','Logistic Regression','Decision Tree','Liner Discriminant Analysis','Quadratic Discremenant Analysis', 'Naive Baies'],\n",
    "    'Accuracy'    : [avgKnnAccuracy,avgSvcAccuracy,avgRfAccuracy,avgRidgeAccuracy,avgGbcAccuracy,avgXgbAccuracy,avgLrAccuracy,avgDtAccuracy,avgLdaAccuracy,avgQdaAccuracy,avgNbAccuracy],\n",
    "    'Precision'   : [avgKnnPrecision,avgSvcPrecision,avgRfPrecision,avgRidgePrecision,avgGbcPrecision,avgXgbPrecision,avgLrPrecision,avgDtPrecision,avgLdaPrecision,avgQdaPrecision,avgNbPrecision],\n",
    "    'Recall'      : [avgKnnRecall,avgSvcRecall,avgRfRecall,avgRidgeRecall,avgGbcRecall,avgXgbRecall,avgLrRecall,avgDtRecall,avgLdaRecall,avgQdaRecall,avgNbRecall],\n",
    "    'F1_score'    : [avgKnnF1,avgSvcF1,avgRfF1,avgRidgeF1,avgGbcF1,avgXgbF1,avgLrF1,avgDtF1,avgLdaF1,avgQdaF1,avgNbF1],\n",
    "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "models_ensembling.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
