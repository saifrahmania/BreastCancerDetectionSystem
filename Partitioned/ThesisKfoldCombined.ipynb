{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization,Conv1D,GRU,BatchNormalization, ReLU\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from array import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers  import Adam #only keras.optimizers use korle error dey\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "      \n",
    "%matplotlib inline\n",
    "from numpy import mean\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dropout, Flatten, Activation, Dense\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    " \n",
    "# Encode labels in column 'species'.\n",
    "df['diagnosis']= label_encoder.fit_transform(df['diagnosis'].map({'M':1,'B':0})) \n",
    "df['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=df['diagnosis']\n",
    "inputs = df.drop(columns=['diagnosis','id','Unnamed: 32'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "inputs=scaler.fit_transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(targets.shape)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.09706398],\n",
       "        [-2.07333501],\n",
       "        [ 1.26993369],\n",
       "        ...,\n",
       "        [ 2.29607613],\n",
       "        [ 2.75062224],\n",
       "        [ 1.93701461]],\n",
       "\n",
       "       [[ 1.82982061],\n",
       "        [-0.35363241],\n",
       "        [ 1.68595471],\n",
       "        ...,\n",
       "        [ 1.0870843 ],\n",
       "        [-0.24388967],\n",
       "        [ 0.28118999]],\n",
       "\n",
       "       [[ 1.57988811],\n",
       "        [ 0.45618695],\n",
       "        [ 1.56650313],\n",
       "        ...,\n",
       "        [ 1.95500035],\n",
       "        [ 1.152255  ],\n",
       "        [ 0.20139121]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.70228425],\n",
       "        [ 2.0455738 ],\n",
       "        [ 0.67267578],\n",
       "        ...,\n",
       "        [ 0.41406869],\n",
       "        [-1.10454895],\n",
       "        [-0.31840916]],\n",
       "\n",
       "       [[ 1.83834103],\n",
       "        [ 2.33645719],\n",
       "        [ 1.98252415],\n",
       "        ...,\n",
       "        [ 2.28998549],\n",
       "        [ 1.91908301],\n",
       "        [ 2.21963528]],\n",
       "\n",
       "       [[-1.80840125],\n",
       "        [ 1.22179204],\n",
       "        [-1.81438851],\n",
       "        ...,\n",
       "        [-1.74506282],\n",
       "        [-0.04813821],\n",
       "        [-0.75120669]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.reshape(569,30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_accuracy1=[]\n",
    "cnn_precision1=[]\n",
    "cnn_recall1=[]\n",
    "cnn_f11=[]\n",
    "rnn_accuracy1=[]\n",
    "rnn_precision1=[]\n",
    "rnn_recall1=[]\n",
    "rnn_f11=[]\n",
    "lstm_accuracy1=[]\n",
    "lstm_precision1=[]\n",
    "lstm_recall1=[]\n",
    "lstm_f11=[]\n",
    "gru_accuracy1=[]\n",
    "gru_precision1=[]\n",
    "gru_recall1=[]\n",
    "gru_f11=[]\n",
    "knn_accuracy1 = []\n",
    "knn_precision1 = []\n",
    "knn_recall1 = []\n",
    "knn_f11 = []\n",
    "svc_accuracy1 = []\n",
    "svc_precision1 = []\n",
    "svc_recall1 = []\n",
    "svc_f11 = []\n",
    "rf_accuracy1 = []\n",
    "rf_precision1 = []\n",
    "rf_recall1 = []\n",
    "rf_f11 = []\n",
    "ridge_accuracy1 = []\n",
    "ridge_precision1 = []\n",
    "ridge_recall1 = []\n",
    "ridge_f11 = []\n",
    "gbc_accuracy1 = []\n",
    "gbc_precision1 = []\n",
    "gbc_recall1 = []\n",
    "gbc_f11 = []\n",
    "xgb_accuracy1 = []\n",
    "xgb_precision1 = []\n",
    "xgb_recall1 = []\n",
    "xgb_f11 = []\n",
    "lr_accuracy1 = []\n",
    "lr_precision1 = []\n",
    "lr_recall1 = []\n",
    "lr_f11 = []\n",
    "dt_accuracy1 = []\n",
    "dt_precision1 = []\n",
    "dt_recall1 = []\n",
    "dt_f11 = []\n",
    "lda_accuracy1 = []\n",
    "lda_precision1 = []\n",
    "lda_recall1 = []\n",
    "lda_f11 = []\n",
    "qda_accuracy1 = []\n",
    "qda_precision1 = []\n",
    "qda_recall1 = []\n",
    "qda_f11 = []\n",
    "nb_accuracy1 = []\n",
    "nb_precision1 = []\n",
    "nb_recall1 = []\n",
    "nb_f11 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold No:   1\n",
      "CNN\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 3s 34ms/step - loss: 0.7776 - accuracy: 0.6367 - val_loss: 0.6358 - val_accuracy: 0.8555\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.5102 - accuracy: 0.7773 - val_loss: 0.5777 - val_accuracy: 0.8809\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3415 - accuracy: 0.8301 - val_loss: 0.5256 - val_accuracy: 0.8789\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2731 - accuracy: 0.8828 - val_loss: 0.4820 - val_accuracy: 0.8750\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2693 - accuracy: 0.8926 - val_loss: 0.4421 - val_accuracy: 0.8809\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2129 - accuracy: 0.9023 - val_loss: 0.4059 - val_accuracy: 0.8848\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2823 - accuracy: 0.9023 - val_loss: 0.3731 - val_accuracy: 0.8945\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2126 - accuracy: 0.9062 - val_loss: 0.3420 - val_accuracy: 0.9102\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1927 - accuracy: 0.9297 - val_loss: 0.3095 - val_accuracy: 0.9219\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1519 - accuracy: 0.9473 - val_loss: 0.2794 - val_accuracy: 0.9297\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1852 - accuracy: 0.9238 - val_loss: 0.2520 - val_accuracy: 0.9395\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1302 - accuracy: 0.9492 - val_loss: 0.2267 - val_accuracy: 0.9434\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1546 - accuracy: 0.9414 - val_loss: 0.2045 - val_accuracy: 0.9473\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1186 - accuracy: 0.9551 - val_loss: 0.1833 - val_accuracy: 0.9551\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1401 - accuracy: 0.9453 - val_loss: 0.1640 - val_accuracy: 0.9590\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1479 - accuracy: 0.9336 - val_loss: 0.1474 - val_accuracy: 0.9668\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1312 - accuracy: 0.9570 - val_loss: 0.1338 - val_accuracy: 0.9727\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1010 - accuracy: 0.9668 - val_loss: 0.1208 - val_accuracy: 0.9766\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0986 - accuracy: 0.9590 - val_loss: 0.1108 - val_accuracy: 0.9766\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1193 - accuracy: 0.9473 - val_loss: 0.1006 - val_accuracy: 0.9785\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1217 - accuracy: 0.9492 - val_loss: 0.0925 - val_accuracy: 0.9844\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1154 - accuracy: 0.9531 - val_loss: 0.0855 - val_accuracy: 0.9844\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1268 - accuracy: 0.9414 - val_loss: 0.0796 - val_accuracy: 0.9863\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0857 - accuracy: 0.9688 - val_loss: 0.0741 - val_accuracy: 0.9863\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1120 - accuracy: 0.9609 - val_loss: 0.0695 - val_accuracy: 0.9863\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0831 - accuracy: 0.9766 - val_loss: 0.0655 - val_accuracy: 0.9883\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0880 - accuracy: 0.9668 - val_loss: 0.0618 - val_accuracy: 0.9883\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0888 - accuracy: 0.9648 - val_loss: 0.0584 - val_accuracy: 0.9883\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0879 - accuracy: 0.9746 - val_loss: 0.0557 - val_accuracy: 0.9883\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0973 - accuracy: 0.9551 - val_loss: 0.0532 - val_accuracy: 0.9883\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0894 - accuracy: 0.9609 - val_loss: 0.0506 - val_accuracy: 0.9883\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0944 - accuracy: 0.9609 - val_loss: 0.0486 - val_accuracy: 0.9883\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1067 - accuracy: 0.9590 - val_loss: 0.0470 - val_accuracy: 0.9883\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1177 - accuracy: 0.9609 - val_loss: 0.0453 - val_accuracy: 0.9883\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1002 - accuracy: 0.9590 - val_loss: 0.0437 - val_accuracy: 0.9883\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0796 - accuracy: 0.9707 - val_loss: 0.0424 - val_accuracy: 0.9883\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0920 - accuracy: 0.9648 - val_loss: 0.0414 - val_accuracy: 0.9883\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0867 - accuracy: 0.9688 - val_loss: 0.0402 - val_accuracy: 0.9883\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0685 - accuracy: 0.9746 - val_loss: 0.0392 - val_accuracy: 0.9902\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1002 - accuracy: 0.9609 - val_loss: 0.0383 - val_accuracy: 0.9883\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0785 - accuracy: 0.9688 - val_loss: 0.0377 - val_accuracy: 0.9902\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0799 - accuracy: 0.9727 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0738 - accuracy: 0.9668 - val_loss: 0.0362 - val_accuracy: 0.9902\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0905 - accuracy: 0.9746 - val_loss: 0.0353 - val_accuracy: 0.9902\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0755 - accuracy: 0.9707 - val_loss: 0.0345 - val_accuracy: 0.9902\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0812 - accuracy: 0.9727 - val_loss: 0.0338 - val_accuracy: 0.9902\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0825 - accuracy: 0.9609 - val_loss: 0.0331 - val_accuracy: 0.9902\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9688 - val_loss: 0.0325 - val_accuracy: 0.9883\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0829 - accuracy: 0.9648 - val_loss: 0.0320 - val_accuracy: 0.9902\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0579 - accuracy: 0.9766 - val_loss: 0.0314 - val_accuracy: 0.9902\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0538 - accuracy: 0.9824 - val_loss: 0.0308 - val_accuracy: 0.9922\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0589 - accuracy: 0.9785 - val_loss: 0.0304 - val_accuracy: 0.9902\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0647 - accuracy: 0.9785 - val_loss: 0.0298 - val_accuracy: 0.9902\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0657 - accuracy: 0.9766 - val_loss: 0.0292 - val_accuracy: 0.9902\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0516 - accuracy: 0.9863 - val_loss: 0.0289 - val_accuracy: 0.9902\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0580 - accuracy: 0.9785 - val_loss: 0.0286 - val_accuracy: 0.9902\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0660 - accuracy: 0.9746 - val_loss: 0.0280 - val_accuracy: 0.9883\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0553 - accuracy: 0.9785 - val_loss: 0.0275 - val_accuracy: 0.9902\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0638 - accuracy: 0.9746 - val_loss: 0.0269 - val_accuracy: 0.9902\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0649 - accuracy: 0.9805 - val_loss: 0.0264 - val_accuracy: 0.9902\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "RNN\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_2_input'), name='dense_2_input', description=\"created by layer 'dense_2_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_2_input'), name='dense_2_input', description=\"created by layer 'dense_2_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      " 87/103 [========================>.....] - ETA: 0s - loss: 0.2631 - accuracy: 0.8897WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_2_input'), name='dense_2_input', description=\"created by layer 'dense_2_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "103/103 [==============================] - 2s 8ms/step - loss: 0.2411 - accuracy: 0.8984 - val_loss: 0.0843 - val_accuracy: 0.9844\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0765 - accuracy: 0.9824 - val_loss: 0.0579 - val_accuracy: 0.9902\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 0.9863 - val_loss: 0.0444 - val_accuracy: 0.9922\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9902 - val_loss: 0.0354 - val_accuracy: 0.9902\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9922 - val_loss: 0.0366 - val_accuracy: 0.9922\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0413 - accuracy: 0.9902 - val_loss: 0.0263 - val_accuracy: 0.9902\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0338 - accuracy: 0.9863 - val_loss: 0.0333 - val_accuracy: 0.9863\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.0200 - val_accuracy: 0.9922\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.0151 - val_accuracy: 0.9980\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0157 - accuracy: 0.9941 - val_loss: 0.0097 - val_accuracy: 0.9961\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0181 - accuracy: 0.9922 - val_loss: 0.0264 - val_accuracy: 0.9922\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0112 - val_accuracy: 0.9961\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0074 - val_accuracy: 0.9961\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9961\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0195 - accuracy: 0.9902 - val_loss: 0.0103 - val_accuracy: 0.9941\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0254 - accuracy: 0.9941 - val_loss: 0.0267 - val_accuracy: 0.9883\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9902 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.9961 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 8.4518e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.5181e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.5032e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.1446e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 6.6574e-04 - accuracy: 1.0000 - val_loss: 5.1313e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.3935e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 8.6140e-04 - accuracy: 1.0000 - val_loss: 5.4572e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 8.4128e-04 - accuracy: 1.0000 - val_loss: 3.3819e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 4.5544e-04 - accuracy: 1.0000 - val_loss: 3.0127e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 4.5104e-04 - accuracy: 1.0000 - val_loss: 3.3558e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 3.3517e-04 - accuracy: 1.0000 - val_loss: 2.4937e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.0481e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 9.8951e-04 - accuracy: 1.0000 - val_loss: 3.0662e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6596e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 2s 18ms/step - loss: 2.4666e-04 - accuracy: 1.0000 - val_loss: 2.0953e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 4s 37ms/step - loss: 5.0448e-04 - accuracy: 1.0000 - val_loss: 2.0827e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 7.0380e-04 - accuracy: 1.0000 - val_loss: 1.9103e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 3.0985e-04 - accuracy: 1.0000 - val_loss: 1.3265e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 4s 40ms/step - loss: 2.9909e-04 - accuracy: 1.0000 - val_loss: 1.5655e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 2s 15ms/step - loss: 1.9958e-04 - accuracy: 1.0000 - val_loss: 1.2833e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 2.6324e-04 - accuracy: 1.0000 - val_loss: 1.1412e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 3s 31ms/step - loss: 1.0446e-04 - accuracy: 1.0000 - val_loss: 9.3265e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 3s 26ms/step - loss: 2.7112e-04 - accuracy: 1.0000 - val_loss: 7.7794e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 9.5158e-05 - accuracy: 1.0000 - val_loss: 7.0915e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 1.2444e-04 - accuracy: 1.0000 - val_loss: 6.7303e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 4.0851e-04 - accuracy: 1.0000 - val_loss: 3.0552e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.0103 - val_accuracy: 0.9980\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 5s 44ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 1s 11ms/step - loss: 0.0240 - accuracy: 0.9941 - val_loss: 0.0030 - val_accuracy: 0.9980\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_2_input'), name='dense_2_input', description=\"created by layer 'dense_2_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "2/2 [==============================] - 1s 27ms/step\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 24s 220ms/step - loss: 0.1699 - accuracy: 0.7910 - val_loss: 0.1238 - val_accuracy: 0.8457\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.1147 - accuracy: 0.8535 - val_loss: 0.0984 - val_accuracy: 0.8770\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 0.0936 - accuracy: 0.8848 - val_loss: 0.0755 - val_accuracy: 0.8984\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0657 - accuracy: 0.9219 - val_loss: 0.0501 - val_accuracy: 0.9434\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0630 - accuracy: 0.9395 - val_loss: 0.0531 - val_accuracy: 0.9375\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0602 - accuracy: 0.9395 - val_loss: 0.0461 - val_accuracy: 0.9473\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0585 - accuracy: 0.9395 - val_loss: 0.0508 - val_accuracy: 0.9453\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0584 - accuracy: 0.9375 - val_loss: 0.0413 - val_accuracy: 0.9453\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 0.0502 - accuracy: 0.9453 - val_loss: 0.0423 - val_accuracy: 0.9492\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.0497 - accuracy: 0.9453 - val_loss: 0.0423 - val_accuracy: 0.9453\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0470 - accuracy: 0.9434 - val_loss: 0.0397 - val_accuracy: 0.9453\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0472 - accuracy: 0.9453 - val_loss: 0.0422 - val_accuracy: 0.9473\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0455 - accuracy: 0.9492 - val_loss: 0.0390 - val_accuracy: 0.9492\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0484 - accuracy: 0.9355 - val_loss: 0.0394 - val_accuracy: 0.9473\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.0456 - accuracy: 0.9492 - val_loss: 0.0393 - val_accuracy: 0.9473\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0458 - accuracy: 0.9453 - val_loss: 0.0423 - val_accuracy: 0.9434\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0449 - accuracy: 0.9492 - val_loss: 0.0374 - val_accuracy: 0.9531\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.0429 - accuracy: 0.9473 - val_loss: 0.0362 - val_accuracy: 0.9512\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.0427 - accuracy: 0.9492 - val_loss: 0.0360 - val_accuracy: 0.9492\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.0432 - accuracy: 0.9453 - val_loss: 0.0369 - val_accuracy: 0.9531\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0419 - accuracy: 0.9473 - val_loss: 0.0353 - val_accuracy: 0.9492\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 95ms/step - loss: 0.0426 - accuracy: 0.9492 - val_loss: 0.0361 - val_accuracy: 0.9492\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0420 - accuracy: 0.9512 - val_loss: 0.0376 - val_accuracy: 0.9551\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.0406 - accuracy: 0.9512 - val_loss: 0.0322 - val_accuracy: 0.9590\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0388 - accuracy: 0.9492 - val_loss: 0.0327 - val_accuracy: 0.9609\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.0371 - accuracy: 0.9590 - val_loss: 0.0308 - val_accuracy: 0.9648\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.0379 - accuracy: 0.9629 - val_loss: 0.0321 - val_accuracy: 0.9609\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0354 - accuracy: 0.9590 - val_loss: 0.0286 - val_accuracy: 0.9648\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0358 - accuracy: 0.9609 - val_loss: 0.0313 - val_accuracy: 0.9590\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0361 - accuracy: 0.9590 - val_loss: 0.0305 - val_accuracy: 0.9609\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0357 - accuracy: 0.9590 - val_loss: 0.0276 - val_accuracy: 0.9668\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0350 - accuracy: 0.9648 - val_loss: 0.0291 - val_accuracy: 0.9629\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0342 - accuracy: 0.9609 - val_loss: 0.0262 - val_accuracy: 0.9629\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0329 - accuracy: 0.9688 - val_loss: 0.0251 - val_accuracy: 0.9668\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0298 - accuracy: 0.9648 - val_loss: 0.0269 - val_accuracy: 0.9629\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.0321 - accuracy: 0.9668 - val_loss: 0.0260 - val_accuracy: 0.9668\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0328 - accuracy: 0.9609 - val_loss: 0.0285 - val_accuracy: 0.9648\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0296 - accuracy: 0.9746 - val_loss: 0.0236 - val_accuracy: 0.9688\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0269 - accuracy: 0.9688 - val_loss: 0.0240 - val_accuracy: 0.9688\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0268 - accuracy: 0.9727 - val_loss: 0.0233 - val_accuracy: 0.9727\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0258 - accuracy: 0.9707 - val_loss: 0.0223 - val_accuracy: 0.9727\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0283 - accuracy: 0.9648 - val_loss: 0.0280 - val_accuracy: 0.9688\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0296 - accuracy: 0.9629 - val_loss: 0.0221 - val_accuracy: 0.9707\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0267 - accuracy: 0.9746 - val_loss: 0.0216 - val_accuracy: 0.9727\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0281 - accuracy: 0.9609 - val_loss: 0.0216 - val_accuracy: 0.9746\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0366 - accuracy: 0.9590 - val_loss: 0.0279 - val_accuracy: 0.9688\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0286 - accuracy: 0.9668 - val_loss: 0.0228 - val_accuracy: 0.9707\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.0289 - accuracy: 0.9668 - val_loss: 0.0220 - val_accuracy: 0.9766\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0253 - accuracy: 0.9746 - val_loss: 0.0200 - val_accuracy: 0.9785\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0256 - accuracy: 0.9688 - val_loss: 0.0206 - val_accuracy: 0.9727\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0239 - accuracy: 0.9766 - val_loss: 0.0188 - val_accuracy: 0.9805\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0230 - accuracy: 0.9766 - val_loss: 0.0196 - val_accuracy: 0.9805\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.0228 - accuracy: 0.9785 - val_loss: 0.0183 - val_accuracy: 0.9785\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0218 - accuracy: 0.9727 - val_loss: 0.0179 - val_accuracy: 0.9805\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.0218 - accuracy: 0.9746 - val_loss: 0.0182 - val_accuracy: 0.9785\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0224 - accuracy: 0.9746 - val_loss: 0.0183 - val_accuracy: 0.9805\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0238 - accuracy: 0.9766 - val_loss: 0.0183 - val_accuracy: 0.9805\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0251 - accuracy: 0.9688 - val_loss: 0.0383 - val_accuracy: 0.9531\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0338 - accuracy: 0.9609 - val_loss: 0.0443 - val_accuracy: 0.9570\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.0370 - accuracy: 0.9609 - val_loss: 0.0244 - val_accuracy: 0.9727\n",
      "2/2 [==============================] - 2s 32ms/step\n",
      "GRU\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 10s 203ms/step - loss: 0.1576 - accuracy: 0.8359 - val_loss: 0.0947 - val_accuracy: 0.8984\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.1043 - accuracy: 0.8594 - val_loss: 0.0833 - val_accuracy: 0.9180\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0870 - accuracy: 0.9160 - val_loss: 0.0803 - val_accuracy: 0.9082\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0827 - accuracy: 0.9102 - val_loss: 0.0748 - val_accuracy: 0.9258\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0780 - accuracy: 0.9297 - val_loss: 0.0720 - val_accuracy: 0.9375\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0728 - accuracy: 0.9355 - val_loss: 0.0679 - val_accuracy: 0.9473\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0737 - accuracy: 0.9414 - val_loss: 0.0642 - val_accuracy: 0.9434\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0709 - accuracy: 0.9375 - val_loss: 0.0612 - val_accuracy: 0.9512\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0697 - accuracy: 0.9551 - val_loss: 0.0638 - val_accuracy: 0.9453\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0681 - accuracy: 0.9414 - val_loss: 0.0598 - val_accuracy: 0.9531\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0602 - accuracy: 0.9629 - val_loss: 0.0576 - val_accuracy: 0.9688\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0606 - accuracy: 0.9590 - val_loss: 0.0541 - val_accuracy: 0.9629\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0619 - accuracy: 0.9492 - val_loss: 0.0578 - val_accuracy: 0.9668\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0580 - accuracy: 0.9531 - val_loss: 0.0479 - val_accuracy: 0.9648\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0539 - accuracy: 0.9609 - val_loss: 0.0452 - val_accuracy: 0.9609\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0480 - accuracy: 0.9648 - val_loss: 0.0406 - val_accuracy: 0.9688\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0478 - accuracy: 0.9629 - val_loss: 0.0379 - val_accuracy: 0.9609\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0467 - accuracy: 0.9570 - val_loss: 0.0359 - val_accuracy: 0.9688\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0434 - accuracy: 0.9570 - val_loss: 0.0343 - val_accuracy: 0.9688\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0442 - accuracy: 0.9707 - val_loss: 0.0348 - val_accuracy: 0.9648\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0408 - accuracy: 0.9570 - val_loss: 0.0306 - val_accuracy: 0.9688\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0381 - accuracy: 0.9688 - val_loss: 0.0316 - val_accuracy: 0.9707\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0378 - accuracy: 0.9609 - val_loss: 0.0305 - val_accuracy: 0.9668\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0395 - accuracy: 0.9688 - val_loss: 0.0326 - val_accuracy: 0.9668\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0347 - accuracy: 0.9707 - val_loss: 0.0288 - val_accuracy: 0.9648\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0369 - accuracy: 0.9609 - val_loss: 0.0274 - val_accuracy: 0.9688\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0327 - accuracy: 0.9707 - val_loss: 0.0271 - val_accuracy: 0.9688\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0356 - accuracy: 0.9648 - val_loss: 0.0267 - val_accuracy: 0.9688\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0361 - accuracy: 0.9648 - val_loss: 0.0289 - val_accuracy: 0.9668\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0335 - accuracy: 0.9727 - val_loss: 0.0289 - val_accuracy: 0.9707\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0340 - accuracy: 0.9609 - val_loss: 0.0251 - val_accuracy: 0.9707\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0315 - accuracy: 0.9648 - val_loss: 0.0249 - val_accuracy: 0.9727\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0301 - accuracy: 0.9746 - val_loss: 0.0278 - val_accuracy: 0.9688\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0333 - accuracy: 0.9648 - val_loss: 0.0264 - val_accuracy: 0.9688\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0333 - accuracy: 0.9648 - val_loss: 0.0293 - val_accuracy: 0.9688\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0330 - accuracy: 0.9707 - val_loss: 0.0246 - val_accuracy: 0.9707\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0304 - accuracy: 0.9688 - val_loss: 0.0244 - val_accuracy: 0.9727\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0294 - accuracy: 0.9707 - val_loss: 0.0244 - val_accuracy: 0.9707\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0305 - accuracy: 0.9688 - val_loss: 0.0230 - val_accuracy: 0.9707\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0292 - accuracy: 0.9766 - val_loss: 0.0227 - val_accuracy: 0.9727\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0297 - accuracy: 0.9688 - val_loss: 0.0220 - val_accuracy: 0.9707\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0299 - accuracy: 0.9688 - val_loss: 0.0216 - val_accuracy: 0.9707\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0272 - accuracy: 0.9707 - val_loss: 0.0221 - val_accuracy: 0.9727\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0309 - accuracy: 0.9648 - val_loss: 0.0241 - val_accuracy: 0.9707\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0291 - accuracy: 0.9707 - val_loss: 0.0218 - val_accuracy: 0.9746\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0271 - accuracy: 0.9746 - val_loss: 0.0203 - val_accuracy: 0.9746\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0275 - accuracy: 0.9707 - val_loss: 0.0208 - val_accuracy: 0.9727\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0262 - accuracy: 0.9727 - val_loss: 0.0203 - val_accuracy: 0.9785\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0260 - accuracy: 0.9727 - val_loss: 0.0194 - val_accuracy: 0.9707\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0243 - accuracy: 0.9766 - val_loss: 0.0198 - val_accuracy: 0.9766\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0244 - accuracy: 0.9746 - val_loss: 0.0195 - val_accuracy: 0.9688\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0249 - accuracy: 0.9727 - val_loss: 0.0209 - val_accuracy: 0.9766\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0263 - accuracy: 0.9766 - val_loss: 0.0187 - val_accuracy: 0.9785\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0233 - accuracy: 0.9785 - val_loss: 0.0175 - val_accuracy: 0.9785\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0242 - accuracy: 0.9766 - val_loss: 0.0177 - val_accuracy: 0.9766\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0234 - accuracy: 0.9766 - val_loss: 0.0174 - val_accuracy: 0.9785\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0232 - accuracy: 0.9766 - val_loss: 0.0174 - val_accuracy: 0.9785\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0235 - accuracy: 0.9785 - val_loss: 0.0156 - val_accuracy: 0.9824\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0213 - accuracy: 0.9824 - val_loss: 0.0163 - val_accuracy: 0.9805\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0185 - accuracy: 0.9824 - val_loss: 0.0145 - val_accuracy: 0.9824\n",
      "2/2 [==============================] - 2s 20ms/step\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   2\n",
      "CNN\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 2s 23ms/step - loss: 0.9308 - accuracy: 0.5449 - val_loss: 0.6693 - val_accuracy: 0.6992\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5841 - accuracy: 0.7246 - val_loss: 0.6308 - val_accuracy: 0.8965\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4759 - accuracy: 0.7949 - val_loss: 0.5882 - val_accuracy: 0.9023\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3573 - accuracy: 0.8535 - val_loss: 0.5477 - val_accuracy: 0.9102\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3069 - accuracy: 0.8848 - val_loss: 0.5088 - val_accuracy: 0.9141\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2404 - accuracy: 0.9082 - val_loss: 0.4699 - val_accuracy: 0.9102\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2217 - accuracy: 0.9102 - val_loss: 0.4314 - val_accuracy: 0.9102\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2176 - accuracy: 0.9023 - val_loss: 0.3944 - val_accuracy: 0.9102\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1944 - accuracy: 0.9160 - val_loss: 0.3603 - val_accuracy: 0.9141\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2267 - accuracy: 0.9102 - val_loss: 0.3281 - val_accuracy: 0.9180\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1676 - accuracy: 0.9355 - val_loss: 0.2991 - val_accuracy: 0.9238\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1634 - accuracy: 0.9395 - val_loss: 0.2713 - val_accuracy: 0.9336\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1701 - accuracy: 0.9316 - val_loss: 0.2474 - val_accuracy: 0.9336\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1615 - accuracy: 0.9336 - val_loss: 0.2242 - val_accuracy: 0.9395\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9492 - val_loss: 0.2039 - val_accuracy: 0.9453\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1659 - accuracy: 0.9355 - val_loss: 0.1862 - val_accuracy: 0.9473\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1696 - accuracy: 0.9297 - val_loss: 0.1699 - val_accuracy: 0.9492\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.9551 - val_loss: 0.1558 - val_accuracy: 0.9512\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1232 - accuracy: 0.9531 - val_loss: 0.1430 - val_accuracy: 0.9531\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1351 - accuracy: 0.9395 - val_loss: 0.1326 - val_accuracy: 0.9551\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1304 - accuracy: 0.9512 - val_loss: 0.1238 - val_accuracy: 0.9590\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1372 - accuracy: 0.9434 - val_loss: 0.1150 - val_accuracy: 0.9609\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1107 - accuracy: 0.9590 - val_loss: 0.1086 - val_accuracy: 0.9609\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1303 - accuracy: 0.9570 - val_loss: 0.1011 - val_accuracy: 0.9629\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.9531 - val_loss: 0.0938 - val_accuracy: 0.9648\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1015 - accuracy: 0.9570 - val_loss: 0.0883 - val_accuracy: 0.9648\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0897 - accuracy: 0.9707 - val_loss: 0.0841 - val_accuracy: 0.9648\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9727 - val_loss: 0.0808 - val_accuracy: 0.9668\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0901 - accuracy: 0.9648 - val_loss: 0.0780 - val_accuracy: 0.9707\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.0741 - val_accuracy: 0.9766\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9648 - val_loss: 0.0716 - val_accuracy: 0.9785\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1129 - accuracy: 0.9492 - val_loss: 0.0697 - val_accuracy: 0.9785\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1131 - accuracy: 0.9551 - val_loss: 0.0673 - val_accuracy: 0.9805\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.9668 - val_loss: 0.0652 - val_accuracy: 0.9805\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1000 - accuracy: 0.9648 - val_loss: 0.0633 - val_accuracy: 0.9805\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0884 - accuracy: 0.9668 - val_loss: 0.0612 - val_accuracy: 0.9824\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9668 - val_loss: 0.0592 - val_accuracy: 0.9844\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1012 - accuracy: 0.9648 - val_loss: 0.0581 - val_accuracy: 0.9844\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1031 - accuracy: 0.9648 - val_loss: 0.0567 - val_accuracy: 0.9844\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1052 - accuracy: 0.9590 - val_loss: 0.0550 - val_accuracy: 0.9844\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0976 - accuracy: 0.9648 - val_loss: 0.0529 - val_accuracy: 0.9863\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.9727 - val_loss: 0.0520 - val_accuracy: 0.9863\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1068 - accuracy: 0.9668 - val_loss: 0.0503 - val_accuracy: 0.9863\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0884 - accuracy: 0.9668 - val_loss: 0.0496 - val_accuracy: 0.9863\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0862 - accuracy: 0.9688 - val_loss: 0.0496 - val_accuracy: 0.9863\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0914 - accuracy: 0.9707 - val_loss: 0.0489 - val_accuracy: 0.9863\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0908 - accuracy: 0.9629 - val_loss: 0.0481 - val_accuracy: 0.9863\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0924 - accuracy: 0.9629 - val_loss: 0.0473 - val_accuracy: 0.9863\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9746 - val_loss: 0.0462 - val_accuracy: 0.9863\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0982 - accuracy: 0.9570 - val_loss: 0.0460 - val_accuracy: 0.9863\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 0.9707 - val_loss: 0.0453 - val_accuracy: 0.9863\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0720 - accuracy: 0.9785 - val_loss: 0.0447 - val_accuracy: 0.9863\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0849 - accuracy: 0.9785 - val_loss: 0.0443 - val_accuracy: 0.9863\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0847 - accuracy: 0.9727 - val_loss: 0.0443 - val_accuracy: 0.9863\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0765 - accuracy: 0.9688 - val_loss: 0.0446 - val_accuracy: 0.9844\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0866 - accuracy: 0.9648 - val_loss: 0.0444 - val_accuracy: 0.9863\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0898 - accuracy: 0.9648 - val_loss: 0.0439 - val_accuracy: 0.9844\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0751 - accuracy: 0.9668 - val_loss: 0.0431 - val_accuracy: 0.9844\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0752 - accuracy: 0.9668 - val_loss: 0.0425 - val_accuracy: 0.9863\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0855 - accuracy: 0.9648 - val_loss: 0.0416 - val_accuracy: 0.9883\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D1B1C0E680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "RNN\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      " 79/103 [======================>.......] - ETA: 0s - loss: 0.2203 - accuracy: 0.9139WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1939 - accuracy: 0.9316 - val_loss: 0.0824 - val_accuracy: 0.9766\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9707 - val_loss: 0.0543 - val_accuracy: 0.9883\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 0.0419 - val_accuracy: 0.9922\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9844 - val_loss: 0.0393 - val_accuracy: 0.9883\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.0322 - val_accuracy: 0.9902\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9805 - val_loss: 0.0368 - val_accuracy: 0.9844\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0244 - val_accuracy: 0.9902\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 0.0306 - val_accuracy: 0.9863\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9883 - val_loss: 0.0141 - val_accuracy: 0.9941\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9922 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0150 - val_accuracy: 0.9902\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9863 - val_loss: 0.0243 - val_accuracy: 0.9902\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9883 - val_loss: 0.0106 - val_accuracy: 0.9961\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9941 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9941 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9961 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9941 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9961 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9961 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9980 - val_loss: 9.4364e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 9.8299e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 5.0170e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 8.1456e-04 - accuracy: 1.0000 - val_loss: 4.4582e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 8.2524e-04 - accuracy: 1.0000 - val_loss: 3.7485e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.9051e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.5583e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9980\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9922 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9922 - val_loss: 0.0094 - val_accuracy: 0.9941\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9902 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9941 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 7.6891e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 9.6627e-04 - accuracy: 1.0000 - val_loss: 6.4406e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.5586e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9961 - val_loss: 6.9625e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.1156e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.7231e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 8.6720e-04 - accuracy: 1.0000 - val_loss: 3.7999e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9961 - val_loss: 0.0075 - val_accuracy: 0.9961\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 6.9154e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 8.0341e-04 - accuracy: 1.0000 - val_loss: 5.3148e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 9.4880e-04 - accuracy: 1.0000 - val_loss: 3.9688e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8331e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.0962e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.4778e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9980\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9961 - val_loss: 4.8361e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D1B1B29AB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 8s 145ms/step - loss: 0.2017 - accuracy: 0.7598 - val_loss: 0.1312 - val_accuracy: 0.8086\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.1241 - accuracy: 0.8398 - val_loss: 0.1039 - val_accuracy: 0.8770\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.1015 - accuracy: 0.8730 - val_loss: 0.0918 - val_accuracy: 0.8906\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.0931 - accuracy: 0.8809 - val_loss: 0.0688 - val_accuracy: 0.9062\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0674 - accuracy: 0.9316 - val_loss: 0.0499 - val_accuracy: 0.9434\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0562 - accuracy: 0.9414 - val_loss: 0.0454 - val_accuracy: 0.9453\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0529 - accuracy: 0.9395 - val_loss: 0.0442 - val_accuracy: 0.9434\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0510 - accuracy: 0.9395 - val_loss: 0.0527 - val_accuracy: 0.9453\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.0614 - accuracy: 0.9277 - val_loss: 0.0425 - val_accuracy: 0.9453\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0519 - accuracy: 0.9414 - val_loss: 0.0416 - val_accuracy: 0.9473\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0476 - accuracy: 0.9414 - val_loss: 0.0398 - val_accuracy: 0.9453\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0471 - accuracy: 0.9453 - val_loss: 0.0419 - val_accuracy: 0.9414\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0480 - accuracy: 0.9453 - val_loss: 0.0400 - val_accuracy: 0.9434\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0471 - accuracy: 0.9414 - val_loss: 0.0393 - val_accuracy: 0.9473\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0453 - accuracy: 0.9434 - val_loss: 0.0407 - val_accuracy: 0.9473\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0440 - accuracy: 0.9453 - val_loss: 0.0386 - val_accuracy: 0.9492\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0452 - accuracy: 0.9414 - val_loss: 0.0393 - val_accuracy: 0.9473\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0454 - accuracy: 0.9453 - val_loss: 0.0388 - val_accuracy: 0.9453\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0453 - accuracy: 0.9355 - val_loss: 0.0425 - val_accuracy: 0.9492\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0463 - accuracy: 0.9414 - val_loss: 0.0401 - val_accuracy: 0.9434\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0423 - accuracy: 0.9434 - val_loss: 0.0469 - val_accuracy: 0.9434\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0479 - accuracy: 0.9395 - val_loss: 0.0425 - val_accuracy: 0.9453\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0443 - accuracy: 0.9453 - val_loss: 0.0361 - val_accuracy: 0.9531\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0406 - accuracy: 0.9473 - val_loss: 0.0394 - val_accuracy: 0.9531\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0411 - accuracy: 0.9531 - val_loss: 0.0359 - val_accuracy: 0.9570\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0422 - accuracy: 0.9473 - val_loss: 0.0351 - val_accuracy: 0.9492\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0402 - accuracy: 0.9492 - val_loss: 0.0341 - val_accuracy: 0.9570\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0395 - accuracy: 0.9492 - val_loss: 0.0345 - val_accuracy: 0.9512\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0401 - accuracy: 0.9512 - val_loss: 0.0332 - val_accuracy: 0.9570\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0368 - accuracy: 0.9551 - val_loss: 0.0332 - val_accuracy: 0.9590\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0382 - accuracy: 0.9531 - val_loss: 0.0320 - val_accuracy: 0.9551\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0373 - accuracy: 0.9453 - val_loss: 0.0342 - val_accuracy: 0.9492\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0393 - accuracy: 0.9551 - val_loss: 0.0360 - val_accuracy: 0.9551\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0380 - accuracy: 0.9531 - val_loss: 0.0388 - val_accuracy: 0.9473\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0392 - accuracy: 0.9512 - val_loss: 0.0337 - val_accuracy: 0.9629\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0381 - accuracy: 0.9512 - val_loss: 0.0315 - val_accuracy: 0.9609\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0352 - accuracy: 0.9551 - val_loss: 0.0306 - val_accuracy: 0.9590\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0343 - accuracy: 0.9551 - val_loss: 0.0288 - val_accuracy: 0.9590\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0349 - accuracy: 0.9531 - val_loss: 0.0306 - val_accuracy: 0.9590\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0346 - accuracy: 0.9492 - val_loss: 0.0292 - val_accuracy: 0.9570\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0350 - accuracy: 0.9551 - val_loss: 0.0297 - val_accuracy: 0.9609\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0357 - accuracy: 0.9512 - val_loss: 0.0286 - val_accuracy: 0.9629\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0342 - accuracy: 0.9590 - val_loss: 0.0334 - val_accuracy: 0.9570\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0342 - accuracy: 0.9551 - val_loss: 0.0272 - val_accuracy: 0.9590\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0338 - accuracy: 0.9570 - val_loss: 0.0312 - val_accuracy: 0.9570\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0345 - accuracy: 0.9590 - val_loss: 0.0291 - val_accuracy: 0.9570\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0334 - accuracy: 0.9570 - val_loss: 0.0281 - val_accuracy: 0.9648\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0326 - accuracy: 0.9629 - val_loss: 0.0278 - val_accuracy: 0.9570\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0326 - accuracy: 0.9570 - val_loss: 0.0285 - val_accuracy: 0.9590\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0307 - accuracy: 0.9590 - val_loss: 0.0254 - val_accuracy: 0.9629\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0275 - accuracy: 0.9609 - val_loss: 0.0258 - val_accuracy: 0.9648\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0286 - accuracy: 0.9629 - val_loss: 0.0251 - val_accuracy: 0.9629\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0311 - accuracy: 0.9570 - val_loss: 0.0249 - val_accuracy: 0.9668\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0300 - accuracy: 0.9707 - val_loss: 0.0255 - val_accuracy: 0.9629\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0304 - accuracy: 0.9629 - val_loss: 0.0288 - val_accuracy: 0.9570\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0293 - accuracy: 0.9590 - val_loss: 0.0250 - val_accuracy: 0.9648\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0319 - accuracy: 0.9551 - val_loss: 0.0271 - val_accuracy: 0.9570\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0294 - accuracy: 0.9609 - val_loss: 0.0243 - val_accuracy: 0.9648\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0280 - accuracy: 0.9609 - val_loss: 0.0252 - val_accuracy: 0.9668\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0285 - accuracy: 0.9609 - val_loss: 0.0289 - val_accuracy: 0.9629\n",
      "2/2 [==============================] - 2s 20ms/step\n",
      "GRU\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 8s 142ms/step - loss: 0.1498 - accuracy: 0.8477 - val_loss: 0.1041 - val_accuracy: 0.9043\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.0956 - accuracy: 0.9082 - val_loss: 0.0836 - val_accuracy: 0.9062\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0869 - accuracy: 0.8984 - val_loss: 0.0815 - val_accuracy: 0.9219\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0875 - accuracy: 0.9121 - val_loss: 0.0770 - val_accuracy: 0.9160\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0865 - accuracy: 0.9004 - val_loss: 0.0727 - val_accuracy: 0.9219\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0758 - accuracy: 0.9199 - val_loss: 0.0670 - val_accuracy: 0.9375\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0700 - accuracy: 0.9395 - val_loss: 0.0625 - val_accuracy: 0.9414\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0682 - accuracy: 0.9336 - val_loss: 0.0562 - val_accuracy: 0.9590\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0618 - accuracy: 0.9434 - val_loss: 0.0510 - val_accuracy: 0.9570\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0574 - accuracy: 0.9453 - val_loss: 0.0481 - val_accuracy: 0.9609\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0532 - accuracy: 0.9531 - val_loss: 0.0451 - val_accuracy: 0.9551\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0515 - accuracy: 0.9570 - val_loss: 0.0421 - val_accuracy: 0.9590\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0504 - accuracy: 0.9531 - val_loss: 0.0384 - val_accuracy: 0.9609\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0497 - accuracy: 0.9492 - val_loss: 0.0380 - val_accuracy: 0.9590\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0465 - accuracy: 0.9609 - val_loss: 0.0366 - val_accuracy: 0.9609\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0422 - accuracy: 0.9570 - val_loss: 0.0374 - val_accuracy: 0.9590\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0416 - accuracy: 0.9629 - val_loss: 0.0354 - val_accuracy: 0.9590\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0445 - accuracy: 0.9531 - val_loss: 0.0320 - val_accuracy: 0.9590\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0392 - accuracy: 0.9668 - val_loss: 0.0322 - val_accuracy: 0.9629\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0397 - accuracy: 0.9727 - val_loss: 0.0306 - val_accuracy: 0.9648\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0380 - accuracy: 0.9590 - val_loss: 0.0297 - val_accuracy: 0.9609\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0335 - accuracy: 0.9570 - val_loss: 0.0273 - val_accuracy: 0.9707\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0354 - accuracy: 0.9648 - val_loss: 0.0272 - val_accuracy: 0.9668\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0345 - accuracy: 0.9629 - val_loss: 0.0285 - val_accuracy: 0.9707\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0356 - accuracy: 0.9629 - val_loss: 0.0268 - val_accuracy: 0.9668\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0337 - accuracy: 0.9668 - val_loss: 0.0269 - val_accuracy: 0.9648\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0329 - accuracy: 0.9688 - val_loss: 0.0261 - val_accuracy: 0.9707\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0337 - accuracy: 0.9609 - val_loss: 0.0269 - val_accuracy: 0.9688\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0325 - accuracy: 0.9609 - val_loss: 0.0267 - val_accuracy: 0.9688\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0331 - accuracy: 0.9648 - val_loss: 0.0269 - val_accuracy: 0.9727\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0313 - accuracy: 0.9688 - val_loss: 0.0267 - val_accuracy: 0.9688\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0334 - accuracy: 0.9648 - val_loss: 0.0259 - val_accuracy: 0.9668\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0312 - accuracy: 0.9688 - val_loss: 0.0240 - val_accuracy: 0.9727\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0314 - accuracy: 0.9648 - val_loss: 0.0239 - val_accuracy: 0.9727\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0303 - accuracy: 0.9668 - val_loss: 0.0230 - val_accuracy: 0.9707\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0296 - accuracy: 0.9668 - val_loss: 0.0234 - val_accuracy: 0.9707\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0287 - accuracy: 0.9746 - val_loss: 0.0227 - val_accuracy: 0.9727\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0281 - accuracy: 0.9707 - val_loss: 0.0240 - val_accuracy: 0.9688\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0301 - accuracy: 0.9688 - val_loss: 0.0236 - val_accuracy: 0.9727\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0283 - accuracy: 0.9746 - val_loss: 0.0217 - val_accuracy: 0.9668\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0274 - accuracy: 0.9707 - val_loss: 0.0218 - val_accuracy: 0.9727\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0276 - accuracy: 0.9688 - val_loss: 0.0225 - val_accuracy: 0.9668\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0272 - accuracy: 0.9727 - val_loss: 0.0250 - val_accuracy: 0.9727\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0281 - accuracy: 0.9707 - val_loss: 0.0238 - val_accuracy: 0.9727\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0281 - accuracy: 0.9785 - val_loss: 0.0236 - val_accuracy: 0.9727\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0254 - accuracy: 0.9688 - val_loss: 0.0204 - val_accuracy: 0.9727\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0271 - accuracy: 0.9688 - val_loss: 0.0206 - val_accuracy: 0.9727\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0280 - accuracy: 0.9688 - val_loss: 0.0214 - val_accuracy: 0.9727\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0281 - accuracy: 0.9727 - val_loss: 0.0208 - val_accuracy: 0.9727\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0273 - accuracy: 0.9707 - val_loss: 0.0208 - val_accuracy: 0.9746\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0282 - accuracy: 0.9727 - val_loss: 0.0202 - val_accuracy: 0.9766\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0264 - accuracy: 0.9707 - val_loss: 0.0199 - val_accuracy: 0.9727\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0242 - accuracy: 0.9746 - val_loss: 0.0188 - val_accuracy: 0.9766\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0224 - accuracy: 0.9766 - val_loss: 0.0180 - val_accuracy: 0.9746\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0251 - accuracy: 0.9727 - val_loss: 0.0179 - val_accuracy: 0.9766\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0248 - accuracy: 0.9688 - val_loss: 0.0184 - val_accuracy: 0.9746\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0225 - accuracy: 0.9785 - val_loss: 0.0173 - val_accuracy: 0.9766\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0246 - accuracy: 0.9727 - val_loss: 0.0174 - val_accuracy: 0.9785\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0236 - accuracy: 0.9766 - val_loss: 0.0165 - val_accuracy: 0.9766\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0205 - accuracy: 0.9766 - val_loss: 0.0161 - val_accuracy: 0.9766\n",
      "2/2 [==============================] - 1s 14ms/step\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   3\n",
      "CNN\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 2s 23ms/step - loss: 0.7037 - accuracy: 0.6797 - val_loss: 0.6282 - val_accuracy: 0.8633\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4176 - accuracy: 0.8262 - val_loss: 0.5764 - val_accuracy: 0.9004\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3283 - accuracy: 0.8691 - val_loss: 0.5319 - val_accuracy: 0.9023\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2673 - accuracy: 0.9043 - val_loss: 0.4922 - val_accuracy: 0.8887\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2494 - accuracy: 0.9023 - val_loss: 0.4545 - val_accuracy: 0.8848\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2415 - accuracy: 0.9238 - val_loss: 0.4187 - val_accuracy: 0.8828\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1817 - accuracy: 0.9277 - val_loss: 0.3850 - val_accuracy: 0.8828\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1902 - accuracy: 0.9160 - val_loss: 0.3557 - val_accuracy: 0.8828\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1406 - accuracy: 0.9570 - val_loss: 0.3289 - val_accuracy: 0.8887\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1378 - accuracy: 0.9434 - val_loss: 0.3038 - val_accuracy: 0.8945\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1293 - accuracy: 0.9609 - val_loss: 0.2803 - val_accuracy: 0.8984\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1346 - accuracy: 0.9414 - val_loss: 0.2562 - val_accuracy: 0.9023\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1297 - accuracy: 0.9414 - val_loss: 0.2352 - val_accuracy: 0.9102\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1400 - accuracy: 0.9531 - val_loss: 0.2127 - val_accuracy: 0.9180\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1493 - accuracy: 0.9434 - val_loss: 0.1951 - val_accuracy: 0.9277\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1232 - accuracy: 0.9492 - val_loss: 0.1806 - val_accuracy: 0.9316\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1267 - accuracy: 0.9473 - val_loss: 0.1635 - val_accuracy: 0.9375\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1039 - accuracy: 0.9668 - val_loss: 0.1455 - val_accuracy: 0.9453\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1181 - accuracy: 0.9590 - val_loss: 0.1353 - val_accuracy: 0.9453\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1375 - accuracy: 0.9512 - val_loss: 0.1229 - val_accuracy: 0.9512\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1015 - accuracy: 0.9551 - val_loss: 0.1143 - val_accuracy: 0.9551\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1017 - accuracy: 0.9512 - val_loss: 0.1059 - val_accuracy: 0.9570\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0815 - accuracy: 0.9746 - val_loss: 0.0963 - val_accuracy: 0.9590\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1079 - accuracy: 0.9590 - val_loss: 0.0854 - val_accuracy: 0.9766\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1215 - accuracy: 0.9492 - val_loss: 0.0792 - val_accuracy: 0.9766\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1071 - accuracy: 0.9570 - val_loss: 0.0715 - val_accuracy: 0.9785\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0942 - accuracy: 0.9707 - val_loss: 0.0675 - val_accuracy: 0.9805\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0759 - accuracy: 0.9766 - val_loss: 0.0629 - val_accuracy: 0.9844\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0867 - accuracy: 0.9746 - val_loss: 0.0583 - val_accuracy: 0.9863\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0931 - accuracy: 0.9688 - val_loss: 0.0541 - val_accuracy: 0.9883\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0897 - accuracy: 0.9648 - val_loss: 0.0511 - val_accuracy: 0.9902\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0763 - accuracy: 0.9746 - val_loss: 0.0485 - val_accuracy: 0.9902\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0718 - accuracy: 0.9766 - val_loss: 0.0468 - val_accuracy: 0.9902\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0805 - accuracy: 0.9648 - val_loss: 0.0447 - val_accuracy: 0.9902\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0776 - accuracy: 0.9727 - val_loss: 0.0427 - val_accuracy: 0.9902\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0749 - accuracy: 0.9746 - val_loss: 0.0409 - val_accuracy: 0.9922\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0705 - accuracy: 0.9746 - val_loss: 0.0392 - val_accuracy: 0.9941\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0528 - accuracy: 0.9844 - val_loss: 0.0375 - val_accuracy: 0.9941\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0706 - accuracy: 0.9727 - val_loss: 0.0366 - val_accuracy: 0.9941\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0630 - accuracy: 0.9805 - val_loss: 0.0358 - val_accuracy: 0.9922\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0707 - accuracy: 0.9746 - val_loss: 0.0346 - val_accuracy: 0.9922\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0587 - accuracy: 0.9805 - val_loss: 0.0332 - val_accuracy: 0.9941\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0698 - accuracy: 0.9688 - val_loss: 0.0322 - val_accuracy: 0.9941\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0675 - accuracy: 0.9766 - val_loss: 0.0312 - val_accuracy: 0.9941\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0547 - accuracy: 0.9805 - val_loss: 0.0307 - val_accuracy: 0.9941\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0769 - accuracy: 0.9707 - val_loss: 0.0301 - val_accuracy: 0.9941\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.0298 - val_accuracy: 0.9941\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0664 - accuracy: 0.9668 - val_loss: 0.0293 - val_accuracy: 0.9922\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0604 - accuracy: 0.9766 - val_loss: 0.0287 - val_accuracy: 0.9941\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0681 - accuracy: 0.9727 - val_loss: 0.0276 - val_accuracy: 0.9941\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0678 - accuracy: 0.9688 - val_loss: 0.0271 - val_accuracy: 0.9941\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0406 - accuracy: 0.9902 - val_loss: 0.0267 - val_accuracy: 0.9941\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0838 - accuracy: 0.9766 - val_loss: 0.0265 - val_accuracy: 0.9941\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0524 - accuracy: 0.9766 - val_loss: 0.0259 - val_accuracy: 0.9941\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0459 - accuracy: 0.9824 - val_loss: 0.0254 - val_accuracy: 0.9941\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0513 - accuracy: 0.9746 - val_loss: 0.0251 - val_accuracy: 0.9941\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.0246 - val_accuracy: 0.9941\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0742 - accuracy: 0.9785 - val_loss: 0.0245 - val_accuracy: 0.9941\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0488 - accuracy: 0.9824 - val_loss: 0.0241 - val_accuracy: 0.9941\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0552 - accuracy: 0.9805 - val_loss: 0.0239 - val_accuracy: 0.9941\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "RNN\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      " 83/103 [=======================>......] - ETA: 0s - loss: 0.2480 - accuracy: 0.9084WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.2264 - accuracy: 0.9121 - val_loss: 0.0755 - val_accuracy: 0.9785\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9746 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9824 - val_loss: 0.0346 - val_accuracy: 0.9922\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9863 - val_loss: 0.0289 - val_accuracy: 0.9941\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.0243 - val_accuracy: 0.9922\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.0191 - val_accuracy: 0.9961\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9941 - val_loss: 0.0161 - val_accuracy: 0.9941\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.0124 - val_accuracy: 0.9941\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9941\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0111 - val_accuracy: 0.9941\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9961 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9961 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9961 - val_loss: 0.0092 - val_accuracy: 0.9941\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0035 - val_accuracy: 0.9980\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9980 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9961 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9961 - val_loss: 0.0044 - val_accuracy: 0.9980\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9922 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9980 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.9064e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.5063e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.6146e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 9.9210e-04 - accuracy: 1.0000 - val_loss: 4.8588e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 4.9309e-04 - accuracy: 1.0000 - val_loss: 4.4015e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 7.1706e-04 - accuracy: 1.0000 - val_loss: 3.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 5.3104e-04 - accuracy: 1.0000 - val_loss: 2.7106e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 4.1005e-04 - accuracy: 1.0000 - val_loss: 2.4227e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 4.2985e-04 - accuracy: 1.0000 - val_loss: 2.4638e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 3.6804e-04 - accuracy: 1.0000 - val_loss: 1.9364e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 6.3441e-04 - accuracy: 1.0000 - val_loss: 1.7981e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 5.0873e-04 - accuracy: 1.0000 - val_loss: 1.6387e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.9979e-04 - accuracy: 1.0000 - val_loss: 1.2393e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 2.8856e-04 - accuracy: 1.0000 - val_loss: 1.8778e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 1.2932e-04 - accuracy: 1.0000 - val_loss: 1.3259e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.6504e-04 - accuracy: 1.0000 - val_loss: 9.6308e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.0687e-04 - accuracy: 1.0000 - val_loss: 9.2974e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1645e-04 - accuracy: 1.0000 - val_loss: 8.9306e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.5402e-04 - accuracy: 1.0000 - val_loss: 7.8786e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.1409e-04 - accuracy: 1.0000 - val_loss: 7.1850e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 4.9305e-04 - accuracy: 1.0000 - val_loss: 8.6056e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.1671e-04 - accuracy: 1.0000 - val_loss: 7.9253e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.1477e-04 - accuracy: 1.0000 - val_loss: 5.9118e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3061e-04 - accuracy: 1.0000 - val_loss: 5.3023e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.9321e-04 - accuracy: 1.0000 - val_loss: 4.8872e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 4.0280e-04 - accuracy: 1.0000 - val_loss: 1.1090e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9961 - val_loss: 0.0021 - val_accuracy: 0.9980\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9902 - val_loss: 0.0041 - val_accuracy: 0.9980\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_16_input'), name='dense_16_input', description=\"created by layer 'dense_16_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 8s 168ms/step - loss: 0.1953 - accuracy: 0.7773 - val_loss: 0.1328 - val_accuracy: 0.7891\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 0.1311 - accuracy: 0.8008 - val_loss: 0.1059 - val_accuracy: 0.8770\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0988 - accuracy: 0.8789 - val_loss: 0.0871 - val_accuracy: 0.8945\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0844 - accuracy: 0.8945 - val_loss: 0.0550 - val_accuracy: 0.9180\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0558 - accuracy: 0.9395 - val_loss: 0.0436 - val_accuracy: 0.9414\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0530 - accuracy: 0.9375 - val_loss: 0.0467 - val_accuracy: 0.9473\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0519 - accuracy: 0.9414 - val_loss: 0.0380 - val_accuracy: 0.9492\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0476 - accuracy: 0.9473 - val_loss: 0.0393 - val_accuracy: 0.9434\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0449 - accuracy: 0.9414 - val_loss: 0.0401 - val_accuracy: 0.9512\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0436 - accuracy: 0.9492 - val_loss: 0.0367 - val_accuracy: 0.9453\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0441 - accuracy: 0.9453 - val_loss: 0.0396 - val_accuracy: 0.9492\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0429 - accuracy: 0.9453 - val_loss: 0.0418 - val_accuracy: 0.9512\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0422 - accuracy: 0.9512 - val_loss: 0.0360 - val_accuracy: 0.9512\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0406 - accuracy: 0.9492 - val_loss: 0.0338 - val_accuracy: 0.9531\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0391 - accuracy: 0.9531 - val_loss: 0.0337 - val_accuracy: 0.9609\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0411 - accuracy: 0.9492 - val_loss: 0.0331 - val_accuracy: 0.9570\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0381 - accuracy: 0.9609 - val_loss: 0.0321 - val_accuracy: 0.9531\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0390 - accuracy: 0.9551 - val_loss: 0.0371 - val_accuracy: 0.9492\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.0409 - accuracy: 0.9531 - val_loss: 0.0361 - val_accuracy: 0.9512\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0446 - accuracy: 0.9492 - val_loss: 0.0370 - val_accuracy: 0.9531\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0383 - accuracy: 0.9570 - val_loss: 0.0345 - val_accuracy: 0.9590\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0397 - accuracy: 0.9473 - val_loss: 0.0304 - val_accuracy: 0.9629\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0385 - accuracy: 0.9531 - val_loss: 0.0308 - val_accuracy: 0.9629\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0351 - accuracy: 0.9570 - val_loss: 0.0323 - val_accuracy: 0.9609\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0370 - accuracy: 0.9590 - val_loss: 0.0337 - val_accuracy: 0.9629\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0354 - accuracy: 0.9590 - val_loss: 0.0377 - val_accuracy: 0.9473\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0409 - accuracy: 0.9434 - val_loss: 0.0330 - val_accuracy: 0.9590\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0366 - accuracy: 0.9590 - val_loss: 0.0295 - val_accuracy: 0.9629\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0359 - accuracy: 0.9590 - val_loss: 0.0299 - val_accuracy: 0.9629\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0346 - accuracy: 0.9590 - val_loss: 0.0288 - val_accuracy: 0.9648\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.0347 - accuracy: 0.9609 - val_loss: 0.0293 - val_accuracy: 0.9609\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0357 - accuracy: 0.9590 - val_loss: 0.0295 - val_accuracy: 0.9648\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0339 - accuracy: 0.9609 - val_loss: 0.0293 - val_accuracy: 0.9648\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0367 - accuracy: 0.9551 - val_loss: 0.0275 - val_accuracy: 0.9629\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0344 - accuracy: 0.9590 - val_loss: 0.0304 - val_accuracy: 0.9629\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0333 - accuracy: 0.9570 - val_loss: 0.0278 - val_accuracy: 0.9609\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.0318 - accuracy: 0.9609 - val_loss: 0.0269 - val_accuracy: 0.9688\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 0.0308 - accuracy: 0.9609 - val_loss: 0.0270 - val_accuracy: 0.9668\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 0.0315 - accuracy: 0.9609 - val_loss: 0.0264 - val_accuracy: 0.9688\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.0297 - accuracy: 0.9648 - val_loss: 0.0262 - val_accuracy: 0.9668\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.0318 - accuracy: 0.9609 - val_loss: 0.0271 - val_accuracy: 0.9648\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 95ms/step - loss: 0.0309 - accuracy: 0.9648 - val_loss: 0.0273 - val_accuracy: 0.9609\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0293 - accuracy: 0.9668 - val_loss: 0.0252 - val_accuracy: 0.9688\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0294 - accuracy: 0.9688 - val_loss: 0.0269 - val_accuracy: 0.9609\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0300 - accuracy: 0.9629 - val_loss: 0.0271 - val_accuracy: 0.9609\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 95ms/step - loss: 0.0305 - accuracy: 0.9590 - val_loss: 0.0245 - val_accuracy: 0.9688\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0297 - accuracy: 0.9570 - val_loss: 0.0255 - val_accuracy: 0.9648\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.0275 - accuracy: 0.9629 - val_loss: 0.0261 - val_accuracy: 0.9648\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.0298 - accuracy: 0.9609 - val_loss: 0.0263 - val_accuracy: 0.9609\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0311 - accuracy: 0.9609 - val_loss: 0.0248 - val_accuracy: 0.9668\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0298 - accuracy: 0.9648 - val_loss: 0.0242 - val_accuracy: 0.9688\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.0337 - accuracy: 0.9590 - val_loss: 0.0234 - val_accuracy: 0.9688\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 96ms/step - loss: 0.0309 - accuracy: 0.9629 - val_loss: 0.0282 - val_accuracy: 0.9629\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0313 - accuracy: 0.9668 - val_loss: 0.0229 - val_accuracy: 0.9668\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0292 - accuracy: 0.9648 - val_loss: 0.0256 - val_accuracy: 0.9629\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.0303 - accuracy: 0.9609 - val_loss: 0.0222 - val_accuracy: 0.9707\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 95ms/step - loss: 0.0276 - accuracy: 0.9648 - val_loss: 0.0221 - val_accuracy: 0.9688\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0268 - accuracy: 0.9688 - val_loss: 0.0208 - val_accuracy: 0.9688\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0291 - accuracy: 0.9590 - val_loss: 0.0241 - val_accuracy: 0.9707\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.0323 - accuracy: 0.9688 - val_loss: 0.0258 - val_accuracy: 0.9668\n",
      "2/2 [==============================] - 2s 19ms/step\n",
      "GRU\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 8s 179ms/step - loss: 0.1577 - accuracy: 0.8184 - val_loss: 0.0860 - val_accuracy: 0.9004\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0913 - accuracy: 0.9043 - val_loss: 0.0826 - val_accuracy: 0.9160\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.0865 - accuracy: 0.9062 - val_loss: 0.0756 - val_accuracy: 0.9121\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0775 - accuracy: 0.9238 - val_loss: 0.0724 - val_accuracy: 0.9160\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0774 - accuracy: 0.9180 - val_loss: 0.0687 - val_accuracy: 0.9316\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0715 - accuracy: 0.9395 - val_loss: 0.0627 - val_accuracy: 0.9473\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0674 - accuracy: 0.9336 - val_loss: 0.0580 - val_accuracy: 0.9473\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0634 - accuracy: 0.9434 - val_loss: 0.0551 - val_accuracy: 0.9570\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0611 - accuracy: 0.9434 - val_loss: 0.0519 - val_accuracy: 0.9531\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0551 - accuracy: 0.9551 - val_loss: 0.0484 - val_accuracy: 0.9629\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0519 - accuracy: 0.9609 - val_loss: 0.0509 - val_accuracy: 0.9473\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0551 - accuracy: 0.9512 - val_loss: 0.0444 - val_accuracy: 0.9668\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0491 - accuracy: 0.9590 - val_loss: 0.0386 - val_accuracy: 0.9648\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0475 - accuracy: 0.9570 - val_loss: 0.0371 - val_accuracy: 0.9648\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0438 - accuracy: 0.9590 - val_loss: 0.0355 - val_accuracy: 0.9609\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.0478 - accuracy: 0.9492 - val_loss: 0.0358 - val_accuracy: 0.9648\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0412 - accuracy: 0.9648 - val_loss: 0.0318 - val_accuracy: 0.9629\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0425 - accuracy: 0.9648 - val_loss: 0.0341 - val_accuracy: 0.9648\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0398 - accuracy: 0.9590 - val_loss: 0.0288 - val_accuracy: 0.9648\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.0360 - accuracy: 0.9648 - val_loss: 0.0288 - val_accuracy: 0.9590\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.0359 - accuracy: 0.9609 - val_loss: 0.0272 - val_accuracy: 0.9707\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0355 - accuracy: 0.9648 - val_loss: 0.0282 - val_accuracy: 0.9648\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0336 - accuracy: 0.9629 - val_loss: 0.0280 - val_accuracy: 0.9727\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.0361 - accuracy: 0.9668 - val_loss: 0.0257 - val_accuracy: 0.9668\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0313 - accuracy: 0.9590 - val_loss: 0.0253 - val_accuracy: 0.9668\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0285 - accuracy: 0.9707 - val_loss: 0.0243 - val_accuracy: 0.9688\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0325 - accuracy: 0.9707 - val_loss: 0.0264 - val_accuracy: 0.9746\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0305 - accuracy: 0.9668 - val_loss: 0.0265 - val_accuracy: 0.9688\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0315 - accuracy: 0.9688 - val_loss: 0.0242 - val_accuracy: 0.9707\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0272 - accuracy: 0.9727 - val_loss: 0.0228 - val_accuracy: 0.9746\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0307 - accuracy: 0.9629 - val_loss: 0.0222 - val_accuracy: 0.9727\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0300 - accuracy: 0.9727 - val_loss: 0.0236 - val_accuracy: 0.9707\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0299 - accuracy: 0.9707 - val_loss: 0.0226 - val_accuracy: 0.9727\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0293 - accuracy: 0.9668 - val_loss: 0.0228 - val_accuracy: 0.9727\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0308 - accuracy: 0.9629 - val_loss: 0.0214 - val_accuracy: 0.9746\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.0303 - accuracy: 0.9688 - val_loss: 0.0222 - val_accuracy: 0.9746\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0298 - accuracy: 0.9629 - val_loss: 0.0210 - val_accuracy: 0.9727\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0290 - accuracy: 0.9727 - val_loss: 0.0222 - val_accuracy: 0.9727\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0267 - accuracy: 0.9727 - val_loss: 0.0202 - val_accuracy: 0.9727\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0278 - accuracy: 0.9707 - val_loss: 0.0209 - val_accuracy: 0.9727\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0268 - accuracy: 0.9727 - val_loss: 0.0199 - val_accuracy: 0.9766\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0273 - accuracy: 0.9727 - val_loss: 0.0235 - val_accuracy: 0.9707\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0285 - accuracy: 0.9688 - val_loss: 0.0212 - val_accuracy: 0.9746\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0268 - accuracy: 0.9707 - val_loss: 0.0201 - val_accuracy: 0.9727\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0252 - accuracy: 0.9766 - val_loss: 0.0197 - val_accuracy: 0.9746\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0257 - accuracy: 0.9746 - val_loss: 0.0197 - val_accuracy: 0.9766\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0259 - accuracy: 0.9707 - val_loss: 0.0190 - val_accuracy: 0.9746\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0238 - accuracy: 0.9746 - val_loss: 0.0188 - val_accuracy: 0.9727\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0249 - accuracy: 0.9688 - val_loss: 0.0191 - val_accuracy: 0.9766\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0260 - accuracy: 0.9766 - val_loss: 0.0187 - val_accuracy: 0.9746\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0227 - accuracy: 0.9746 - val_loss: 0.0193 - val_accuracy: 0.9766\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0256 - accuracy: 0.9707 - val_loss: 0.0179 - val_accuracy: 0.9766\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0229 - accuracy: 0.9746 - val_loss: 0.0182 - val_accuracy: 0.9727\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0234 - accuracy: 0.9766 - val_loss: 0.0177 - val_accuracy: 0.9785\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0234 - accuracy: 0.9766 - val_loss: 0.0168 - val_accuracy: 0.9766\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0211 - accuracy: 0.9805 - val_loss: 0.0171 - val_accuracy: 0.9766\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0256 - accuracy: 0.9727 - val_loss: 0.0164 - val_accuracy: 0.9766\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0215 - accuracy: 0.9746 - val_loss: 0.0156 - val_accuracy: 0.9766\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0219 - accuracy: 0.9746 - val_loss: 0.0152 - val_accuracy: 0.9766\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0208 - accuracy: 0.9766 - val_loss: 0.0145 - val_accuracy: 0.9844\n",
      "2/2 [==============================] - 1s 14ms/step\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   4\n",
      "CNN\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 3s 48ms/step - loss: 0.5823 - accuracy: 0.7188 - val_loss: 0.6173 - val_accuracy: 0.9004\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4119 - accuracy: 0.8242 - val_loss: 0.5662 - val_accuracy: 0.9316\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3411 - accuracy: 0.8809 - val_loss: 0.5212 - val_accuracy: 0.9375\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.2619 - accuracy: 0.9023 - val_loss: 0.4775 - val_accuracy: 0.9336\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.2391 - accuracy: 0.9180 - val_loss: 0.4398 - val_accuracy: 0.9316\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.2275 - accuracy: 0.9102 - val_loss: 0.4061 - val_accuracy: 0.9316\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1942 - accuracy: 0.9121 - val_loss: 0.3726 - val_accuracy: 0.9316\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1784 - accuracy: 0.9258 - val_loss: 0.3421 - val_accuracy: 0.9336\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1893 - accuracy: 0.9277 - val_loss: 0.3133 - val_accuracy: 0.9336\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.1568 - accuracy: 0.9238 - val_loss: 0.2839 - val_accuracy: 0.9336\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.1860 - accuracy: 0.9258 - val_loss: 0.2598 - val_accuracy: 0.9375\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.1380 - accuracy: 0.9355 - val_loss: 0.2368 - val_accuracy: 0.9375\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1406 - accuracy: 0.9512 - val_loss: 0.2160 - val_accuracy: 0.9375\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1293 - accuracy: 0.9551 - val_loss: 0.1957 - val_accuracy: 0.9434\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1601 - accuracy: 0.9336 - val_loss: 0.1777 - val_accuracy: 0.9453\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.1155 - accuracy: 0.9570 - val_loss: 0.1612 - val_accuracy: 0.9512\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.1380 - accuracy: 0.9590 - val_loss: 0.1466 - val_accuracy: 0.9570\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.1095 - accuracy: 0.9609 - val_loss: 0.1351 - val_accuracy: 0.9570\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1122 - accuracy: 0.9629 - val_loss: 0.1251 - val_accuracy: 0.9629\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.1319 - accuracy: 0.9473 - val_loss: 0.1176 - val_accuracy: 0.9629\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1031 - accuracy: 0.9668 - val_loss: 0.1089 - val_accuracy: 0.9629\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1102 - accuracy: 0.9570 - val_loss: 0.1009 - val_accuracy: 0.9668\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1229 - accuracy: 0.9531 - val_loss: 0.0944 - val_accuracy: 0.9688\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 32ms/step - loss: 0.1331 - accuracy: 0.9551 - val_loss: 0.0885 - val_accuracy: 0.9727\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.0863 - accuracy: 0.9688 - val_loss: 0.0828 - val_accuracy: 0.9727\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1142 - accuracy: 0.9512 - val_loss: 0.0788 - val_accuracy: 0.9766\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1023 - accuracy: 0.9609 - val_loss: 0.0750 - val_accuracy: 0.9766\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1096 - accuracy: 0.9570 - val_loss: 0.0711 - val_accuracy: 0.9785\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1007 - accuracy: 0.9570 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1154 - accuracy: 0.9551 - val_loss: 0.0653 - val_accuracy: 0.9785\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0867 - accuracy: 0.9629 - val_loss: 0.0623 - val_accuracy: 0.9785\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1151 - accuracy: 0.9648 - val_loss: 0.0596 - val_accuracy: 0.9824\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1140 - accuracy: 0.9570 - val_loss: 0.0581 - val_accuracy: 0.9824\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0982 - accuracy: 0.9688 - val_loss: 0.0565 - val_accuracy: 0.9844\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0818 - accuracy: 0.9688 - val_loss: 0.0550 - val_accuracy: 0.9844\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0726 - accuracy: 0.9766 - val_loss: 0.0531 - val_accuracy: 0.9844\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0952 - accuracy: 0.9570 - val_loss: 0.0517 - val_accuracy: 0.9844\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0702 - accuracy: 0.9746 - val_loss: 0.0503 - val_accuracy: 0.9844\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0996 - accuracy: 0.9551 - val_loss: 0.0496 - val_accuracy: 0.9863\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0956 - accuracy: 0.9668 - val_loss: 0.0484 - val_accuracy: 0.9883\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0788 - accuracy: 0.9766 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0797 - accuracy: 0.9746 - val_loss: 0.0456 - val_accuracy: 0.9883\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0710 - accuracy: 0.9707 - val_loss: 0.0444 - val_accuracy: 0.9883\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0969 - accuracy: 0.9648 - val_loss: 0.0437 - val_accuracy: 0.9883\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0743 - accuracy: 0.9785 - val_loss: 0.0431 - val_accuracy: 0.9883\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0699 - accuracy: 0.9746 - val_loss: 0.0423 - val_accuracy: 0.9883\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.0816 - accuracy: 0.9668 - val_loss: 0.0415 - val_accuracy: 0.9883\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0845 - accuracy: 0.9746 - val_loss: 0.0407 - val_accuracy: 0.9883\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0875 - accuracy: 0.9629 - val_loss: 0.0400 - val_accuracy: 0.9883\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0740 - accuracy: 0.9746 - val_loss: 0.0395 - val_accuracy: 0.9883\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0817 - accuracy: 0.9648 - val_loss: 0.0390 - val_accuracy: 0.9883\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0720 - accuracy: 0.9707 - val_loss: 0.0387 - val_accuracy: 0.9883\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0671 - accuracy: 0.9805 - val_loss: 0.0385 - val_accuracy: 0.9883\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.0827 - accuracy: 0.9668 - val_loss: 0.0379 - val_accuracy: 0.9883\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0711 - accuracy: 0.9766 - val_loss: 0.0378 - val_accuracy: 0.9902\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0786 - accuracy: 0.9688 - val_loss: 0.0366 - val_accuracy: 0.9902\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0686 - accuracy: 0.9746 - val_loss: 0.0360 - val_accuracy: 0.9902\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0630 - accuracy: 0.9844 - val_loss: 0.0353 - val_accuracy: 0.9902\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0678 - accuracy: 0.9766 - val_loss: 0.0347 - val_accuracy: 0.9902\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "RNN\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_23_input'), name='dense_23_input', description=\"created by layer 'dense_23_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_23_input'), name='dense_23_input', description=\"created by layer 'dense_23_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9238WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_23_input'), name='dense_23_input', description=\"created by layer 'dense_23_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "103/103 [==============================] - 2s 9ms/step - loss: 0.2071 - accuracy: 0.9238 - val_loss: 0.0856 - val_accuracy: 0.9707\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0828 - accuracy: 0.9727 - val_loss: 0.0556 - val_accuracy: 0.9883\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0646 - accuracy: 0.9785 - val_loss: 0.0453 - val_accuracy: 0.9824\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 0.0359 - val_accuracy: 0.9902\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 0.0319 - val_accuracy: 0.9922\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9922 - val_loss: 0.0268 - val_accuracy: 0.9922\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 0.0224 - val_accuracy: 0.9941\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.0172 - val_accuracy: 0.9941\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.0229 - accuracy: 0.9961 - val_loss: 0.0162 - val_accuracy: 0.9902\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0172 - val_accuracy: 0.9941\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 0.9902 - val_loss: 0.0107 - val_accuracy: 0.9980\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0624 - accuracy: 0.9844 - val_loss: 0.0519 - val_accuracy: 0.9863\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.0144 - val_accuracy: 0.9941\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0080 - val_accuracy: 0.9961\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.0111 - accuracy: 0.9941 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.0131 - val_accuracy: 0.9980\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 0.9941 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.0106 - accuracy: 0.9922 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 9.1899e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.5469e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.8925e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.4871e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 6.5262e-04 - accuracy: 1.0000 - val_loss: 4.7965e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9980\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.7632e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 9.1994e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 9.4378e-04 - accuracy: 1.0000 - val_loss: 3.8300e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 6.2379e-04 - accuracy: 1.0000 - val_loss: 3.2904e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.1874e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 8.3289e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0476 - accuracy: 0.9922 - val_loss: 0.0031 - val_accuracy: 0.9980\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0154 - accuracy: 0.9980 - val_loss: 0.0213 - val_accuracy: 0.9941\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9902 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9961 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 8.4943e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 7.0504e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.3139e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: 0.0077 - val_accuracy: 0.9961\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.5863e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8789e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3584e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 6.3556e-04 - accuracy: 1.0000 - val_loss: 4.2173e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 4.2823e-04 - accuracy: 1.0000 - val_loss: 2.0461e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.4129e-04 - accuracy: 1.0000 - val_loss: 1.8967e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 2.6535e-04 - accuracy: 1.0000 - val_loss: 1.7962e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 4.8224e-04 - accuracy: 1.0000 - val_loss: 1.5849e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 4.4183e-04 - accuracy: 1.0000 - val_loss: 1.5730e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_23_input'), name='dense_23_input', description=\"created by layer 'dense_23_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 18s 487ms/step - loss: 0.1671 - accuracy: 0.8086 - val_loss: 0.1398 - val_accuracy: 0.7988\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 5s 327ms/step - loss: 0.1212 - accuracy: 0.8457 - val_loss: 0.1016 - val_accuracy: 0.8828\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.1014 - accuracy: 0.8809 - val_loss: 0.0817 - val_accuracy: 0.8945\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.0706 - accuracy: 0.9160 - val_loss: 0.0515 - val_accuracy: 0.9355\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 5s 296ms/step - loss: 0.0633 - accuracy: 0.9414 - val_loss: 0.0521 - val_accuracy: 0.9297\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 0.0632 - accuracy: 0.9238 - val_loss: 0.0472 - val_accuracy: 0.9434\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 0.0569 - accuracy: 0.9316 - val_loss: 0.0453 - val_accuracy: 0.9414\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.0536 - accuracy: 0.9414 - val_loss: 0.0458 - val_accuracy: 0.9395\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 5s 319ms/step - loss: 0.0507 - accuracy: 0.9434 - val_loss: 0.0423 - val_accuracy: 0.9395\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.0535 - accuracy: 0.9316 - val_loss: 0.0431 - val_accuracy: 0.9414\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 0.0506 - accuracy: 0.9375 - val_loss: 0.0414 - val_accuracy: 0.9414\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.0499 - accuracy: 0.9395 - val_loss: 0.0400 - val_accuracy: 0.9414\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 5s 290ms/step - loss: 0.0493 - accuracy: 0.9355 - val_loss: 0.0404 - val_accuracy: 0.9395\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 4s 258ms/step - loss: 0.0454 - accuracy: 0.9414 - val_loss: 0.0401 - val_accuracy: 0.9375\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 5s 313ms/step - loss: 0.0428 - accuracy: 0.9434 - val_loss: 0.0388 - val_accuracy: 0.9434\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 3s 220ms/step - loss: 0.0472 - accuracy: 0.9395 - val_loss: 0.0399 - val_accuracy: 0.9473\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 4s 274ms/step - loss: 0.0463 - accuracy: 0.9473 - val_loss: 0.0392 - val_accuracy: 0.9453\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.0466 - accuracy: 0.9473 - val_loss: 0.0438 - val_accuracy: 0.9492\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 5s 327ms/step - loss: 0.0494 - accuracy: 0.9434 - val_loss: 0.0404 - val_accuracy: 0.9414\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.0453 - accuracy: 0.9473 - val_loss: 0.0387 - val_accuracy: 0.9492\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 5s 299ms/step - loss: 0.0459 - accuracy: 0.9434 - val_loss: 0.0414 - val_accuracy: 0.9414\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 0.0460 - accuracy: 0.9473 - val_loss: 0.0393 - val_accuracy: 0.9492\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 5s 298ms/step - loss: 0.0433 - accuracy: 0.9473 - val_loss: 0.0355 - val_accuracy: 0.9590\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.0422 - accuracy: 0.9512 - val_loss: 0.0413 - val_accuracy: 0.9512\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 5s 297ms/step - loss: 0.0448 - accuracy: 0.9453 - val_loss: 0.0400 - val_accuracy: 0.9531\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 4s 281ms/step - loss: 0.0405 - accuracy: 0.9570 - val_loss: 0.0331 - val_accuracy: 0.9512\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.0366 - accuracy: 0.9551 - val_loss: 0.0324 - val_accuracy: 0.9551\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.0381 - accuracy: 0.9531 - val_loss: 0.0335 - val_accuracy: 0.9570\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.0373 - accuracy: 0.9492 - val_loss: 0.0314 - val_accuracy: 0.9590\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.0374 - accuracy: 0.9551 - val_loss: 0.0452 - val_accuracy: 0.9375\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.0404 - accuracy: 0.9492 - val_loss: 0.0360 - val_accuracy: 0.9570\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.0343 - accuracy: 0.9688 - val_loss: 0.0333 - val_accuracy: 0.9492\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.0399 - accuracy: 0.9473 - val_loss: 0.0353 - val_accuracy: 0.9531\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.0455 - accuracy: 0.9512 - val_loss: 0.0333 - val_accuracy: 0.9512\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 4s 284ms/step - loss: 0.0373 - accuracy: 0.9590 - val_loss: 0.0316 - val_accuracy: 0.9590\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 4s 274ms/step - loss: 0.0349 - accuracy: 0.9551 - val_loss: 0.0344 - val_accuracy: 0.9570\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.0418 - accuracy: 0.9531 - val_loss: 0.0327 - val_accuracy: 0.9609\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.0378 - accuracy: 0.9551 - val_loss: 0.0289 - val_accuracy: 0.9570\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 0.0362 - accuracy: 0.9609 - val_loss: 0.0345 - val_accuracy: 0.9551\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 5s 303ms/step - loss: 0.0397 - accuracy: 0.9473 - val_loss: 0.0293 - val_accuracy: 0.9590\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.0336 - accuracy: 0.9590 - val_loss: 0.0290 - val_accuracy: 0.9629\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.0355 - accuracy: 0.9531 - val_loss: 0.0270 - val_accuracy: 0.9590\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.0325 - accuracy: 0.9629 - val_loss: 0.0272 - val_accuracy: 0.9629\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.0339 - accuracy: 0.9570 - val_loss: 0.0276 - val_accuracy: 0.9629\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.0331 - accuracy: 0.9570 - val_loss: 0.0260 - val_accuracy: 0.9629\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0326 - accuracy: 0.9570 - val_loss: 0.0246 - val_accuracy: 0.9648\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.0323 - accuracy: 0.9570 - val_loss: 0.0267 - val_accuracy: 0.9609\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0306 - accuracy: 0.9590 - val_loss: 0.0248 - val_accuracy: 0.9648\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.0290 - accuracy: 0.9609 - val_loss: 0.0241 - val_accuracy: 0.9629\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0295 - accuracy: 0.9570 - val_loss: 0.0240 - val_accuracy: 0.9668\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0305 - accuracy: 0.9609 - val_loss: 0.0256 - val_accuracy: 0.9629\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.0303 - accuracy: 0.9648 - val_loss: 0.0235 - val_accuracy: 0.9648\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.0318 - accuracy: 0.9590 - val_loss: 0.0244 - val_accuracy: 0.9648\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.0263 - accuracy: 0.9707 - val_loss: 0.0272 - val_accuracy: 0.9688\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 3s 224ms/step - loss: 0.0299 - accuracy: 0.9648 - val_loss: 0.0300 - val_accuracy: 0.9629\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 3s 211ms/step - loss: 0.0386 - accuracy: 0.9590 - val_loss: 0.0267 - val_accuracy: 0.9688\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 2s 157ms/step - loss: 0.0302 - accuracy: 0.9629 - val_loss: 0.0255 - val_accuracy: 0.9668\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 0.0324 - accuracy: 0.9648 - val_loss: 0.0332 - val_accuracy: 0.9629\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.0346 - accuracy: 0.9590 - val_loss: 0.0240 - val_accuracy: 0.9668\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 3s 211ms/step - loss: 0.0256 - accuracy: 0.9707 - val_loss: 0.0253 - val_accuracy: 0.9668\n",
      "2/2 [==============================] - 3s 40ms/step\n",
      "GRU\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 16s 362ms/step - loss: 0.1416 - accuracy: 0.8359 - val_loss: 0.0916 - val_accuracy: 0.9102\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 2s 158ms/step - loss: 0.0973 - accuracy: 0.9004 - val_loss: 0.0879 - val_accuracy: 0.9121\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.0887 - accuracy: 0.9062 - val_loss: 0.0784 - val_accuracy: 0.9219\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.0820 - accuracy: 0.9180 - val_loss: 0.0730 - val_accuracy: 0.9277\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0753 - accuracy: 0.9199 - val_loss: 0.0683 - val_accuracy: 0.9355\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.0765 - accuracy: 0.9297 - val_loss: 0.0650 - val_accuracy: 0.9375\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.0690 - accuracy: 0.9375 - val_loss: 0.0592 - val_accuracy: 0.9590\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.0698 - accuracy: 0.9434 - val_loss: 0.0594 - val_accuracy: 0.9434\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.0666 - accuracy: 0.9395 - val_loss: 0.0542 - val_accuracy: 0.9473\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0591 - accuracy: 0.9434 - val_loss: 0.0499 - val_accuracy: 0.9609\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.0542 - accuracy: 0.9531 - val_loss: 0.0454 - val_accuracy: 0.9609\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.0554 - accuracy: 0.9551 - val_loss: 0.0420 - val_accuracy: 0.9609\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0517 - accuracy: 0.9590 - val_loss: 0.0447 - val_accuracy: 0.9590\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0477 - accuracy: 0.9551 - val_loss: 0.0425 - val_accuracy: 0.9570\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.0476 - accuracy: 0.9531 - val_loss: 0.0357 - val_accuracy: 0.9609\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.0424 - accuracy: 0.9609 - val_loss: 0.0392 - val_accuracy: 0.9551\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.0439 - accuracy: 0.9570 - val_loss: 0.0321 - val_accuracy: 0.9629\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0405 - accuracy: 0.9648 - val_loss: 0.0310 - val_accuracy: 0.9668\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0412 - accuracy: 0.9609 - val_loss: 0.0344 - val_accuracy: 0.9590\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.0401 - accuracy: 0.9609 - val_loss: 0.0300 - val_accuracy: 0.9668\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.0388 - accuracy: 0.9688 - val_loss: 0.0302 - val_accuracy: 0.9668\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0372 - accuracy: 0.9648 - val_loss: 0.0290 - val_accuracy: 0.9688\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.0374 - accuracy: 0.9609 - val_loss: 0.0295 - val_accuracy: 0.9688\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.0389 - accuracy: 0.9629 - val_loss: 0.0335 - val_accuracy: 0.9668\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0431 - accuracy: 0.9648 - val_loss: 0.0292 - val_accuracy: 0.9668\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.0399 - accuracy: 0.9609 - val_loss: 0.0272 - val_accuracy: 0.9648\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 0.0330 - accuracy: 0.9668 - val_loss: 0.0270 - val_accuracy: 0.9688\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 0.0324 - accuracy: 0.9707 - val_loss: 0.0261 - val_accuracy: 0.9707\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.0332 - accuracy: 0.9668 - val_loss: 0.0257 - val_accuracy: 0.9727\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.0346 - accuracy: 0.9707 - val_loss: 0.0269 - val_accuracy: 0.9707\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.0337 - accuracy: 0.9629 - val_loss: 0.0267 - val_accuracy: 0.9648\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 0.0319 - accuracy: 0.9668 - val_loss: 0.0262 - val_accuracy: 0.9688\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.0313 - accuracy: 0.9629 - val_loss: 0.0254 - val_accuracy: 0.9648\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.0303 - accuracy: 0.9668 - val_loss: 0.0250 - val_accuracy: 0.9688\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.0306 - accuracy: 0.9648 - val_loss: 0.0255 - val_accuracy: 0.9707\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 0.0297 - accuracy: 0.9727 - val_loss: 0.0257 - val_accuracy: 0.9668\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 4s 279ms/step - loss: 0.0313 - accuracy: 0.9629 - val_loss: 0.0237 - val_accuracy: 0.9707\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.0300 - accuracy: 0.9648 - val_loss: 0.0231 - val_accuracy: 0.9727\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.0300 - accuracy: 0.9727 - val_loss: 0.0231 - val_accuracy: 0.9727\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.0292 - accuracy: 0.9668 - val_loss: 0.0232 - val_accuracy: 0.9727\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.0299 - accuracy: 0.9707 - val_loss: 0.0231 - val_accuracy: 0.9727\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 0.0282 - accuracy: 0.9688 - val_loss: 0.0222 - val_accuracy: 0.9746\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.0266 - accuracy: 0.9746 - val_loss: 0.0222 - val_accuracy: 0.9707\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 0.0309 - accuracy: 0.9668 - val_loss: 0.0226 - val_accuracy: 0.9727\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.0286 - accuracy: 0.9668 - val_loss: 0.0227 - val_accuracy: 0.9707\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.0286 - accuracy: 0.9688 - val_loss: 0.0220 - val_accuracy: 0.9707\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.0267 - accuracy: 0.9688 - val_loss: 0.0215 - val_accuracy: 0.9727\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 0.0287 - accuracy: 0.9688 - val_loss: 0.0218 - val_accuracy: 0.9707\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.0261 - accuracy: 0.9688 - val_loss: 0.0228 - val_accuracy: 0.9688\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.0314 - accuracy: 0.9648 - val_loss: 0.0234 - val_accuracy: 0.9727\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0298 - accuracy: 0.9688 - val_loss: 0.0212 - val_accuracy: 0.9727\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.0259 - accuracy: 0.9746 - val_loss: 0.0209 - val_accuracy: 0.9727\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.0279 - accuracy: 0.9648 - val_loss: 0.0249 - val_accuracy: 0.9727\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.0280 - accuracy: 0.9707 - val_loss: 0.0206 - val_accuracy: 0.9727\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.0254 - accuracy: 0.9746 - val_loss: 0.0201 - val_accuracy: 0.9727\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 4s 288ms/step - loss: 0.0272 - accuracy: 0.9668 - val_loss: 0.0214 - val_accuracy: 0.9727\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.0265 - accuracy: 0.9746 - val_loss: 0.0196 - val_accuracy: 0.9746\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 0.0299 - accuracy: 0.9629 - val_loss: 0.0216 - val_accuracy: 0.9727\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.0284 - accuracy: 0.9746 - val_loss: 0.0197 - val_accuracy: 0.9727\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 4s 227ms/step - loss: 0.0244 - accuracy: 0.9766 - val_loss: 0.0196 - val_accuracy: 0.9707\n",
      "2/2 [==============================] - 3s 47ms/step\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   5\n",
      "CNN\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 4s 54ms/step - loss: 0.7939 - accuracy: 0.6250 - val_loss: 0.6396 - val_accuracy: 0.7988\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4725 - accuracy: 0.7598 - val_loss: 0.5857 - val_accuracy: 0.8867\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.3340 - accuracy: 0.8574 - val_loss: 0.5390 - val_accuracy: 0.9043\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3160 - accuracy: 0.8633 - val_loss: 0.4937 - val_accuracy: 0.9102\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2447 - accuracy: 0.9004 - val_loss: 0.4539 - val_accuracy: 0.9082\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2312 - accuracy: 0.9102 - val_loss: 0.4138 - val_accuracy: 0.9121\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2065 - accuracy: 0.9219 - val_loss: 0.3746 - val_accuracy: 0.9180\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 33ms/step - loss: 0.1860 - accuracy: 0.9375 - val_loss: 0.3389 - val_accuracy: 0.9199\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.1793 - accuracy: 0.9434 - val_loss: 0.3048 - val_accuracy: 0.9277\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1904 - accuracy: 0.9277 - val_loss: 0.2724 - val_accuracy: 0.9375\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1721 - accuracy: 0.9199 - val_loss: 0.2417 - val_accuracy: 0.9395\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1571 - accuracy: 0.9375 - val_loss: 0.2160 - val_accuracy: 0.9414\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1079 - accuracy: 0.9570 - val_loss: 0.1938 - val_accuracy: 0.9434\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.1324 - accuracy: 0.9434 - val_loss: 0.1742 - val_accuracy: 0.9473\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.1052 - accuracy: 0.9551 - val_loss: 0.1577 - val_accuracy: 0.9531\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1288 - accuracy: 0.9453 - val_loss: 0.1419 - val_accuracy: 0.9551\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.1306 - accuracy: 0.9453 - val_loss: 0.1277 - val_accuracy: 0.9590\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0925 - accuracy: 0.9688 - val_loss: 0.1164 - val_accuracy: 0.9590\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.1283 - accuracy: 0.9473 - val_loss: 0.1067 - val_accuracy: 0.9590\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.1091 - accuracy: 0.9609 - val_loss: 0.0982 - val_accuracy: 0.9570\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1136 - accuracy: 0.9590 - val_loss: 0.0896 - val_accuracy: 0.9648\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1113 - accuracy: 0.9570 - val_loss: 0.0834 - val_accuracy: 0.9707\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1101 - accuracy: 0.9570 - val_loss: 0.0771 - val_accuracy: 0.9746\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0861 - accuracy: 0.9766 - val_loss: 0.0717 - val_accuracy: 0.9785\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.1179 - accuracy: 0.9512 - val_loss: 0.0661 - val_accuracy: 0.9824\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.1218 - accuracy: 0.9414 - val_loss: 0.0616 - val_accuracy: 0.9844\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0931 - accuracy: 0.9727 - val_loss: 0.0584 - val_accuracy: 0.9844\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0729 - accuracy: 0.9746 - val_loss: 0.0548 - val_accuracy: 0.9863\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0884 - accuracy: 0.9551 - val_loss: 0.0518 - val_accuracy: 0.9863\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0828 - accuracy: 0.9727 - val_loss: 0.0497 - val_accuracy: 0.9883\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0794 - accuracy: 0.9629 - val_loss: 0.0478 - val_accuracy: 0.9883\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1150 - accuracy: 0.9609 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0684 - accuracy: 0.9746 - val_loss: 0.0441 - val_accuracy: 0.9883\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0725 - accuracy: 0.9629 - val_loss: 0.0428 - val_accuracy: 0.9883\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.1022 - accuracy: 0.9551 - val_loss: 0.0417 - val_accuracy: 0.9883\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 0.0399 - val_accuracy: 0.9883\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0883 - accuracy: 0.9727 - val_loss: 0.0385 - val_accuracy: 0.9883\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0873 - accuracy: 0.9609 - val_loss: 0.0376 - val_accuracy: 0.9883\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0772 - accuracy: 0.9668 - val_loss: 0.0368 - val_accuracy: 0.9883\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0649 - accuracy: 0.9785 - val_loss: 0.0360 - val_accuracy: 0.9883\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0799 - accuracy: 0.9766 - val_loss: 0.0354 - val_accuracy: 0.9883\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0625 - accuracy: 0.9785 - val_loss: 0.0350 - val_accuracy: 0.9883\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0693 - accuracy: 0.9766 - val_loss: 0.0339 - val_accuracy: 0.9883\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0651 - accuracy: 0.9727 - val_loss: 0.0332 - val_accuracy: 0.9883\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0737 - accuracy: 0.9707 - val_loss: 0.0326 - val_accuracy: 0.9902\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.0535 - accuracy: 0.9766 - val_loss: 0.0320 - val_accuracy: 0.9902\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0613 - accuracy: 0.9785 - val_loss: 0.0314 - val_accuracy: 0.9902\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.0304 - val_accuracy: 0.9902\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0882 - accuracy: 0.9531 - val_loss: 0.0296 - val_accuracy: 0.9902\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0636 - accuracy: 0.9766 - val_loss: 0.0291 - val_accuracy: 0.9902\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0658 - accuracy: 0.9688 - val_loss: 0.0289 - val_accuracy: 0.9883\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0700 - accuracy: 0.9727 - val_loss: 0.0290 - val_accuracy: 0.9883\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0699 - accuracy: 0.9766 - val_loss: 0.0280 - val_accuracy: 0.9883\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0554 - accuracy: 0.9785 - val_loss: 0.0273 - val_accuracy: 0.9902\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0546 - accuracy: 0.9844 - val_loss: 0.0268 - val_accuracy: 0.9902\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0437 - accuracy: 0.9863 - val_loss: 0.0263 - val_accuracy: 0.9922\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0469 - accuracy: 0.9805 - val_loss: 0.0257 - val_accuracy: 0.9922\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0416 - accuracy: 0.9883 - val_loss: 0.0252 - val_accuracy: 0.9922\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0440 - accuracy: 0.9844 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0567 - accuracy: 0.9805 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "RNN\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_30_input'), name='dense_30_input', description=\"created by layer 'dense_30_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_30_input'), name='dense_30_input', description=\"created by layer 'dense_30_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      " 97/103 [===========================>..] - ETA: 0s - loss: 0.1989 - accuracy: 0.9216WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_30_input'), name='dense_30_input', description=\"created by layer 'dense_30_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "103/103 [==============================] - 2s 8ms/step - loss: 0.1921 - accuracy: 0.9258 - val_loss: 0.0701 - val_accuracy: 0.9824\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0633 - accuracy: 0.9844 - val_loss: 0.0475 - val_accuracy: 0.9902\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.0483 - accuracy: 0.9863 - val_loss: 0.0343 - val_accuracy: 0.9902\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9902 - val_loss: 0.0277 - val_accuracy: 0.9922\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 0.0204 - val_accuracy: 0.9961\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9961 - val_loss: 0.0146 - val_accuracy: 0.9961\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0164 - val_accuracy: 0.9941\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0153 - accuracy: 0.9941 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0169 - accuracy: 0.9961 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0536 - accuracy: 0.9844 - val_loss: 0.0127 - val_accuracy: 0.9980\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.0069 - val_accuracy: 0.9980\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.0049 - val_accuracy: 0.9980\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0181 - accuracy: 0.9922 - val_loss: 0.0040 - val_accuracy: 0.9980\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 9.0659e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.1025e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0414 - val_accuracy: 0.9902\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9961 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9980\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.8922e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.9148e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.4255e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.3917e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 7.5831e-04 - accuracy: 1.0000 - val_loss: 3.5088e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 5.5747e-04 - accuracy: 1.0000 - val_loss: 3.0197e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 3.1796e-04 - accuracy: 1.0000 - val_loss: 2.7891e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 4.2662e-04 - accuracy: 1.0000 - val_loss: 2.4180e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 8.9500e-04 - accuracy: 1.0000 - val_loss: 5.7438e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 5.0117e-04 - accuracy: 1.0000 - val_loss: 2.7154e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.7085e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 4.3288e-04 - accuracy: 1.0000 - val_loss: 1.6634e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 3.2781e-04 - accuracy: 1.0000 - val_loss: 1.5773e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 4.9303e-04 - accuracy: 1.0000 - val_loss: 1.8278e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 3.5159e-04 - accuracy: 1.0000 - val_loss: 1.3812e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0191 - accuracy: 0.9922 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9883 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 6.4669e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 7.7582e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 7.2072e-04 - accuracy: 1.0000 - val_loss: 5.5511e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 6.6836e-04 - accuracy: 1.0000 - val_loss: 4.5913e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 6.8494e-04 - accuracy: 1.0000 - val_loss: 3.4467e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 4.7227e-04 - accuracy: 1.0000 - val_loss: 3.0259e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 6.8188e-04 - accuracy: 1.0000 - val_loss: 2.7481e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 6.6886e-04 - accuracy: 1.0000 - val_loss: 2.4896e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 4.8218e-04 - accuracy: 1.0000 - val_loss: 2.2835e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 3.9875e-04 - accuracy: 1.0000 - val_loss: 2.1788e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 3.0249e-04 - accuracy: 1.0000 - val_loss: 1.7880e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 4.0370e-04 - accuracy: 1.0000 - val_loss: 1.8301e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 1s 9ms/step - loss: 5.8757e-04 - accuracy: 1.0000 - val_loss: 1.5103e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_30_input'), name='dense_30_input', description=\"created by layer 'dense_30_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 19s 454ms/step - loss: 0.1822 - accuracy: 0.7891 - val_loss: 0.1210 - val_accuracy: 0.8418\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.1181 - accuracy: 0.8516 - val_loss: 0.0971 - val_accuracy: 0.8809\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 4s 260ms/step - loss: 0.1014 - accuracy: 0.8691 - val_loss: 0.0815 - val_accuracy: 0.8965\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0749 - accuracy: 0.9082 - val_loss: 0.0600 - val_accuracy: 0.9375\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.0636 - accuracy: 0.9336 - val_loss: 0.0454 - val_accuracy: 0.9492\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.0563 - accuracy: 0.9414 - val_loss: 0.0466 - val_accuracy: 0.9453\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 4s 258ms/step - loss: 0.0533 - accuracy: 0.9512 - val_loss: 0.0428 - val_accuracy: 0.9492\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.0495 - accuracy: 0.9395 - val_loss: 0.0459 - val_accuracy: 0.9492\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0508 - accuracy: 0.9375 - val_loss: 0.0400 - val_accuracy: 0.9453\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.0476 - accuracy: 0.9473 - val_loss: 0.0389 - val_accuracy: 0.9473\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.0481 - accuracy: 0.9434 - val_loss: 0.0484 - val_accuracy: 0.9453\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 0.0539 - accuracy: 0.9434 - val_loss: 0.0373 - val_accuracy: 0.9492\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.0427 - accuracy: 0.9492 - val_loss: 0.0359 - val_accuracy: 0.9473\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.0428 - accuracy: 0.9414 - val_loss: 0.0357 - val_accuracy: 0.9492\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.0418 - accuracy: 0.9492 - val_loss: 0.0350 - val_accuracy: 0.9512\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.0430 - accuracy: 0.9453 - val_loss: 0.0380 - val_accuracy: 0.9531\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.0445 - accuracy: 0.9492 - val_loss: 0.0344 - val_accuracy: 0.9512\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.0425 - accuracy: 0.9434 - val_loss: 0.0418 - val_accuracy: 0.9473\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.0423 - accuracy: 0.9434 - val_loss: 0.0342 - val_accuracy: 0.9551\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.0395 - accuracy: 0.9492 - val_loss: 0.0337 - val_accuracy: 0.9551\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.0400 - accuracy: 0.9531 - val_loss: 0.0338 - val_accuracy: 0.9512\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.0414 - accuracy: 0.9609 - val_loss: 0.0333 - val_accuracy: 0.9531\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.0413 - accuracy: 0.9492 - val_loss: 0.0396 - val_accuracy: 0.9512\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.0363 - accuracy: 0.9590 - val_loss: 0.0350 - val_accuracy: 0.9531\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.0390 - accuracy: 0.9570 - val_loss: 0.0401 - val_accuracy: 0.9531\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 0.0400 - accuracy: 0.9551 - val_loss: 0.0334 - val_accuracy: 0.9609\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.0368 - accuracy: 0.9570 - val_loss: 0.0321 - val_accuracy: 0.9492\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 4s 258ms/step - loss: 0.0365 - accuracy: 0.9570 - val_loss: 0.0326 - val_accuracy: 0.9590\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.0404 - accuracy: 0.9512 - val_loss: 0.0306 - val_accuracy: 0.9551\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.0349 - accuracy: 0.9570 - val_loss: 0.0307 - val_accuracy: 0.9551\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.0353 - accuracy: 0.9531 - val_loss: 0.0290 - val_accuracy: 0.9590\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.0356 - accuracy: 0.9570 - val_loss: 0.0369 - val_accuracy: 0.9570\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.0439 - accuracy: 0.9434 - val_loss: 0.0370 - val_accuracy: 0.9590\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.0455 - accuracy: 0.9434 - val_loss: 0.0299 - val_accuracy: 0.9648\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 0.0375 - accuracy: 0.9668 - val_loss: 0.0325 - val_accuracy: 0.9707\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 4s 226ms/step - loss: 0.0346 - accuracy: 0.9570 - val_loss: 0.0287 - val_accuracy: 0.9668\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.0315 - accuracy: 0.9688 - val_loss: 0.0278 - val_accuracy: 0.9590\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.0304 - accuracy: 0.9648 - val_loss: 0.0247 - val_accuracy: 0.9707\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.0346 - accuracy: 0.9609 - val_loss: 0.0259 - val_accuracy: 0.9648\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.0306 - accuracy: 0.9590 - val_loss: 0.0253 - val_accuracy: 0.9629\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.0297 - accuracy: 0.9648 - val_loss: 0.0240 - val_accuracy: 0.9629\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.0294 - accuracy: 0.9648 - val_loss: 0.0230 - val_accuracy: 0.9688\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.0289 - accuracy: 0.9609 - val_loss: 0.0278 - val_accuracy: 0.9629\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.0360 - accuracy: 0.9570 - val_loss: 0.0280 - val_accuracy: 0.9668\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.0298 - accuracy: 0.9688 - val_loss: 0.0217 - val_accuracy: 0.9707\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.0267 - accuracy: 0.9648 - val_loss: 0.0216 - val_accuracy: 0.9688\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.0266 - accuracy: 0.9668 - val_loss: 0.0229 - val_accuracy: 0.9688\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.0296 - accuracy: 0.9629 - val_loss: 0.0314 - val_accuracy: 0.9590\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 4s 258ms/step - loss: 0.0316 - accuracy: 0.9629 - val_loss: 0.0203 - val_accuracy: 0.9707\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.0259 - accuracy: 0.9648 - val_loss: 0.0272 - val_accuracy: 0.9648\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 0.0332 - accuracy: 0.9629 - val_loss: 0.0228 - val_accuracy: 0.9668\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 3s 219ms/step - loss: 0.0257 - accuracy: 0.9688 - val_loss: 0.0207 - val_accuracy: 0.9746\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.0264 - accuracy: 0.9688 - val_loss: 0.0206 - val_accuracy: 0.9688\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.0259 - accuracy: 0.9688 - val_loss: 0.0204 - val_accuracy: 0.9727\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.0233 - accuracy: 0.9746 - val_loss: 0.0192 - val_accuracy: 0.9727\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.0215 - accuracy: 0.9727 - val_loss: 0.0178 - val_accuracy: 0.9727\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 3s 220ms/step - loss: 0.0221 - accuracy: 0.9766 - val_loss: 0.0171 - val_accuracy: 0.9785\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0212 - accuracy: 0.9785 - val_loss: 0.0179 - val_accuracy: 0.9785\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0202 - accuracy: 0.9746 - val_loss: 0.0198 - val_accuracy: 0.9727\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0232 - accuracy: 0.9746 - val_loss: 0.0191 - val_accuracy: 0.9746\n",
      "2/2 [==============================] - 3s 39ms/step\n",
      "GRU\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 11s 253ms/step - loss: 0.1647 - accuracy: 0.8008 - val_loss: 0.0922 - val_accuracy: 0.9043\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0997 - accuracy: 0.8789 - val_loss: 0.0813 - val_accuracy: 0.9180\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0843 - accuracy: 0.9023 - val_loss: 0.0774 - val_accuracy: 0.9141\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0839 - accuracy: 0.9082 - val_loss: 0.0751 - val_accuracy: 0.9180\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.0782 - accuracy: 0.9238 - val_loss: 0.0730 - val_accuracy: 0.9277\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0745 - accuracy: 0.9277 - val_loss: 0.0671 - val_accuracy: 0.9453\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 0.0718 - accuracy: 0.9375 - val_loss: 0.0710 - val_accuracy: 0.9590\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0687 - accuracy: 0.9531 - val_loss: 0.0668 - val_accuracy: 0.9531\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.0653 - accuracy: 0.9512 - val_loss: 0.0600 - val_accuracy: 0.9570\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0653 - accuracy: 0.9414 - val_loss: 0.0510 - val_accuracy: 0.9609\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.0606 - accuracy: 0.9551 - val_loss: 0.0491 - val_accuracy: 0.9629\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0520 - accuracy: 0.9570 - val_loss: 0.0435 - val_accuracy: 0.9648\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 0.0538 - accuracy: 0.9531 - val_loss: 0.0405 - val_accuracy: 0.9609\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.0460 - accuracy: 0.9609 - val_loss: 0.0369 - val_accuracy: 0.9668\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.0450 - accuracy: 0.9590 - val_loss: 0.0374 - val_accuracy: 0.9648\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 0.0433 - accuracy: 0.9629 - val_loss: 0.0303 - val_accuracy: 0.9629\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0373 - accuracy: 0.9648 - val_loss: 0.0296 - val_accuracy: 0.9668\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 0.0391 - accuracy: 0.9707 - val_loss: 0.0334 - val_accuracy: 0.9648\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.0365 - accuracy: 0.9648 - val_loss: 0.0311 - val_accuracy: 0.9668\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.0373 - accuracy: 0.9688 - val_loss: 0.0301 - val_accuracy: 0.9629\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 0.0346 - accuracy: 0.9668 - val_loss: 0.0281 - val_accuracy: 0.9746\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 0.0335 - accuracy: 0.9707 - val_loss: 0.0317 - val_accuracy: 0.9766\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.0337 - accuracy: 0.9629 - val_loss: 0.0245 - val_accuracy: 0.9746\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0305 - accuracy: 0.9727 - val_loss: 0.0241 - val_accuracy: 0.9707\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0301 - accuracy: 0.9707 - val_loss: 0.0277 - val_accuracy: 0.9746\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.0302 - accuracy: 0.9746 - val_loss: 0.0231 - val_accuracy: 0.9766\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0301 - accuracy: 0.9707 - val_loss: 0.0239 - val_accuracy: 0.9746\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0299 - accuracy: 0.9688 - val_loss: 0.0220 - val_accuracy: 0.9707\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.0305 - accuracy: 0.9727 - val_loss: 0.0216 - val_accuracy: 0.9785\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.0285 - accuracy: 0.9707 - val_loss: 0.0209 - val_accuracy: 0.9785\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0287 - accuracy: 0.9668 - val_loss: 0.0212 - val_accuracy: 0.9766\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0278 - accuracy: 0.9746 - val_loss: 0.0201 - val_accuracy: 0.9766\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0246 - accuracy: 0.9766 - val_loss: 0.0193 - val_accuracy: 0.9785\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0243 - accuracy: 0.9785 - val_loss: 0.0217 - val_accuracy: 0.9785\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0279 - accuracy: 0.9785 - val_loss: 0.0198 - val_accuracy: 0.9766\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0260 - accuracy: 0.9746 - val_loss: 0.0211 - val_accuracy: 0.9785\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0269 - accuracy: 0.9746 - val_loss: 0.0218 - val_accuracy: 0.9785\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0255 - accuracy: 0.9785 - val_loss: 0.0218 - val_accuracy: 0.9785\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 0.0261 - accuracy: 0.9766 - val_loss: 0.0190 - val_accuracy: 0.9785\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0251 - accuracy: 0.9805 - val_loss: 0.0198 - val_accuracy: 0.9785\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 0.0261 - accuracy: 0.9766 - val_loss: 0.0187 - val_accuracy: 0.9785\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0244 - accuracy: 0.9805 - val_loss: 0.0177 - val_accuracy: 0.9785\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0220 - accuracy: 0.9785 - val_loss: 0.0188 - val_accuracy: 0.9785\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0248 - accuracy: 0.9766 - val_loss: 0.0175 - val_accuracy: 0.9785\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.0232 - accuracy: 0.9824 - val_loss: 0.0206 - val_accuracy: 0.9824\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0247 - accuracy: 0.9844 - val_loss: 0.0172 - val_accuracy: 0.9805\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0251 - accuracy: 0.9766 - val_loss: 0.0182 - val_accuracy: 0.9785\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 0.0240 - accuracy: 0.9785 - val_loss: 0.0169 - val_accuracy: 0.9805\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 0.0245 - accuracy: 0.9785 - val_loss: 0.0164 - val_accuracy: 0.9785\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.0231 - accuracy: 0.9746 - val_loss: 0.0163 - val_accuracy: 0.9785\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.0257 - accuracy: 0.9746 - val_loss: 0.0159 - val_accuracy: 0.9785\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.0229 - accuracy: 0.9785 - val_loss: 0.0179 - val_accuracy: 0.9785\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.0203 - accuracy: 0.9824 - val_loss: 0.0167 - val_accuracy: 0.9805\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.0229 - accuracy: 0.9785 - val_loss: 0.0161 - val_accuracy: 0.9785\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 3s 220ms/step - loss: 0.0222 - accuracy: 0.9785 - val_loss: 0.0156 - val_accuracy: 0.9805\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.0207 - accuracy: 0.9805 - val_loss: 0.0157 - val_accuracy: 0.9805\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0207 - accuracy: 0.9785 - val_loss: 0.0150 - val_accuracy: 0.9805\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0195 - accuracy: 0.9824 - val_loss: 0.0147 - val_accuracy: 0.9805\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.0194 - accuracy: 0.9805 - val_loss: 0.0155 - val_accuracy: 0.9805\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.0217 - accuracy: 0.9785 - val_loss: 0.0160 - val_accuracy: 0.9824\n",
      "2/2 [==============================] - 2s 31ms/step\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   6\n",
      "CNN\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 3s 49ms/step - loss: 0.9577 - accuracy: 0.5254 - val_loss: 0.6616 - val_accuracy: 0.7598\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.6270 - accuracy: 0.6855 - val_loss: 0.6270 - val_accuracy: 0.7793\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.4661 - accuracy: 0.7793 - val_loss: 0.5959 - val_accuracy: 0.7949\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3746 - accuracy: 0.8418 - val_loss: 0.5632 - val_accuracy: 0.8418\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.3240 - accuracy: 0.8535 - val_loss: 0.5294 - val_accuracy: 0.8848\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.2815 - accuracy: 0.8945 - val_loss: 0.4919 - val_accuracy: 0.9141\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2333 - accuracy: 0.9023 - val_loss: 0.4524 - val_accuracy: 0.9414\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.2305 - accuracy: 0.8945 - val_loss: 0.4148 - val_accuracy: 0.9434\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.2053 - accuracy: 0.9180 - val_loss: 0.3811 - val_accuracy: 0.9473\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1862 - accuracy: 0.9316 - val_loss: 0.3459 - val_accuracy: 0.9453\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1897 - accuracy: 0.9199 - val_loss: 0.3117 - val_accuracy: 0.9473\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1800 - accuracy: 0.9316 - val_loss: 0.2818 - val_accuracy: 0.9473\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1662 - accuracy: 0.9434 - val_loss: 0.2549 - val_accuracy: 0.9473\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1732 - accuracy: 0.9238 - val_loss: 0.2300 - val_accuracy: 0.9492\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1428 - accuracy: 0.9531 - val_loss: 0.2082 - val_accuracy: 0.9512\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1377 - accuracy: 0.9492 - val_loss: 0.1888 - val_accuracy: 0.9551\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1497 - accuracy: 0.9570 - val_loss: 0.1724 - val_accuracy: 0.9551\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1593 - accuracy: 0.9316 - val_loss: 0.1575 - val_accuracy: 0.9551\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1299 - accuracy: 0.9551 - val_loss: 0.1458 - val_accuracy: 0.9551\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1160 - accuracy: 0.9629 - val_loss: 0.1353 - val_accuracy: 0.9590\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1177 - accuracy: 0.9648 - val_loss: 0.1255 - val_accuracy: 0.9590\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1327 - accuracy: 0.9590 - val_loss: 0.1172 - val_accuracy: 0.9629\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1198 - accuracy: 0.9609 - val_loss: 0.1102 - val_accuracy: 0.9648\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1319 - accuracy: 0.9512 - val_loss: 0.1020 - val_accuracy: 0.9648\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1301 - accuracy: 0.9551 - val_loss: 0.0948 - val_accuracy: 0.9746\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0821 - accuracy: 0.9746 - val_loss: 0.0894 - val_accuracy: 0.9766\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0990 - accuracy: 0.9629 - val_loss: 0.0858 - val_accuracy: 0.9766\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1035 - accuracy: 0.9629 - val_loss: 0.0813 - val_accuracy: 0.9785\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1094 - accuracy: 0.9727 - val_loss: 0.0770 - val_accuracy: 0.9785\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0772 - accuracy: 0.9727 - val_loss: 0.0733 - val_accuracy: 0.9785\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1039 - accuracy: 0.9648 - val_loss: 0.0704 - val_accuracy: 0.9805\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1003 - accuracy: 0.9570 - val_loss: 0.0682 - val_accuracy: 0.9805\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1194 - accuracy: 0.9609 - val_loss: 0.0664 - val_accuracy: 0.9805\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1116 - accuracy: 0.9648 - val_loss: 0.0644 - val_accuracy: 0.9824\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1098 - accuracy: 0.9590 - val_loss: 0.0614 - val_accuracy: 0.9863\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0875 - accuracy: 0.9707 - val_loss: 0.0595 - val_accuracy: 0.9863\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0899 - accuracy: 0.9648 - val_loss: 0.0577 - val_accuracy: 0.9863\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0934 - accuracy: 0.9609 - val_loss: 0.0570 - val_accuracy: 0.9863\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0812 - accuracy: 0.9766 - val_loss: 0.0559 - val_accuracy: 0.9863\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0779 - accuracy: 0.9746 - val_loss: 0.0544 - val_accuracy: 0.9863\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0849 - accuracy: 0.9727 - val_loss: 0.0527 - val_accuracy: 0.9883\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0726 - accuracy: 0.9746 - val_loss: 0.0519 - val_accuracy: 0.9883\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0873 - accuracy: 0.9746 - val_loss: 0.0510 - val_accuracy: 0.9883\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0981 - accuracy: 0.9609 - val_loss: 0.0497 - val_accuracy: 0.9883\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0892 - accuracy: 0.9688 - val_loss: 0.0487 - val_accuracy: 0.9883\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0788 - accuracy: 0.9727 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0890 - accuracy: 0.9629 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0971 - accuracy: 0.9629 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0684 - accuracy: 0.9824 - val_loss: 0.0460 - val_accuracy: 0.9883\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0873 - accuracy: 0.9648 - val_loss: 0.0449 - val_accuracy: 0.9883\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0724 - accuracy: 0.9746 - val_loss: 0.0441 - val_accuracy: 0.9902\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0828 - accuracy: 0.9766 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0945 - accuracy: 0.9688 - val_loss: 0.0426 - val_accuracy: 0.9902\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0751 - accuracy: 0.9727 - val_loss: 0.0422 - val_accuracy: 0.9883\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0725 - accuracy: 0.9727 - val_loss: 0.0420 - val_accuracy: 0.9883\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0794 - accuracy: 0.9746 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0743 - accuracy: 0.9766 - val_loss: 0.0404 - val_accuracy: 0.9902\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0569 - accuracy: 0.9766 - val_loss: 0.0397 - val_accuracy: 0.9902\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0930 - accuracy: 0.9668 - val_loss: 0.0394 - val_accuracy: 0.9902\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0589 - accuracy: 0.9746 - val_loss: 0.0390 - val_accuracy: 0.9902\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "RNN\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_37_input'), name='dense_37_input', description=\"created by layer 'dense_37_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_37_input'), name='dense_37_input', description=\"created by layer 'dense_37_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      " 90/103 [=========================>....] - ETA: 0s - loss: 0.2262 - accuracy: 0.9244WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_37_input'), name='dense_37_input', description=\"created by layer 'dense_37_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "103/103 [==============================] - 2s 8ms/step - loss: 0.2101 - accuracy: 0.9297 - val_loss: 0.0844 - val_accuracy: 0.9805\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0765 - accuracy: 0.9805 - val_loss: 0.0593 - val_accuracy: 0.9844\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0580 - accuracy: 0.9824 - val_loss: 0.0474 - val_accuracy: 0.9863\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0556 - accuracy: 0.9844 - val_loss: 0.0387 - val_accuracy: 0.9902\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0475 - accuracy: 0.9863 - val_loss: 0.0328 - val_accuracy: 0.9883\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 0.0312 - val_accuracy: 0.9902\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0540 - accuracy: 0.9824 - val_loss: 0.0288 - val_accuracy: 0.9902\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0375 - accuracy: 0.9863 - val_loss: 0.0220 - val_accuracy: 0.9922\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0302 - accuracy: 0.9883 - val_loss: 0.0238 - val_accuracy: 0.9902\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 0.0141 - val_accuracy: 0.9941\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0227 - accuracy: 0.9902 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.0114 - val_accuracy: 0.9980\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9980\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9980\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0150 - val_accuracy: 0.9961\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0281 - accuracy: 0.9922 - val_loss: 0.0103 - val_accuracy: 0.9961\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.0094 - val_accuracy: 0.9961\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 9.9641e-04 - accuracy: 1.0000 - val_loss: 8.4845e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.8571e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.9410e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.8072e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.7153e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 8.3931e-04 - accuracy: 1.0000 - val_loss: 3.7596e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.5972e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 4.7220e-04 - accuracy: 1.0000 - val_loss: 3.0331e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 5.3327e-04 - accuracy: 1.0000 - val_loss: 2.3504e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 4.0642e-04 - accuracy: 1.0000 - val_loss: 2.2042e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 8.4344e-04 - accuracy: 1.0000 - val_loss: 2.2610e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 4.1182e-04 - accuracy: 1.0000 - val_loss: 1.7324e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 5.4188e-04 - accuracy: 1.0000 - val_loss: 1.8096e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 4.7984e-04 - accuracy: 1.0000 - val_loss: 1.8485e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 3.7938e-04 - accuracy: 1.0000 - val_loss: 1.3169e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 2.9774e-04 - accuracy: 1.0000 - val_loss: 1.2102e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 3.9657e-04 - accuracy: 1.0000 - val_loss: 1.1742e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9961 - val_loss: 0.0417 - val_accuracy: 0.9902\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.5359e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 2.2393e-04 - accuracy: 1.0000 - val_loss: 1.7839e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 398, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 398, 30), dtype=tf.float32, name='dense_37_input'), name='dense_37_input', description=\"created by layer 'dense_37_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 18s 422ms/step - loss: 0.1846 - accuracy: 0.7695 - val_loss: 0.1318 - val_accuracy: 0.8164\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 4s 287ms/step - loss: 0.1204 - accuracy: 0.8516 - val_loss: 0.1108 - val_accuracy: 0.8613\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 0.1064 - accuracy: 0.8613 - val_loss: 0.0906 - val_accuracy: 0.8906\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.0882 - accuracy: 0.8945 - val_loss: 0.0617 - val_accuracy: 0.9316\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0706 - accuracy: 0.9180 - val_loss: 0.0525 - val_accuracy: 0.9395\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 4s 226ms/step - loss: 0.0604 - accuracy: 0.9336 - val_loss: 0.0517 - val_accuracy: 0.9375\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 0.0563 - accuracy: 0.9375 - val_loss: 0.0475 - val_accuracy: 0.9453\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 3s 220ms/step - loss: 0.0567 - accuracy: 0.9395 - val_loss: 0.0417 - val_accuracy: 0.9434\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.0494 - accuracy: 0.9395 - val_loss: 0.0425 - val_accuracy: 0.9492\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.0481 - accuracy: 0.9395 - val_loss: 0.0414 - val_accuracy: 0.9453\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 3s 220ms/step - loss: 0.0465 - accuracy: 0.9453 - val_loss: 0.0423 - val_accuracy: 0.9492\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.0474 - accuracy: 0.9434 - val_loss: 0.0412 - val_accuracy: 0.9434\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 0.0458 - accuracy: 0.9492 - val_loss: 0.0412 - val_accuracy: 0.9453\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 0.0477 - accuracy: 0.9473 - val_loss: 0.0390 - val_accuracy: 0.9453\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 0.0445 - accuracy: 0.9473 - val_loss: 0.0380 - val_accuracy: 0.9453\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 0.0430 - accuracy: 0.9434 - val_loss: 0.0365 - val_accuracy: 0.9492\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 2s 160ms/step - loss: 0.0422 - accuracy: 0.9512 - val_loss: 0.0373 - val_accuracy: 0.9570\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 0.0425 - accuracy: 0.9473 - val_loss: 0.0393 - val_accuracy: 0.9512\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.0457 - accuracy: 0.9453 - val_loss: 0.0398 - val_accuracy: 0.9473\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.0428 - accuracy: 0.9492 - val_loss: 0.0386 - val_accuracy: 0.9590\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 3s 152ms/step - loss: 0.0435 - accuracy: 0.9473 - val_loss: 0.0372 - val_accuracy: 0.9609\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 0.0408 - accuracy: 0.9531 - val_loss: 0.0317 - val_accuracy: 0.9570\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0417 - accuracy: 0.9492 - val_loss: 0.0322 - val_accuracy: 0.9629\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0358 - accuracy: 0.9570 - val_loss: 0.0301 - val_accuracy: 0.9648\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0367 - accuracy: 0.9590 - val_loss: 0.0328 - val_accuracy: 0.9570\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0364 - accuracy: 0.9609 - val_loss: 0.0302 - val_accuracy: 0.9629\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0389 - accuracy: 0.9551 - val_loss: 0.0292 - val_accuracy: 0.9629\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0429 - accuracy: 0.9453 - val_loss: 0.0375 - val_accuracy: 0.9629\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0367 - accuracy: 0.9570 - val_loss: 0.0332 - val_accuracy: 0.9609\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0348 - accuracy: 0.9551 - val_loss: 0.0275 - val_accuracy: 0.9629\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0348 - accuracy: 0.9570 - val_loss: 0.0277 - val_accuracy: 0.9648\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.0318 - accuracy: 0.9609 - val_loss: 0.0263 - val_accuracy: 0.9668\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0330 - accuracy: 0.9570 - val_loss: 0.0263 - val_accuracy: 0.9629\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0298 - accuracy: 0.9648 - val_loss: 0.0256 - val_accuracy: 0.9688\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0322 - accuracy: 0.9590 - val_loss: 0.0275 - val_accuracy: 0.9668\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0344 - accuracy: 0.9570 - val_loss: 0.0258 - val_accuracy: 0.9688\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0317 - accuracy: 0.9590 - val_loss: 0.0242 - val_accuracy: 0.9727\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0298 - accuracy: 0.9648 - val_loss: 0.0245 - val_accuracy: 0.9688\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.0307 - accuracy: 0.9648 - val_loss: 0.0247 - val_accuracy: 0.9629\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0307 - accuracy: 0.9629 - val_loss: 0.0244 - val_accuracy: 0.9707\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.0309 - accuracy: 0.9629 - val_loss: 0.0245 - val_accuracy: 0.9688\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0278 - accuracy: 0.9609 - val_loss: 0.0249 - val_accuracy: 0.9688\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.0273 - accuracy: 0.9648 - val_loss: 0.0236 - val_accuracy: 0.9648\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.0277 - accuracy: 0.9609 - val_loss: 0.0228 - val_accuracy: 0.9688\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0277 - accuracy: 0.9707 - val_loss: 0.0228 - val_accuracy: 0.9648\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.0282 - accuracy: 0.9648 - val_loss: 0.0221 - val_accuracy: 0.9707\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.0264 - accuracy: 0.9629 - val_loss: 0.0222 - val_accuracy: 0.9668\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0267 - accuracy: 0.9668 - val_loss: 0.0225 - val_accuracy: 0.9648\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 4s 281ms/step - loss: 0.0261 - accuracy: 0.9688 - val_loss: 0.0239 - val_accuracy: 0.9629\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0270 - accuracy: 0.9609 - val_loss: 0.0243 - val_accuracy: 0.9629\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.0295 - accuracy: 0.9629 - val_loss: 0.0237 - val_accuracy: 0.9707\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0279 - accuracy: 0.9688 - val_loss: 0.0224 - val_accuracy: 0.9727\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.0272 - accuracy: 0.9629 - val_loss: 0.0226 - val_accuracy: 0.9707\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.0284 - accuracy: 0.9609 - val_loss: 0.0237 - val_accuracy: 0.9707\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 0.0259 - accuracy: 0.9727 - val_loss: 0.0211 - val_accuracy: 0.9727\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0236 - accuracy: 0.9668 - val_loss: 0.0217 - val_accuracy: 0.9688\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 2s 157ms/step - loss: 0.0274 - accuracy: 0.9648 - val_loss: 0.0235 - val_accuracy: 0.9648\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0254 - accuracy: 0.9648 - val_loss: 0.0208 - val_accuracy: 0.9727\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0288 - accuracy: 0.9688 - val_loss: 0.0279 - val_accuracy: 0.9609\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 2s 157ms/step - loss: 0.0283 - accuracy: 0.9648 - val_loss: 0.0236 - val_accuracy: 0.9668\n",
      "2/2 [==============================] - 2s 27ms/step\n",
      "GRU\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 10s 230ms/step - loss: 0.1297 - accuracy: 0.8711 - val_loss: 0.0940 - val_accuracy: 0.9180\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0921 - accuracy: 0.9062 - val_loss: 0.0806 - val_accuracy: 0.9082\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 0.0827 - accuracy: 0.9160 - val_loss: 0.0727 - val_accuracy: 0.9258\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 0.0765 - accuracy: 0.9199 - val_loss: 0.0685 - val_accuracy: 0.9336\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 0.0704 - accuracy: 0.9316 - val_loss: 0.0629 - val_accuracy: 0.9434\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.0672 - accuracy: 0.9375 - val_loss: 0.0567 - val_accuracy: 0.9473\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 0.0640 - accuracy: 0.9512 - val_loss: 0.0512 - val_accuracy: 0.9648\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0585 - accuracy: 0.9473 - val_loss: 0.0461 - val_accuracy: 0.9648\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0562 - accuracy: 0.9570 - val_loss: 0.0398 - val_accuracy: 0.9629\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.0485 - accuracy: 0.9570 - val_loss: 0.0361 - val_accuracy: 0.9668\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 0.0449 - accuracy: 0.9648 - val_loss: 0.0353 - val_accuracy: 0.9668\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.0432 - accuracy: 0.9590 - val_loss: 0.0353 - val_accuracy: 0.9668\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.0397 - accuracy: 0.9668 - val_loss: 0.0334 - val_accuracy: 0.9629\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 0.0398 - accuracy: 0.9629 - val_loss: 0.0307 - val_accuracy: 0.9648\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 0.0397 - accuracy: 0.9707 - val_loss: 0.0299 - val_accuracy: 0.9648\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.0386 - accuracy: 0.9609 - val_loss: 0.0275 - val_accuracy: 0.9707\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0319 - accuracy: 0.9707 - val_loss: 0.0251 - val_accuracy: 0.9668\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.0331 - accuracy: 0.9648 - val_loss: 0.0247 - val_accuracy: 0.9688\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 0.0351 - accuracy: 0.9590 - val_loss: 0.0250 - val_accuracy: 0.9727\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 0.0328 - accuracy: 0.9629 - val_loss: 0.0286 - val_accuracy: 0.9727\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 0.0331 - accuracy: 0.9688 - val_loss: 0.0251 - val_accuracy: 0.9707\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 0.0319 - accuracy: 0.9629 - val_loss: 0.0233 - val_accuracy: 0.9707\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 0.0304 - accuracy: 0.9688 - val_loss: 0.0235 - val_accuracy: 0.9707\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 0.0306 - accuracy: 0.9668 - val_loss: 0.0233 - val_accuracy: 0.9746\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0288 - accuracy: 0.9668 - val_loss: 0.0228 - val_accuracy: 0.9746\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0302 - accuracy: 0.9668 - val_loss: 0.0223 - val_accuracy: 0.9727\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.0304 - accuracy: 0.9707 - val_loss: 0.0218 - val_accuracy: 0.9746\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.0307 - accuracy: 0.9688 - val_loss: 0.0229 - val_accuracy: 0.9727\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.0305 - accuracy: 0.9727 - val_loss: 0.0248 - val_accuracy: 0.9727\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0305 - accuracy: 0.9688 - val_loss: 0.0227 - val_accuracy: 0.9746\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0269 - accuracy: 0.9727 - val_loss: 0.0216 - val_accuracy: 0.9746\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 0.0250 - accuracy: 0.9746 - val_loss: 0.0210 - val_accuracy: 0.9746\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.0290 - accuracy: 0.9668 - val_loss: 0.0221 - val_accuracy: 0.9746\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.0276 - accuracy: 0.9746 - val_loss: 0.0211 - val_accuracy: 0.9766\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0274 - accuracy: 0.9688 - val_loss: 0.0216 - val_accuracy: 0.9766\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0283 - accuracy: 0.9668 - val_loss: 0.0212 - val_accuracy: 0.9746\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0249 - accuracy: 0.9746 - val_loss: 0.0209 - val_accuracy: 0.9746\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0264 - accuracy: 0.9707 - val_loss: 0.0214 - val_accuracy: 0.9746\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.0258 - accuracy: 0.9746 - val_loss: 0.0214 - val_accuracy: 0.9766\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0244 - accuracy: 0.9746 - val_loss: 0.0197 - val_accuracy: 0.9746\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 0.0258 - accuracy: 0.9746 - val_loss: 0.0199 - val_accuracy: 0.9746\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.0255 - accuracy: 0.9707 - val_loss: 0.0202 - val_accuracy: 0.9707\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 0.0258 - accuracy: 0.9727 - val_loss: 0.0203 - val_accuracy: 0.9746\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0254 - accuracy: 0.9727 - val_loss: 0.0189 - val_accuracy: 0.9746\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.0230 - accuracy: 0.9766 - val_loss: 0.0191 - val_accuracy: 0.9746\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 0.0255 - accuracy: 0.9688 - val_loss: 0.0187 - val_accuracy: 0.9727\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0247 - accuracy: 0.9707 - val_loss: 0.0185 - val_accuracy: 0.9766\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 0.0234 - accuracy: 0.9766 - val_loss: 0.0183 - val_accuracy: 0.9746\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.0251 - accuracy: 0.9727 - val_loss: 0.0189 - val_accuracy: 0.9746\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 0.0231 - accuracy: 0.9766 - val_loss: 0.0178 - val_accuracy: 0.9746\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0229 - accuracy: 0.9727 - val_loss: 0.0177 - val_accuracy: 0.9746\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 0.0228 - accuracy: 0.9746 - val_loss: 0.0172 - val_accuracy: 0.9766\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 0.0232 - accuracy: 0.9707 - val_loss: 0.0175 - val_accuracy: 0.9766\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 0.0241 - accuracy: 0.9727 - val_loss: 0.0169 - val_accuracy: 0.9746\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0225 - accuracy: 0.9766 - val_loss: 0.0172 - val_accuracy: 0.9746\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 0.0225 - accuracy: 0.9707 - val_loss: 0.0168 - val_accuracy: 0.9746\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 0.0208 - accuracy: 0.9766 - val_loss: 0.0165 - val_accuracy: 0.9766\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0197 - accuracy: 0.9785 - val_loss: 0.0169 - val_accuracy: 0.9746\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.0215 - accuracy: 0.9766 - val_loss: 0.0176 - val_accuracy: 0.9746\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.0215 - accuracy: 0.9766 - val_loss: 0.0175 - val_accuracy: 0.9785\n",
      "2/2 [==============================] - 1s 19ms/step\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 249\u001b[0m\n\u001b[0;32m    235\u001b[0m gbc_parameters \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(gbc__n_estimators \u001b[39m=\u001b[39m [\u001b[39m10\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m200\u001b[39m],\n\u001b[0;32m    236\u001b[0m                   gbc__loss \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdeviance\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexponential\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    237\u001b[0m                   gbc__learning_rate \u001b[39m=\u001b[39m [\u001b[39m0.001\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m]\n\u001b[0;32m    238\u001b[0m )\n\u001b[0;32m    241\u001b[0m gbc_cv \u001b[39m=\u001b[39m GridSearchCV(gbc_pipeline,\n\u001b[0;32m    242\u001b[0m                   param_grid \u001b[39m=\u001b[39m gbc_parameters,\n\u001b[0;32m    243\u001b[0m                   cv \u001b[39m=\u001b[39m epochs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    246\u001b[0m                   error_score \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    247\u001b[0m                   )\n\u001b[1;32m--> 249\u001b[0m gbc_cv\u001b[39m.\u001b[39;49mfit(inputs[train], targets[train])\n\u001b[0;32m    250\u001b[0m gbc_targets_pred \u001b[39m=\u001b[39m gbc_cv\u001b[39m.\u001b[39mpredict(inputs[test])\n\u001b[0;32m    251\u001b[0m gbc_accuracy\u001b[39m=\u001b[39maccuracy_score(targets[test],gbc_targets_pred)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_folds=10\n",
    "epochs = 60\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    print(\"Fold No:  \",fold_no)\n",
    "    print(\"CNN\")\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=32,kernel_size=2,activation='relu',input_shape=(30,1)))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "\n",
    "    cnn_model.add(Conv1D(filters=64,kernel_size=2,activation='relu'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(Dropout(0.3))\n",
    "\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(64,activation='relu'))\n",
    "    cnn_model.add(Dropout(0.4))\n",
    "\n",
    "    cnn_model.add(Dense(1,activation='sigmoid'))\n",
    "    cnn_model.compile(optimizer=Adam(learning_rate=0.00005),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    cnn_history = cnn_model.fit(inputs[train], targets[train],epochs=epochs,validation_data=(inputs[train], targets[train]),verbose=1)\n",
    "    cnn_targets_pred = (cnn_model.predict(inputs[test]) > 0.5).astype(\"int32\")\n",
    "    cnn_accuracy=accuracy_score(targets[test],cnn_targets_pred)\n",
    "    cnn_precision = precision_score(targets[test],cnn_targets_pred)\n",
    "    cnn_recall = recall_score(targets[test],cnn_targets_pred)\n",
    "    cnn_f1=f1_score(targets[test],cnn_targets_pred)\n",
    "    cnn_accuracy1.append(cnn_accuracy)\n",
    "    cnn_precision1.append(cnn_precision)\n",
    "    cnn_recall1.append(cnn_recall)\n",
    "    cnn_f11.append(cnn_f1)\n",
    "\n",
    "\n",
    "    print(\"RNN\")\n",
    "    rnn_model = Sequential()\n",
    "\n",
    "    rnn_model.add(Dense(128, input_shape = (None,398,30)))\n",
    "    rnn_model.add(ReLU())\n",
    "    rnn_model.add(Dropout(0.1))\n",
    "\n",
    "    rnn_model.add(Dense(64))\n",
    "    rnn_model.add(ReLU())\n",
    "    rnn_model.add(Dropout(0.1))\n",
    "\n",
    "    rnn_model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    rnn_model.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = \"adam\",\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "    rnn_history = rnn_model.fit(inputs[train], targets[train],epochs = epochs, batch_size = 5,validation_data = (inputs[train], targets[train]))\n",
    "    rnn_targets_pred = (rnn_model.predict(inputs[test]) > 0.5).astype(\"int32\")\n",
    "    rnn_accuracy=accuracy_score(targets[test],rnn_targets_pred)\n",
    "    rnn_precision = precision_score(targets[test],rnn_targets_pred)\n",
    "    rnn_recall = recall_score(targets[test],rnn_targets_pred)\n",
    "    rnn_f1=f1_score(targets[test],rnn_targets_pred)\n",
    "    rnn_accuracy1.append(rnn_accuracy)\n",
    "    rnn_precision1.append(rnn_precision)\n",
    "    rnn_recall1.append(rnn_recall)\n",
    "    rnn_f11.append(rnn_f1)\n",
    "\n",
    "    print(\"LSTM\")\n",
    "\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(inputs[train].shape[1],1)))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(Dense(units=1))\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    lstm_model.fit(inputs[train], targets[train], epochs=epochs, batch_size=32,verbose = 1,validation_data=(inputs[train], targets[train]))\n",
    "    lstm_targets_pred = (lstm_model.predict(inputs[test]) > 0.5).astype(\"int32\")\n",
    "    lstm_accuracy=accuracy_score(targets[test],lstm_targets_pred)\n",
    "    lstm_precision = precision_score(targets[test],lstm_targets_pred)\n",
    "    lstm_recall = recall_score(targets[test],lstm_targets_pred)\n",
    "    lstm_f1=f1_score(targets[test],lstm_targets_pred)\n",
    "    lstm_accuracy1.append(lstm_accuracy)\n",
    "    lstm_precision1.append(lstm_precision)\n",
    "    lstm_recall1.append(lstm_recall)\n",
    "    lstm_f11.append(lstm_f1)\n",
    "\n",
    "    print(\"GRU\")\n",
    "\n",
    "    gru_model = Sequential()\n",
    "    gru_model.add(GRU(units=50, return_sequences=True, input_shape=(inputs[train].shape[1],1)))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "    gru_model.add(GRU(units=50, return_sequences=True))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "    gru_model.add(GRU(units=50, return_sequences=True))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "    gru_model.add(GRU(units=50))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "    gru_model.add(Dense(units=1))\n",
    "    gru_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    gru_model.fit(inputs[train], targets[train], epochs=epochs, batch_size=32,verbose = 1,validation_data=(inputs[train], targets[train]))\n",
    "    gru_targets_pred = (gru_model.predict(inputs[test]) > 0.5).astype(\"int32\")\n",
    "    gru_accuracy=accuracy_score(targets[test],gru_targets_pred)\n",
    "    gru_precision = precision_score(targets[test],gru_targets_pred)\n",
    "    gru_recall = recall_score(targets[test],gru_targets_pred)\n",
    "    gru_f1=f1_score(targets[test],gru_targets_pred)\n",
    "    gru_accuracy1.append(gru_accuracy)\n",
    "    gru_precision1.append(gru_precision)\n",
    "    gru_recall1.append(gru_recall)\n",
    "    gru_f11.append(gru_f1)\n",
    "\n",
    "    print(\"KNN\")\n",
    "\n",
    "    knn_steps = [('scaler', StandardScaler()),\n",
    "         ('knn', BaggingClassifier(KNeighborsClassifier()))]\n",
    "    knn_pipeline = Pipeline(knn_steps)\n",
    "\n",
    "    knn_parameters = dict(knn__base_estimator__metric = ['euclidean', 'manhattan', 'minkowski'],\n",
    "                    knn__base_estimator__weights =  ['uniform', 'distance'],\n",
    "                    knn__base_estimator__n_neighbors = range(2,15),\n",
    "                    knn__bootstrap = [True, False],\n",
    "                    knn__bootstrap_features = [True, False],\n",
    "                    knn__n_estimators = [5])\n",
    "\n",
    "\n",
    "    knn_cv = GridSearchCV(knn_pipeline,\n",
    "                    param_grid = knn_parameters,\n",
    "                    cv = epochs,\n",
    "                    scoring = 'accuracy',\n",
    "                    n_jobs = -1,\n",
    "                    )\n",
    "\n",
    "    knn_cv.fit(inputs[train], targets[train])\n",
    "    knn_targets_pred = knn_cv.predict(inputs[test])\n",
    "    knn_accuracy=accuracy_score(targets[test],knn_targets_pred)\n",
    "    knn_precision = precision_score(targets[test],knn_targets_pred)\n",
    "    knn_recall = recall_score(targets[test],knn_targets_pred)\n",
    "    knn_f1=f1_score(targets[test],knn_targets_pred)\n",
    "    knn_accuracy1.append(knn_accuracy)\n",
    "    knn_precision1.append(knn_precision)\n",
    "    knn_recall1.append(knn_recall)\n",
    "    knn_f11.append(knn_f1)\n",
    "\n",
    "    print(\"SVC\")\n",
    "\n",
    "    svc_steps = [('scaler', StandardScaler()),\n",
    "         ('svc', SVC())]\n",
    "    svc_pipeline = Pipeline(svc_steps)\n",
    "\n",
    "    svc_parameters = dict(svc__kernel = ['poly', 'rbf', 'sigmoid'],\n",
    "                      svc__gamma =  [0.0001, 0.001, 0.01, 0.1],\n",
    "                      svc__C = [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20])\n",
    "\n",
    "\n",
    "    svc_cv = GridSearchCV(svc_pipeline,\n",
    "                      param_grid = svc_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1)\n",
    "\n",
    "    svc_cv.fit(inputs[train], targets[train])\n",
    "    svc_targets_pred = svc_cv.predict(inputs[test])\n",
    "    svc_accuracy=accuracy_score(targets[test],svc_targets_pred)\n",
    "    svc_precision = precision_score(targets[test],svc_targets_pred)\n",
    "    svc_recall = recall_score(targets[test],svc_targets_pred)\n",
    "    svc_f1=f1_score(targets[test],svc_targets_pred)\n",
    "    svc_accuracy1.append(svc_accuracy)\n",
    "    svc_precision1.append(svc_precision)\n",
    "    svc_recall1.append(svc_recall)\n",
    "    svc_f11.append(svc_f1)\n",
    "\n",
    "    print(\"Random Forest\")\n",
    "    \n",
    "\n",
    "    rf_steps = [('scaler', StandardScaler()),\n",
    "         ('rf', RandomForestClassifier(random_state = 0))]\n",
    "    rf_pipeline = Pipeline(rf_steps)\n",
    "\n",
    "    rf_parameters = dict(rf__n_estimators = [10,100],\n",
    "                      rf__max_features = ['sqrt', 'log2'],\n",
    "    )\n",
    "\n",
    "\n",
    "    rf_cv = GridSearchCV(rf_pipeline,\n",
    "                      param_grid = rf_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1)\n",
    "\n",
    "    rf_cv.fit(inputs[train], targets[train])\n",
    "    rf_targets_pred = rf_cv.predict(inputs[test])\n",
    "    rf_accuracy=accuracy_score(targets[test],rf_targets_pred)\n",
    "    rf_precision = precision_score(targets[test],rf_targets_pred)\n",
    "    rf_recall = recall_score(targets[test],rf_targets_pred)\n",
    "    rf_f1=f1_score(targets[test],rf_targets_pred)\n",
    "    rf_accuracy1.append(rf_accuracy)\n",
    "    rf_precision1.append(rf_precision)\n",
    "    rf_recall1.append(rf_recall)\n",
    "    rf_f11.append(rf_f1)\n",
    "\n",
    "    ##Start from here \n",
    "\n",
    "    print(\"Ridge Classifier\")\n",
    "\n",
    "    ridge_steps = [('scaler', StandardScaler()),\n",
    "         ('ridge', RidgeClassifier())]\n",
    "    ridge_pipeline = Pipeline(ridge_steps)\n",
    "\n",
    "    ridge_parameters = dict(ridge__alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "\n",
    "    ridge_cv = GridSearchCV(ridge_pipeline,\n",
    "                      param_grid = ridge_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0)\n",
    "\n",
    "    ridge_cv.fit(inputs[train], targets[train])\n",
    "    ridge_targets_pred = ridge_cv.predict(inputs[test])\n",
    "    ridge_accuracy=accuracy_score(targets[test],ridge_targets_pred)\n",
    "    ridge_precision = precision_score(targets[test],ridge_targets_pred)\n",
    "    ridge_recall = recall_score(targets[test],ridge_targets_pred)\n",
    "    ridge_f1=f1_score(targets[test],ridge_targets_pred)\n",
    "    ridge_accuracy1.append(ridge_accuracy)\n",
    "    ridge_precision1.append(ridge_precision)\n",
    "    ridge_recall1.append(ridge_recall)\n",
    "    ridge_f11.append(ridge_f1)\n",
    "\n",
    "    print(\"Gradient Boosting\")\n",
    "\n",
    "    gbc_steps = [('scaler', StandardScaler()),\n",
    "         ('gbc', GradientBoostingClassifier())]\n",
    "    gbc_pipeline = Pipeline(gbc_steps)\n",
    "\n",
    "    gbc_parameters = dict(gbc__n_estimators = [10,100,200],\n",
    "                      gbc__loss = ['deviance', 'exponential'],\n",
    "                      gbc__learning_rate = [0.001, 0.1, 1, 10]\n",
    "    )\n",
    "\n",
    "\n",
    "    gbc_cv = GridSearchCV(gbc_pipeline,\n",
    "                      param_grid = gbc_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0\n",
    "                      )\n",
    "\n",
    "    gbc_cv.fit(inputs[train], targets[train])\n",
    "    gbc_targets_pred = gbc_cv.predict(inputs[test])\n",
    "    gbc_accuracy=accuracy_score(targets[test],gbc_targets_pred)\n",
    "    gbc_precision = precision_score(targets[test],gbc_targets_pred)\n",
    "    gbc_recall = recall_score(targets[test],gbc_targets_pred)\n",
    "    gbc_f1=f1_score(targets[test],gbc_targets_pred)\n",
    "    gbc_accuracy1.append(gbc_accuracy)\n",
    "    gbc_precision1.append(gbc_precision)\n",
    "    gbc_recall1.append(gbc_recall)\n",
    "    gbc_f11.append(gbc_f1)\n",
    "\n",
    "    print(\"XGBoost\")\n",
    "\n",
    "    xgb = XGBClassifier(max_depth = 5,\n",
    "                        min_child_weight = 1,\n",
    "                        gamma = 0.3,\n",
    "                        subsample = 0.8,\n",
    "                        colsample_bytree = 0.8,\n",
    "                        learning_rate = 0.1,\n",
    "                        reg_alpha=0.05,\n",
    "                        disable_default_eval_metric = True)\n",
    "\n",
    "    xgb.fit(inputs[train], targets[train])\n",
    "    xgb_targets_pred = xgb.predict(inputs[test])\n",
    "\n",
    "    xgb_accuracy=accuracy_score(targets[test],xgb_targets_pred)\n",
    "    xgb_precision = precision_score(targets[test],xgb_targets_pred)\n",
    "    xgb_recall = recall_score(targets[test],xgb_targets_pred)\n",
    "    xgb_f1=f1_score(targets[test],xgb_targets_pred)\n",
    "    xgb_accuracy1.append(xgb_accuracy)\n",
    "    xgb_precision1.append(xgb_precision)\n",
    "    xgb_recall1.append(xgb_recall)\n",
    "    xgb_f11.append(xgb_f1)\n",
    "\n",
    "    print(\"Logistic Regression\")\n",
    "\n",
    "    lr_steps = [('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression())]\n",
    "\n",
    "    lr_pipeline = Pipeline(lr_steps)\n",
    "\n",
    "    lr_parameters = dict(lr__C = np.logspace(-3,3,7),                  \n",
    "                      lr__penalty = [\"l1\",\"l2\"])\n",
    "    lr_cv = GridSearchCV(lr_pipeline,\n",
    "                      param_grid = lr_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0\n",
    "                      )\n",
    "    lr_cv.fit(inputs[train], targets[train])\n",
    "    lr_targets_pred = lr_cv.predict(inputs[test])\n",
    "\n",
    "    lr_accuracy=accuracy_score(targets[test],lr_targets_pred)\n",
    "    lr_precision = precision_score(targets[test],lr_targets_pred)\n",
    "    lr_recall = recall_score(targets[test],lr_targets_pred)\n",
    "    lr_f1=f1_score(targets[test],lr_targets_pred)\n",
    "    lr_accuracy1.append(lr_accuracy)\n",
    "    lr_precision1.append(lr_precision)\n",
    "    lr_recall1.append(lr_recall)\n",
    "    lr_f11.append(lr_f1)\n",
    "\n",
    "    print(\"Decision Tree\")\n",
    "\n",
    "    dt = DecisionTreeClassifier()\n",
    "\n",
    "    dt.fit(inputs[train], targets[train],sample_weight=None)\n",
    "    dt_targets_pred = dt.predict(inputs[test])\n",
    "\n",
    "    dt_accuracy=accuracy_score(targets[test],dt_targets_pred)\n",
    "    dt_precision = precision_score(targets[test],dt_targets_pred)\n",
    "    dt_recall = recall_score(targets[test],dt_targets_pred)\n",
    "    dt_f1=f1_score(targets[test],dt_targets_pred)\n",
    "    dt_accuracy1.append(dt_accuracy)\n",
    "    dt_precision1.append(dt_precision)\n",
    "    dt_recall1.append(dt_recall)\n",
    "    dt_f11.append(dt_f1)\n",
    "\n",
    "    print(\"Linear Discremental Analysis\")\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    lda.fit(inputs[train], targets[train])\n",
    "    lda_targets_pred = lda.predict(inputs[test])\n",
    "\n",
    "    lda_accuracy=accuracy_score(targets[test],lda_targets_pred)\n",
    "    lda_precision = precision_score(targets[test],lda_targets_pred)\n",
    "    lda_recall = recall_score(targets[test],lda_targets_pred)\n",
    "    lda_f1=f1_score(targets[test],lda_targets_pred)\n",
    "    lda_accuracy1.append(lda_accuracy)\n",
    "    lda_precision1.append(lda_precision)\n",
    "    lda_recall1.append(lda_recall)\n",
    "    lda_f11.append(lda_f1)\n",
    "\n",
    "    print(\"Quadratic Discremental Analysis\")\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "    qda.fit(inputs[train], targets[train])\n",
    "    qda_targets_pred = qda.predict(inputs[test])\n",
    "\n",
    "    qda_accuracy=accuracy_score(targets[test],qda_targets_pred)\n",
    "    qda_precision = precision_score(targets[test],qda_targets_pred)\n",
    "    qda_recall = recall_score(targets[test],qda_targets_pred)\n",
    "    qda_f1=f1_score(targets[test],qda_targets_pred)\n",
    "    qda_accuracy1.append(qda_accuracy)\n",
    "    qda_precision1.append(qda_precision)\n",
    "    qda_recall1.append(qda_recall)\n",
    "    qda_f11.append(qda_f1)\n",
    "\n",
    "    print(\"Naive Bayes\")\n",
    "\n",
    "    nb= GaussianNB()\n",
    "\n",
    "    nb.fit(inputs[train], targets[train])\n",
    "    nb_targets_pred = nb.predict(inputs[test])\n",
    "\n",
    "    nb_accuracy=accuracy_score(targets[test],nb_targets_pred)\n",
    "    nb_precision = precision_score(targets[test],nb_targets_pred)\n",
    "    nb_recall = recall_score(targets[test],nb_targets_pred)\n",
    "    nb_f1=f1_score(targets[test],nb_targets_pred)\n",
    "    nb_accuracy1.append(nb_accuracy)\n",
    "    nb_precision1.append(nb_precision)\n",
    "    nb_recall1.append(nb_recall)\n",
    "    nb_f11.append(nb_f1)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCnnAccuracy =  mean(cnn_accuracy1)\n",
    "avgCnnPrecision=mean(cnn_precision1)\n",
    "avgCnnRecall=mean(cnn_recall1)\n",
    "avgCnnF1=mean(cnn_f11)\n",
    "avgRnnAccuracy = mean(rnn_accuracy1)\n",
    "avgRnnPrecision = mean(rnn_precision1)\n",
    "avgRnnRecall = mean(rnn_recall1)\n",
    "avgRnnF1 = mean(rnn_f11)\n",
    "avgLstmAccuracy = mean(lstm_accuracy1)\n",
    "avgLstmPrecision = mean(lstm_precision1)\n",
    "avgLstmRecall = mean(lstm_recall1)\n",
    "avgLstmF1 = mean(lstm_f11)\n",
    "avgGruAccuracy = mean(gru_accuracy1)\n",
    "avgGruPrecision = mean(gru_precision1)\n",
    "avgGruRecall = mean(gru_recall1)\n",
    "avgGruF1 = mean(gru_f11)\n",
    "avgKnnAccuracy = mean(knn_accuracy1)\n",
    "avgKnnPrecision = mean(knn_precision1)\n",
    "avgKnnRecall = mean(knn_recall1)\n",
    "avgKnnF1 = mean(knn_f11)\n",
    "avgSvcAccuracy = mean(svc_accuracy1)\n",
    "avgSvcPrecision = mean(svc_precision1)\n",
    "avgSvcRecall = mean(svc_recall1)\n",
    "avgSvcF1 = mean(svc_f11)\n",
    "avgRfAccuracy = mean(rf_accuracy1)\n",
    "avgRfPrecision = mean(rf_precision1)\n",
    "avgRfRecall = mean(rf_recall1)\n",
    "avgRfF1 = mean(rf_f11)\n",
    "avgRidgeAccuracy = mean(ridge_accuracy1)\n",
    "avgRidgePrecision = mean(ridge_precision1)\n",
    "avgRidgeRecall = mean(ridge_recall1)\n",
    "avgRidgeF1 = mean(ridge_f11)\n",
    "avgGbcAccuracy = mean(gbc_accuracy1)\n",
    "avgGbcPrecision = mean(gbc_precision1)\n",
    "avgGbcRecall = mean(gbc_recall1)\n",
    "avgGbcF1 = mean(gbc_f11)\n",
    "avgXgbAccuracy = mean(xgb_accuracy1)\n",
    "avgXgbPrecision = mean(xgb_precision1)\n",
    "avgXgbRecall = mean(xgb_recall1)\n",
    "avgXgbF1 = mean(xgb_f11)\n",
    "avgLrAccuracy = mean(lr_accuracy1)\n",
    "avgLrPrecision = mean(lr_precision1)\n",
    "avgLrRecall = mean(lr_recall1)\n",
    "avgLrF1 = mean(lr_f11)\n",
    "avgDtAccuracy = mean(dt_accuracy1)\n",
    "avgDtPrecision = mean(dt_precision1)\n",
    "avgDtRecall = mean(dt_recall1)\n",
    "avgDtF1 = mean(dt_f11)\n",
    "avgLdaAccuracy = mean(lda_accuracy1)\n",
    "avgLdaPrecision = mean(lda_precision1)\n",
    "avgLdaRecall = mean(lda_recall1)\n",
    "avgLdaF1 = mean(lda_f11)\n",
    "avgQdaAccuracy = mean(qda_accuracy1)\n",
    "avgQdaPrecision = mean(qda_precision1)\n",
    "avgQdaRecall = mean(qda_recall1)\n",
    "avgQdaF1 = mean(qda_f11)\n",
    "avgNbAccuracy = mean(nb_accuracy1)\n",
    "avgNbPrecision = mean(nb_precision1)\n",
    "avgNbRecall = mean(nb_recall1)\n",
    "avgNbF1 = mean(nb_f11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avgCnnAccuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\2018-1-60-048@std.ewubd.edu\\CSE 497\\ThesisKfoldCombined.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=0'>1</a>\u001b[0m models_ensembling \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m       : [\u001b[39m'\u001b[39m\u001b[39mCNN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRNN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mGRU\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLSTM\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mKNN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSupport Vector Classifier\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRandom Forest\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRidge Classifier\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mGradient Boosting Classifier\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mXGBoost\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLogistic Regression\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDecision Tree\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLiner Discriminant Analysis\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mQuadratic Discremenant Analysis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNaive Baies\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m    : [avgCnnAccuracy,avgRnnAccuracy,avgGruAccuracy,avgLstmAccuracy,avgKnnAccuracy,avgSvcAccuracy,avgRfAccuracy,avgRidgeAccuracy,avgGbcAccuracy,avgXgbAccuracy,avgLrAccuracy,avgDtAccuracy,avgLdaAccuracy,avgQdaAccuracy,avgNbAccuracy],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m   : [avgCnnPrecision,avgRnnPrecision,avgGruPrecision,avgLstmPrecision,avgKnnPrecision,avgSvcPrecision,avgRfPrecision,avgRidgePrecision,avgGbcPrecision,avgXgbPrecision,avgLrPrecision,avgDtPrecision,avgLdaPrecision,avgQdaPrecision,avgNbPrecision],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m      : [avgCnnRecall,avgRnnRecall,avgGruRecall,avgLstmRecall,avgKnnRecall,avgSvcRecall,avgRfRecall,avgRidgeRecall,avgGbcRecall,avgXgbRecall,avgLrRecall,avgDtRecall,avgLdaRecall,avgQdaRecall,avgNbRecall],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1_score\u001b[39m\u001b[39m'\u001b[39m    : [avgCnnF1,avgRnnF1,avgGruF1,avgLstmF1,avgKnnF1,avgSvcF1,avgRfF1,avgRidgeF1,avgGbcF1,avgXgbF1,avgLrF1,avgDtF1,avgLdaF1,avgQdaF1,avgNbF1],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=6'>7</a>\u001b[0m     }, columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF1_score\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=8'>9</a>\u001b[0m models_ensembling\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'avgCnnAccuracy' is not defined"
     ]
    }
   ],
   "source": [
    "models_ensembling = pd.DataFrame({\n",
    "    'Model'       : ['CNN','RNN','GRU','LSTM','KNN','Support Vector Classifier','Random Forest','Ridge Classifier','Gradient Boosting Classifier','XGBoost','Logistic Regression','Decision Tree','Liner Discriminant Analysis','Quadratic Discremenant Analysis', 'Naive Baies'],\n",
    "    'Accuracy'    : [avgCnnAccuracy,avgRnnAccuracy,avgGruAccuracy,avgLstmAccuracy,avgKnnAccuracy,avgSvcAccuracy,avgRfAccuracy,avgRidgeAccuracy,avgGbcAccuracy,avgXgbAccuracy,avgLrAccuracy,avgDtAccuracy,avgLdaAccuracy,avgQdaAccuracy,avgNbAccuracy],\n",
    "    'Precision'   : [avgCnnPrecision,avgRnnPrecision,avgGruPrecision,avgLstmPrecision,avgKnnPrecision,avgSvcPrecision,avgRfPrecision,avgRidgePrecision,avgGbcPrecision,avgXgbPrecision,avgLrPrecision,avgDtPrecision,avgLdaPrecision,avgQdaPrecision,avgNbPrecision],\n",
    "    'Recall'      : [avgCnnRecall,avgRnnRecall,avgGruRecall,avgLstmRecall,avgKnnRecall,avgSvcRecall,avgRfRecall,avgRidgeRecall,avgGbcRecall,avgXgbRecall,avgLrRecall,avgDtRecall,avgLdaRecall,avgQdaRecall,avgNbRecall],\n",
    "    'F1_score'    : [avgCnnF1,avgRnnF1,avgGruF1,avgLstmF1,avgKnnF1,avgSvcF1,avgRfF1,avgRidgeF1,avgGbcF1,avgXgbF1,avgLrF1,avgDtF1,avgLdaF1,avgQdaF1,avgNbF1],\n",
    "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "models_ensembling.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "         DecisionTreeClassifier(),\n",
    "         SVC(probability = True),\n",
    "         LinearDiscriminantAnalysis(),\n",
    "         QuadraticDiscriminantAnalysis(),\n",
    "         RandomForestClassifier(),\n",
    "         KNeighborsClassifier(),XGBClassifier(),\n",
    "         GaussianNB(),GradientBoostingClassifier(),\n",
    "         ]\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    scores = cross_validate(model, inputs[train], targets[train], scoring=scoring, cv=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ens = list(zip(['lr', 'dt','gbc', 'svc', 'lda', 'qda', 'rf', 'knn', 'nb','xgb'], models))\n",
    "\n",
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'hard')\n",
    "model_ens.fit(inputs[train], targets[train])\n",
    "pred = model_ens.predict(inputs[test])\n",
    "\n",
    "acc_hard = accuracy_score(targets[test], pred)\n",
    "prec_hard = precision_score(targets[test], pred)\n",
    "recall_hard = recall_score(targets[test], pred)\n",
    "f1_hard = f1_score(targets[test], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'soft')\n",
    "model_ens.fit(inputs[train], targets[train])\n",
    "pred = model_ens.predict(inputs[test])\n",
    "prob = model_ens.predict_proba(inputs[test])[:,1]\n",
    "\n",
    "acc_soft = accuracy_score(targets[test], pred)\n",
    "prec_soft = precision_score(targets[test], pred)\n",
    "recall_soft = recall_score(targets[test], pred)\n",
    "f1_soft = f1_score(targets[test], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensebling_hard</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensembling_soft</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy  Precision  Recall  F1_score\n",
       "0   Ensebling_hard  0.982143   0.933333     1.0  0.965517\n",
       "1  Ensembling_soft  0.982143   0.933333     1.0  0.965517"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ensembling = pd.DataFrame({\n",
    "    'Model'       : ['Ensebling_hard', 'Ensembling_soft'],\n",
    "    'Accuracy'    : [acc_hard, acc_soft],\n",
    "    'Precision'   : [prec_hard, prec_soft],\n",
    "    'Recall'      : [recall_hard, recall_soft],\n",
    "    'F1_score'    : [f1_hard, f1_soft],\n",
    "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "models_ensembling.sort_values(by='Accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
