{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization,Conv1D,GRU,BatchNormalization, ReLU\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from array import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers  import Adam #only keras.optimizers use korle error dey\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "      \n",
    "%matplotlib inline\n",
    "from numpy import mean\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dropout, Flatten, Activation, Dense\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    " \n",
    "# Encode labels in column 'species'.\n",
    "df['diagnosis']= label_encoder.fit_transform(df['diagnosis'].map({'M':1,'B':0})) \n",
    "df['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=df['diagnosis']\n",
    "inputs = df.drop(columns=['diagnosis','id','Unnamed: 32'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "inputs=scaler.fit_transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(targets.shape)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.09706398],\n",
       "        [-2.07333501],\n",
       "        [ 1.26993369],\n",
       "        ...,\n",
       "        [ 2.29607613],\n",
       "        [ 2.75062224],\n",
       "        [ 1.93701461]],\n",
       "\n",
       "       [[ 1.82982061],\n",
       "        [-0.35363241],\n",
       "        [ 1.68595471],\n",
       "        ...,\n",
       "        [ 1.0870843 ],\n",
       "        [-0.24388967],\n",
       "        [ 0.28118999]],\n",
       "\n",
       "       [[ 1.57988811],\n",
       "        [ 0.45618695],\n",
       "        [ 1.56650313],\n",
       "        ...,\n",
       "        [ 1.95500035],\n",
       "        [ 1.152255  ],\n",
       "        [ 0.20139121]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.70228425],\n",
       "        [ 2.0455738 ],\n",
       "        [ 0.67267578],\n",
       "        ...,\n",
       "        [ 0.41406869],\n",
       "        [-1.10454895],\n",
       "        [-0.31840916]],\n",
       "\n",
       "       [[ 1.83834103],\n",
       "        [ 2.33645719],\n",
       "        [ 1.98252415],\n",
       "        ...,\n",
       "        [ 2.28998549],\n",
       "        [ 1.91908301],\n",
       "        [ 2.21963528]],\n",
       "\n",
       "       [[-1.80840125],\n",
       "        [ 1.22179204],\n",
       "        [-1.81438851],\n",
       "        ...,\n",
       "        [-1.74506282],\n",
       "        [-0.04813821],\n",
       "        [-0.75120669]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.reshape(569,30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_accuracy1=[]\n",
    "cnn_precision1=[]\n",
    "cnn_recall1=[]\n",
    "cnn_f11=[]\n",
    "rnn_accuracy1=[]\n",
    "rnn_precision1=[]\n",
    "rnn_recall1=[]\n",
    "rnn_f11=[]\n",
    "lstm_accuracy1=[]\n",
    "lstm_precision1=[]\n",
    "lstm_recall1=[]\n",
    "lstm_f11=[]\n",
    "gru_accuracy1=[]\n",
    "gru_precision1=[]\n",
    "gru_recall1=[]\n",
    "gru_f11=[]\n",
    "knn_accuracy1 = []\n",
    "knn_precision1 = []\n",
    "knn_recall1 = []\n",
    "knn_f11 = []\n",
    "svc_accuracy1 = []\n",
    "svc_precision1 = []\n",
    "svc_recall1 = []\n",
    "svc_f11 = []\n",
    "rf_accuracy1 = []\n",
    "rf_precision1 = []\n",
    "rf_recall1 = []\n",
    "rf_f11 = []\n",
    "ridge_accuracy1 = []\n",
    "ridge_precision1 = []\n",
    "ridge_recall1 = []\n",
    "ridge_f11 = []\n",
    "gbc_accuracy1 = []\n",
    "gbc_precision1 = []\n",
    "gbc_recall1 = []\n",
    "gbc_f11 = []\n",
    "xgb_accuracy1 = []\n",
    "xgb_precision1 = []\n",
    "xgb_recall1 = []\n",
    "xgb_f11 = []\n",
    "lr_accuracy1 = []\n",
    "lr_precision1 = []\n",
    "lr_recall1 = []\n",
    "lr_f11 = []\n",
    "dt_accuracy1 = []\n",
    "dt_precision1 = []\n",
    "dt_recall1 = []\n",
    "dt_f11 = []\n",
    "lda_accuracy1 = []\n",
    "lda_precision1 = []\n",
    "lda_recall1 = []\n",
    "lda_f11 = []\n",
    "qda_accuracy1 = []\n",
    "qda_precision1 = []\n",
    "qda_recall1 = []\n",
    "qda_f11 = []\n",
    "nb_accuracy1 = []\n",
    "nb_precision1 = []\n",
    "nb_recall1 = []\n",
    "nb_f11 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold No:   1\n",
      "CNN\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 3s 35ms/step - loss: 0.6424 - accuracy: 0.7051 - val_loss: 0.6267 - val_accuracy: 0.9023\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3651 - accuracy: 0.8418 - val_loss: 0.5831 - val_accuracy: 0.9297\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2717 - accuracy: 0.8887 - val_loss: 0.5446 - val_accuracy: 0.9336\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2104 - accuracy: 0.9180 - val_loss: 0.5098 - val_accuracy: 0.9453\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2264 - accuracy: 0.9180 - val_loss: 0.4773 - val_accuracy: 0.9512\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2100 - accuracy: 0.9121 - val_loss: 0.4410 - val_accuracy: 0.9512\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2192 - accuracy: 0.9199 - val_loss: 0.4070 - val_accuracy: 0.9570\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1575 - accuracy: 0.9434 - val_loss: 0.3724 - val_accuracy: 0.9570\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1656 - accuracy: 0.9336 - val_loss: 0.3423 - val_accuracy: 0.9609\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1666 - accuracy: 0.9355 - val_loss: 0.3120 - val_accuracy: 0.9590\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1544 - accuracy: 0.9336 - val_loss: 0.2843 - val_accuracy: 0.9609\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1372 - accuracy: 0.9531 - val_loss: 0.2572 - val_accuracy: 0.9668\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1342 - accuracy: 0.9453 - val_loss: 0.2309 - val_accuracy: 0.9727\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1237 - accuracy: 0.9570 - val_loss: 0.2070 - val_accuracy: 0.9746\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1114 - accuracy: 0.9629 - val_loss: 0.1844 - val_accuracy: 0.9766\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1220 - accuracy: 0.9492 - val_loss: 0.1643 - val_accuracy: 0.9766\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1310 - accuracy: 0.9473 - val_loss: 0.1476 - val_accuracy: 0.9766\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1098 - accuracy: 0.9531 - val_loss: 0.1322 - val_accuracy: 0.9766\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1091 - accuracy: 0.9570 - val_loss: 0.1202 - val_accuracy: 0.9766\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1132 - accuracy: 0.9688 - val_loss: 0.1099 - val_accuracy: 0.9766\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0983 - accuracy: 0.9590 - val_loss: 0.1003 - val_accuracy: 0.9805\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1002 - accuracy: 0.9629 - val_loss: 0.0915 - val_accuracy: 0.9824\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0904 - accuracy: 0.9727 - val_loss: 0.0849 - val_accuracy: 0.9824\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0698 - accuracy: 0.9746 - val_loss: 0.0791 - val_accuracy: 0.9844\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1202 - accuracy: 0.9590 - val_loss: 0.0744 - val_accuracy: 0.9844\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0831 - accuracy: 0.9648 - val_loss: 0.0699 - val_accuracy: 0.9844\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0841 - accuracy: 0.9727 - val_loss: 0.0666 - val_accuracy: 0.9844\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1098 - accuracy: 0.9453 - val_loss: 0.0633 - val_accuracy: 0.9844\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1194 - accuracy: 0.9492 - val_loss: 0.0608 - val_accuracy: 0.9844\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0945 - accuracy: 0.9629 - val_loss: 0.0584 - val_accuracy: 0.9844\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0819 - accuracy: 0.9688 - val_loss: 0.0560 - val_accuracy: 0.9844\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0951 - accuracy: 0.9590 - val_loss: 0.0539 - val_accuracy: 0.9863\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0865 - accuracy: 0.9707 - val_loss: 0.0525 - val_accuracy: 0.9844\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0998 - accuracy: 0.9648 - val_loss: 0.0512 - val_accuracy: 0.9844\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1033 - accuracy: 0.9570 - val_loss: 0.0499 - val_accuracy: 0.9844\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0756 - accuracy: 0.9746 - val_loss: 0.0487 - val_accuracy: 0.9863\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0890 - accuracy: 0.9648 - val_loss: 0.0474 - val_accuracy: 0.9883\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0602 - accuracy: 0.9805 - val_loss: 0.0461 - val_accuracy: 0.9902\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0709 - accuracy: 0.9727 - val_loss: 0.0450 - val_accuracy: 0.9902\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0709 - accuracy: 0.9805 - val_loss: 0.0441 - val_accuracy: 0.9902\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0733 - accuracy: 0.9766 - val_loss: 0.0431 - val_accuracy: 0.9883\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0906 - accuracy: 0.9727 - val_loss: 0.0425 - val_accuracy: 0.9902\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0781 - accuracy: 0.9727 - val_loss: 0.0417 - val_accuracy: 0.9922\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0719 - accuracy: 0.9785 - val_loss: 0.0411 - val_accuracy: 0.9902\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0875 - accuracy: 0.9727 - val_loss: 0.0405 - val_accuracy: 0.9922\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0686 - accuracy: 0.9746 - val_loss: 0.0397 - val_accuracy: 0.9922\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0983 - accuracy: 0.9629 - val_loss: 0.0392 - val_accuracy: 0.9922\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0601 - accuracy: 0.9824 - val_loss: 0.0385 - val_accuracy: 0.9922\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0694 - accuracy: 0.9766 - val_loss: 0.0377 - val_accuracy: 0.9922\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0598 - accuracy: 0.9785 - val_loss: 0.0372 - val_accuracy: 0.9922\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0794 - accuracy: 0.9707 - val_loss: 0.0364 - val_accuracy: 0.9922\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0775 - accuracy: 0.9727 - val_loss: 0.0357 - val_accuracy: 0.9922\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 0.9707 - val_loss: 0.0351 - val_accuracy: 0.9922\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0770 - accuracy: 0.9746 - val_loss: 0.0346 - val_accuracy: 0.9922\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 0.0341 - val_accuracy: 0.9922\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9805 - val_loss: 0.0338 - val_accuracy: 0.9922\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0679 - accuracy: 0.9785 - val_loss: 0.0334 - val_accuracy: 0.9902\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0781 - accuracy: 0.9766 - val_loss: 0.0328 - val_accuracy: 0.9902\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0700 - accuracy: 0.9727 - val_loss: 0.0324 - val_accuracy: 0.9902\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0557 - accuracy: 0.9805 - val_loss: 0.0320 - val_accuracy: 0.9902\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "RNN\n",
      "Epoch 1/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.1881 - accuracy: 0.9258 - val_loss: 0.0746 - val_accuracy: 0.9824\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9805 - val_loss: 0.0517 - val_accuracy: 0.9883\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9844 - val_loss: 0.0402 - val_accuracy: 0.9922\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9883 - val_loss: 0.0342 - val_accuracy: 0.9902\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9902 - val_loss: 0.0281 - val_accuracy: 0.9922\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.0236 - val_accuracy: 0.9941\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9941 - val_loss: 0.0192 - val_accuracy: 0.9961\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.0184 - val_accuracy: 0.9941\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.0177 - val_accuracy: 0.9941\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0131 - val_accuracy: 0.9961\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9902 - val_loss: 0.0099 - val_accuracy: 0.9961\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9961 - val_loss: 0.0115 - val_accuracy: 0.9941\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9941 - val_loss: 0.0075 - val_accuracy: 0.9961\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0043 - val_accuracy: 0.9980\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9961 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9902 - val_loss: 0.0137 - val_accuracy: 0.9961\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9922 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 9.1499e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 9.6544e-04 - accuracy: 1.0000 - val_loss: 7.5526e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.9341e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 8.9566e-04 - accuracy: 1.0000 - val_loss: 6.0511e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9961 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.9633e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 7.2822e-04 - accuracy: 1.0000 - val_loss: 4.9962e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.7251e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 6.9201e-04 - accuracy: 1.0000 - val_loss: 3.3203e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 6.6362e-04 - accuracy: 1.0000 - val_loss: 2.8931e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 4.0184e-04 - accuracy: 1.0000 - val_loss: 2.4114e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 4.6271e-04 - accuracy: 1.0000 - val_loss: 2.2614e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 4.1135e-04 - accuracy: 1.0000 - val_loss: 2.1078e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 2.7775e-04 - accuracy: 1.0000 - val_loss: 1.7677e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 2.5467e-04 - accuracy: 1.0000 - val_loss: 1.6756e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 3.4423e-04 - accuracy: 1.0000 - val_loss: 1.5100e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 2.3700e-04 - accuracy: 1.0000 - val_loss: 1.4231e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.8012e-04 - accuracy: 1.0000 - val_loss: 1.3021e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9980 - val_loss: 0.0027 - val_accuracy: 0.9980\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0109 - val_accuracy: 0.9961\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9980\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 4.5014e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 6.4383e-04 - accuracy: 1.0000 - val_loss: 2.9920e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 6.9834e-04 - accuracy: 1.0000 - val_loss: 2.7461e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9961\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9961 - val_loss: 0.0256 - val_accuracy: 0.9941\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9980\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9961 - val_loss: 0.0035 - val_accuracy: 0.9980\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0029 - val_accuracy: 0.9980\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0044 - val_accuracy: 0.9980\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 8s 151ms/step - loss: 0.1698 - accuracy: 0.7930 - val_loss: 0.1205 - val_accuracy: 0.8535\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.1077 - accuracy: 0.8691 - val_loss: 0.0933 - val_accuracy: 0.8848\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0933 - accuracy: 0.8984 - val_loss: 0.0651 - val_accuracy: 0.9141\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0684 - accuracy: 0.9258 - val_loss: 0.0543 - val_accuracy: 0.9336\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0571 - accuracy: 0.9355 - val_loss: 0.0462 - val_accuracy: 0.9434\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0494 - accuracy: 0.9453 - val_loss: 0.0443 - val_accuracy: 0.9414\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0476 - accuracy: 0.9395 - val_loss: 0.0447 - val_accuracy: 0.9395\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0450 - accuracy: 0.9473 - val_loss: 0.0378 - val_accuracy: 0.9492\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0462 - accuracy: 0.9473 - val_loss: 0.0406 - val_accuracy: 0.9434\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0464 - accuracy: 0.9453 - val_loss: 0.0431 - val_accuracy: 0.9492\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0456 - accuracy: 0.9434 - val_loss: 0.0382 - val_accuracy: 0.9434\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0428 - accuracy: 0.9551 - val_loss: 0.0367 - val_accuracy: 0.9473\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0435 - accuracy: 0.9492 - val_loss: 0.0367 - val_accuracy: 0.9453\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0423 - accuracy: 0.9473 - val_loss: 0.0359 - val_accuracy: 0.9512\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0443 - accuracy: 0.9531 - val_loss: 0.0354 - val_accuracy: 0.9512\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0428 - accuracy: 0.9512 - val_loss: 0.0363 - val_accuracy: 0.9531\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0423 - accuracy: 0.9473 - val_loss: 0.0365 - val_accuracy: 0.9473\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0423 - accuracy: 0.9453 - val_loss: 0.0357 - val_accuracy: 0.9551\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0388 - accuracy: 0.9551 - val_loss: 0.0340 - val_accuracy: 0.9531\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0392 - accuracy: 0.9473 - val_loss: 0.0335 - val_accuracy: 0.9551\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0375 - accuracy: 0.9531 - val_loss: 0.0399 - val_accuracy: 0.9492\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0412 - accuracy: 0.9473 - val_loss: 0.0330 - val_accuracy: 0.9531\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0395 - accuracy: 0.9609 - val_loss: 0.0339 - val_accuracy: 0.9531\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0386 - accuracy: 0.9473 - val_loss: 0.0341 - val_accuracy: 0.9629\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0389 - accuracy: 0.9609 - val_loss: 0.0314 - val_accuracy: 0.9609\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0357 - accuracy: 0.9590 - val_loss: 0.0326 - val_accuracy: 0.9609\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0332 - accuracy: 0.9609 - val_loss: 0.0279 - val_accuracy: 0.9648\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0359 - accuracy: 0.9551 - val_loss: 0.0334 - val_accuracy: 0.9629\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0359 - accuracy: 0.9531 - val_loss: 0.0297 - val_accuracy: 0.9668\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0345 - accuracy: 0.9590 - val_loss: 0.0290 - val_accuracy: 0.9570\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0339 - accuracy: 0.9570 - val_loss: 0.0364 - val_accuracy: 0.9512\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0396 - accuracy: 0.9531 - val_loss: 0.0296 - val_accuracy: 0.9590\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0339 - accuracy: 0.9551 - val_loss: 0.0284 - val_accuracy: 0.9688\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0345 - accuracy: 0.9648 - val_loss: 0.0292 - val_accuracy: 0.9668\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0314 - accuracy: 0.9648 - val_loss: 0.0254 - val_accuracy: 0.9688\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0285 - accuracy: 0.9648 - val_loss: 0.0252 - val_accuracy: 0.9629\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0314 - accuracy: 0.9609 - val_loss: 0.0259 - val_accuracy: 0.9648\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0301 - accuracy: 0.9629 - val_loss: 0.0249 - val_accuracy: 0.9629\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0288 - accuracy: 0.9629 - val_loss: 0.0270 - val_accuracy: 0.9648\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0302 - accuracy: 0.9648 - val_loss: 0.0250 - val_accuracy: 0.9668\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0273 - accuracy: 0.9668 - val_loss: 0.0258 - val_accuracy: 0.9688\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0323 - accuracy: 0.9629 - val_loss: 0.0273 - val_accuracy: 0.9688\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0292 - accuracy: 0.9648 - val_loss: 0.0232 - val_accuracy: 0.9707\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0270 - accuracy: 0.9668 - val_loss: 0.0218 - val_accuracy: 0.9727\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0263 - accuracy: 0.9688 - val_loss: 0.0238 - val_accuracy: 0.9688\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0294 - accuracy: 0.9648 - val_loss: 0.0218 - val_accuracy: 0.9707\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0261 - accuracy: 0.9707 - val_loss: 0.0203 - val_accuracy: 0.9746\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0233 - accuracy: 0.9766 - val_loss: 0.0194 - val_accuracy: 0.9727\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0266 - accuracy: 0.9727 - val_loss: 0.0208 - val_accuracy: 0.9707\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0259 - accuracy: 0.9668 - val_loss: 0.0221 - val_accuracy: 0.9707\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0262 - accuracy: 0.9668 - val_loss: 0.0216 - val_accuracy: 0.9727\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0271 - accuracy: 0.9688 - val_loss: 0.0189 - val_accuracy: 0.9727\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0255 - accuracy: 0.9688 - val_loss: 0.0194 - val_accuracy: 0.9785\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0241 - accuracy: 0.9766 - val_loss: 0.0197 - val_accuracy: 0.9766\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0241 - accuracy: 0.9727 - val_loss: 0.0193 - val_accuracy: 0.9746\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0231 - accuracy: 0.9668 - val_loss: 0.0193 - val_accuracy: 0.9766\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0227 - accuracy: 0.9746 - val_loss: 0.0179 - val_accuracy: 0.9785\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0224 - accuracy: 0.9766 - val_loss: 0.0177 - val_accuracy: 0.9785\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0233 - accuracy: 0.9746 - val_loss: 0.0175 - val_accuracy: 0.9766\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0221 - accuracy: 0.9766 - val_loss: 0.0174 - val_accuracy: 0.9766\n",
      "2/2 [==============================] - 1s 15ms/step\n",
      "GRU\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 8s 131ms/step - loss: 0.1601 - accuracy: 0.8086 - val_loss: 0.0854 - val_accuracy: 0.9082\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.0969 - accuracy: 0.8809 - val_loss: 0.0812 - val_accuracy: 0.9141\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0860 - accuracy: 0.9082 - val_loss: 0.0783 - val_accuracy: 0.9141\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0821 - accuracy: 0.9219 - val_loss: 0.0758 - val_accuracy: 0.9160\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0791 - accuracy: 0.9277 - val_loss: 0.0742 - val_accuracy: 0.9297\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0761 - accuracy: 0.9258 - val_loss: 0.0635 - val_accuracy: 0.9453\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0678 - accuracy: 0.9336 - val_loss: 0.0571 - val_accuracy: 0.9512\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0658 - accuracy: 0.9375 - val_loss: 0.0519 - val_accuracy: 0.9629\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0548 - accuracy: 0.9590 - val_loss: 0.0469 - val_accuracy: 0.9609\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0573 - accuracy: 0.9590 - val_loss: 0.0433 - val_accuracy: 0.9648\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0543 - accuracy: 0.9531 - val_loss: 0.0444 - val_accuracy: 0.9609\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.0487 - accuracy: 0.9629 - val_loss: 0.0378 - val_accuracy: 0.9648\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0463 - accuracy: 0.9590 - val_loss: 0.0359 - val_accuracy: 0.9629\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0466 - accuracy: 0.9668 - val_loss: 0.0369 - val_accuracy: 0.9590\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0453 - accuracy: 0.9609 - val_loss: 0.0320 - val_accuracy: 0.9648\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0398 - accuracy: 0.9648 - val_loss: 0.0342 - val_accuracy: 0.9688\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0397 - accuracy: 0.9668 - val_loss: 0.0300 - val_accuracy: 0.9629\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.0380 - accuracy: 0.9688 - val_loss: 0.0292 - val_accuracy: 0.9727\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.0392 - accuracy: 0.9609 - val_loss: 0.0307 - val_accuracy: 0.9668\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0356 - accuracy: 0.9648 - val_loss: 0.0279 - val_accuracy: 0.9668\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0351 - accuracy: 0.9648 - val_loss: 0.0304 - val_accuracy: 0.9609\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0349 - accuracy: 0.9609 - val_loss: 0.0294 - val_accuracy: 0.9688\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0372 - accuracy: 0.9648 - val_loss: 0.0300 - val_accuracy: 0.9707\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0338 - accuracy: 0.9609 - val_loss: 0.0263 - val_accuracy: 0.9648\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0320 - accuracy: 0.9668 - val_loss: 0.0242 - val_accuracy: 0.9707\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0300 - accuracy: 0.9688 - val_loss: 0.0233 - val_accuracy: 0.9727\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0303 - accuracy: 0.9707 - val_loss: 0.0268 - val_accuracy: 0.9688\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0285 - accuracy: 0.9727 - val_loss: 0.0225 - val_accuracy: 0.9746\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.0276 - accuracy: 0.9688 - val_loss: 0.0247 - val_accuracy: 0.9727\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.0285 - accuracy: 0.9707 - val_loss: 0.0226 - val_accuracy: 0.9746\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0296 - accuracy: 0.9668 - val_loss: 0.0229 - val_accuracy: 0.9746\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.0303 - accuracy: 0.9668 - val_loss: 0.0237 - val_accuracy: 0.9746\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.0281 - accuracy: 0.9648 - val_loss: 0.0238 - val_accuracy: 0.9688\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.0295 - accuracy: 0.9727 - val_loss: 0.0228 - val_accuracy: 0.9746\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0285 - accuracy: 0.9766 - val_loss: 0.0209 - val_accuracy: 0.9746\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0274 - accuracy: 0.9727 - val_loss: 0.0217 - val_accuracy: 0.9746\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0259 - accuracy: 0.9785 - val_loss: 0.0208 - val_accuracy: 0.9766\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0316 - accuracy: 0.9648 - val_loss: 0.0210 - val_accuracy: 0.9707\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.0281 - accuracy: 0.9688 - val_loss: 0.0211 - val_accuracy: 0.9766\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0272 - accuracy: 0.9746 - val_loss: 0.0214 - val_accuracy: 0.9746\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0268 - accuracy: 0.9707 - val_loss: 0.0206 - val_accuracy: 0.9746\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0237 - accuracy: 0.9766 - val_loss: 0.0215 - val_accuracy: 0.9746\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.0252 - accuracy: 0.9746 - val_loss: 0.0206 - val_accuracy: 0.9805\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0240 - accuracy: 0.9746 - val_loss: 0.0186 - val_accuracy: 0.9766\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.0261 - accuracy: 0.9766 - val_loss: 0.0190 - val_accuracy: 0.9766\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.0251 - accuracy: 0.9785 - val_loss: 0.0191 - val_accuracy: 0.9785\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0237 - accuracy: 0.9766 - val_loss: 0.0185 - val_accuracy: 0.9785\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.0235 - accuracy: 0.9746 - val_loss: 0.0176 - val_accuracy: 0.9805\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.0234 - accuracy: 0.9785 - val_loss: 0.0191 - val_accuracy: 0.9785\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.0250 - accuracy: 0.9746 - val_loss: 0.0188 - val_accuracy: 0.9805\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0245 - accuracy: 0.9766 - val_loss: 0.0187 - val_accuracy: 0.9824\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0226 - accuracy: 0.9785 - val_loss: 0.0176 - val_accuracy: 0.9785\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0212 - accuracy: 0.9805 - val_loss: 0.0170 - val_accuracy: 0.9824\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0227 - accuracy: 0.9785 - val_loss: 0.0180 - val_accuracy: 0.9805\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.0240 - accuracy: 0.9785 - val_loss: 0.0177 - val_accuracy: 0.9805\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0210 - accuracy: 0.9785 - val_loss: 0.0161 - val_accuracy: 0.9824\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.0217 - accuracy: 0.9746 - val_loss: 0.0170 - val_accuracy: 0.9805\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.0236 - accuracy: 0.9785 - val_loss: 0.0165 - val_accuracy: 0.9824\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0210 - accuracy: 0.9805 - val_loss: 0.0165 - val_accuracy: 0.9805\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.0205 - accuracy: 0.9805 - val_loss: 0.0157 - val_accuracy: 0.9805\n",
      "2/2 [==============================] - 1s 14ms/step\n",
      "KNN\n",
      "SVC\n",
      "Random Forest\n",
      "Ridge Classifier\n",
      "Gradient Boosting\n",
      "XGBoost\n",
      "Logistic Regression\n",
      "Decision Tree\n",
      "Linear Discremental Analysis\n",
      "Quadratic Discremental Analysis\n",
      "Naive Bayes\n",
      "Fold No:   2\n",
      "CNN\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 2s 22ms/step - loss: 0.9007 - accuracy: 0.5762 - val_loss: 0.6357 - val_accuracy: 0.8633\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5734 - accuracy: 0.7246 - val_loss: 0.6053 - val_accuracy: 0.8750\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5792 - val_accuracy: 0.8809\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4103 - accuracy: 0.8438 - val_loss: 0.5531 - val_accuracy: 0.8965\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2968 - accuracy: 0.8730 - val_loss: 0.5244 - val_accuracy: 0.9199\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2700 - accuracy: 0.8770 - val_loss: 0.4935 - val_accuracy: 0.9434\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2433 - accuracy: 0.9043 - val_loss: 0.4621 - val_accuracy: 0.9531\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2632 - accuracy: 0.9082 - val_loss: 0.4278 - val_accuracy: 0.9590\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2347 - accuracy: 0.9082 - val_loss: 0.3936 - val_accuracy: 0.9590\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1959 - accuracy: 0.9219 - val_loss: 0.3614 - val_accuracy: 0.9609\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1776 - accuracy: 0.9395 - val_loss: 0.3300 - val_accuracy: 0.9648\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1888 - accuracy: 0.9219 - val_loss: 0.2996 - val_accuracy: 0.9648\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1770 - accuracy: 0.9453 - val_loss: 0.2708 - val_accuracy: 0.9707\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1585 - accuracy: 0.9453 - val_loss: 0.2459 - val_accuracy: 0.9727\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1555 - accuracy: 0.9414 - val_loss: 0.2226 - val_accuracy: 0.9707\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1584 - accuracy: 0.9355 - val_loss: 0.2002 - val_accuracy: 0.9707\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1392 - accuracy: 0.9414 - val_loss: 0.1812 - val_accuracy: 0.9707\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1433 - accuracy: 0.9434 - val_loss: 0.1649 - val_accuracy: 0.9766\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1090 - accuracy: 0.9727 - val_loss: 0.1489 - val_accuracy: 0.9766\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1079 - accuracy: 0.9609 - val_loss: 0.1356 - val_accuracy: 0.9766\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1122 - accuracy: 0.9629 - val_loss: 0.1249 - val_accuracy: 0.9766\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.9473 - val_loss: 0.1160 - val_accuracy: 0.9766\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1275 - accuracy: 0.9492 - val_loss: 0.1077 - val_accuracy: 0.9766\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1175 - accuracy: 0.9570 - val_loss: 0.1001 - val_accuracy: 0.9785\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9668 - val_loss: 0.0938 - val_accuracy: 0.9805\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1037 - accuracy: 0.9590 - val_loss: 0.0892 - val_accuracy: 0.9805\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1061 - accuracy: 0.9570 - val_loss: 0.0843 - val_accuracy: 0.9805\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1214 - accuracy: 0.9570 - val_loss: 0.0795 - val_accuracy: 0.9824\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0920 - accuracy: 0.9648 - val_loss: 0.0755 - val_accuracy: 0.9824\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0968 - accuracy: 0.9648 - val_loss: 0.0718 - val_accuracy: 0.9824\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1181 - accuracy: 0.9629 - val_loss: 0.0688 - val_accuracy: 0.9824\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0920 - accuracy: 0.9746 - val_loss: 0.0662 - val_accuracy: 0.9824\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1032 - accuracy: 0.9590 - val_loss: 0.0634 - val_accuracy: 0.9844\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0848 - accuracy: 0.9648 - val_loss: 0.0612 - val_accuracy: 0.9844\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0913 - accuracy: 0.9629 - val_loss: 0.0591 - val_accuracy: 0.9863\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0863 - accuracy: 0.9746 - val_loss: 0.0581 - val_accuracy: 0.9863\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1090 - accuracy: 0.9609 - val_loss: 0.0572 - val_accuracy: 0.9844\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0997 - accuracy: 0.9629 - val_loss: 0.0556 - val_accuracy: 0.9844\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0950 - accuracy: 0.9668 - val_loss: 0.0550 - val_accuracy: 0.9844\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0939 - accuracy: 0.9648 - val_loss: 0.0534 - val_accuracy: 0.9863\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0727 - accuracy: 0.9766 - val_loss: 0.0523 - val_accuracy: 0.9863\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0942 - accuracy: 0.9570 - val_loss: 0.0511 - val_accuracy: 0.9883\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0899 - accuracy: 0.9629 - val_loss: 0.0500 - val_accuracy: 0.9883\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0851 - accuracy: 0.9688 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0909 - accuracy: 0.9590 - val_loss: 0.0474 - val_accuracy: 0.9883\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0765 - accuracy: 0.9727 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0895 - accuracy: 0.9707 - val_loss: 0.0458 - val_accuracy: 0.9883\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0805 - accuracy: 0.9668 - val_loss: 0.0455 - val_accuracy: 0.9863\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0721 - accuracy: 0.9766 - val_loss: 0.0459 - val_accuracy: 0.9863\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9688 - val_loss: 0.0451 - val_accuracy: 0.9863\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0680 - accuracy: 0.9805 - val_loss: 0.0444 - val_accuracy: 0.9883\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0669 - accuracy: 0.9824 - val_loss: 0.0442 - val_accuracy: 0.9863\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0781 - accuracy: 0.9766 - val_loss: 0.0433 - val_accuracy: 0.9863\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0848 - accuracy: 0.9668 - val_loss: 0.0426 - val_accuracy: 0.9883\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0635 - accuracy: 0.9766 - val_loss: 0.0423 - val_accuracy: 0.9883\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0753 - accuracy: 0.9648 - val_loss: 0.0411 - val_accuracy: 0.9883\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9746 - val_loss: 0.0405 - val_accuracy: 0.9863\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0760 - accuracy: 0.9746 - val_loss: 0.0405 - val_accuracy: 0.9863\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1013 - accuracy: 0.9668 - val_loss: 0.0395 - val_accuracy: 0.9863\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0744 - accuracy: 0.9746 - val_loss: 0.0390 - val_accuracy: 0.9863\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CE6F1944C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "RNN\n",
      "Epoch 1/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.1955 - accuracy: 0.9297 - val_loss: 0.0768 - val_accuracy: 0.9785\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9766 - val_loss: 0.0547 - val_accuracy: 0.9863\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0590 - accuracy: 0.9766 - val_loss: 0.0442 - val_accuracy: 0.9863\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.0376 - val_accuracy: 0.9922\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0364 - val_accuracy: 0.9883\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.0268 - val_accuracy: 0.9902\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0226 - val_accuracy: 0.9922\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0241 - accuracy: 0.9902 - val_loss: 0.0137 - val_accuracy: 0.9980\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.0120 - val_accuracy: 0.9941\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0152 - val_accuracy: 0.9941\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9883 - val_loss: 0.0488 - val_accuracy: 0.9863\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9883 - val_loss: 0.0106 - val_accuracy: 0.9961\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9980\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.0047 - val_accuracy: 0.9980\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9980\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9961\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9961 - val_loss: 0.0060 - val_accuracy: 0.9961\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 7.4812e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.4897e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 7.9515e-04 - accuracy: 1.0000 - val_loss: 5.6808e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 5.0133e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 9.2305e-04 - accuracy: 1.0000 - val_loss: 4.8420e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 5.4845e-04 - accuracy: 1.0000 - val_loss: 4.4924e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.3180e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.7445e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.0980e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9961 - val_loss: 0.0107 - val_accuracy: 0.9922\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0220 - val_accuracy: 0.9941\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9961 - val_loss: 0.0045 - val_accuracy: 0.9980\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 7.6418e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 9.6458e-04 - accuracy: 1.0000 - val_loss: 7.2528e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.3847e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.6815e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 8.0860e-04 - accuracy: 1.0000 - val_loss: 3.5044e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 8.5708e-04 - accuracy: 1.0000 - val_loss: 2.9048e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 4.1304e-04 - accuracy: 1.0000 - val_loss: 2.6238e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 4.9412e-04 - accuracy: 1.0000 - val_loss: 2.3618e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 3.7727e-04 - accuracy: 1.0000 - val_loss: 2.1511e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 3.1323e-04 - accuracy: 1.0000 - val_loss: 1.8014e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 3.0461e-04 - accuracy: 1.0000 - val_loss: 1.6384e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.6894e-04 - accuracy: 1.0000 - val_loss: 1.5353e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 2.3543e-04 - accuracy: 1.0000 - val_loss: 1.3008e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 7.5982e-04 - accuracy: 1.0000 - val_loss: 1.3294e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 5.5419e-04 - accuracy: 1.0000 - val_loss: 1.1933e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 3.1610e-04 - accuracy: 1.0000 - val_loss: 1.1417e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 3.5463e-04 - accuracy: 1.0000 - val_loss: 9.3911e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 1.0188e-04 - accuracy: 1.0000 - val_loss: 8.4300e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CE6F196050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 12s 251ms/step - loss: 0.1798 - accuracy: 0.7773 - val_loss: 0.1051 - val_accuracy: 0.8711\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.1114 - accuracy: 0.8477 - val_loss: 0.0935 - val_accuracy: 0.8848\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0940 - accuracy: 0.8906 - val_loss: 0.0715 - val_accuracy: 0.9043\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0639 - accuracy: 0.9219 - val_loss: 0.0460 - val_accuracy: 0.9414\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.0588 - accuracy: 0.9453 - val_loss: 0.0610 - val_accuracy: 0.9492\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.0624 - accuracy: 0.9375 - val_loss: 0.0445 - val_accuracy: 0.9453\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0527 - accuracy: 0.9414 - val_loss: 0.0403 - val_accuracy: 0.9473\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0572 - accuracy: 0.9395 - val_loss: 0.0615 - val_accuracy: 0.9512\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0540 - accuracy: 0.9414 - val_loss: 0.0402 - val_accuracy: 0.9453\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0512 - accuracy: 0.9473 - val_loss: 0.0392 - val_accuracy: 0.9453\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0478 - accuracy: 0.9414 - val_loss: 0.0399 - val_accuracy: 0.9473\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0503 - accuracy: 0.9453 - val_loss: 0.0423 - val_accuracy: 0.9434\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0490 - accuracy: 0.9453 - val_loss: 0.0381 - val_accuracy: 0.9453\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0466 - accuracy: 0.9492 - val_loss: 0.0467 - val_accuracy: 0.9434\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0477 - accuracy: 0.9395 - val_loss: 0.0394 - val_accuracy: 0.9453\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0435 - accuracy: 0.9414 - val_loss: 0.0365 - val_accuracy: 0.9512\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0429 - accuracy: 0.9512 - val_loss: 0.0368 - val_accuracy: 0.9551\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.0411 - accuracy: 0.9512 - val_loss: 0.0348 - val_accuracy: 0.9531\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0396 - accuracy: 0.9531 - val_loss: 0.0364 - val_accuracy: 0.9473\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0434 - accuracy: 0.9473 - val_loss: 0.0357 - val_accuracy: 0.9551\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.0402 - accuracy: 0.9453 - val_loss: 0.0388 - val_accuracy: 0.9590\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0415 - accuracy: 0.9453 - val_loss: 0.0346 - val_accuracy: 0.9512\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0378 - accuracy: 0.9512 - val_loss: 0.0333 - val_accuracy: 0.9609\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.0403 - accuracy: 0.9512 - val_loss: 0.0409 - val_accuracy: 0.9453\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0433 - accuracy: 0.9434 - val_loss: 0.0357 - val_accuracy: 0.9531\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.0457 - accuracy: 0.9453 - val_loss: 0.0458 - val_accuracy: 0.9512\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0419 - accuracy: 0.9492 - val_loss: 0.0377 - val_accuracy: 0.9531\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0389 - accuracy: 0.9492 - val_loss: 0.0325 - val_accuracy: 0.9629\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0357 - accuracy: 0.9570 - val_loss: 0.0317 - val_accuracy: 0.9570\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0383 - accuracy: 0.9531 - val_loss: 0.0314 - val_accuracy: 0.9609\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0360 - accuracy: 0.9629 - val_loss: 0.0351 - val_accuracy: 0.9609\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0344 - accuracy: 0.9531 - val_loss: 0.0288 - val_accuracy: 0.9629\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0352 - accuracy: 0.9609 - val_loss: 0.0289 - val_accuracy: 0.9668\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0333 - accuracy: 0.9668 - val_loss: 0.0338 - val_accuracy: 0.9551\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0361 - accuracy: 0.9551 - val_loss: 0.0293 - val_accuracy: 0.9648\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0321 - accuracy: 0.9668 - val_loss: 0.0267 - val_accuracy: 0.9648\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0318 - accuracy: 0.9551 - val_loss: 0.0318 - val_accuracy: 0.9570\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0338 - accuracy: 0.9590 - val_loss: 0.0304 - val_accuracy: 0.9648\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0316 - accuracy: 0.9688 - val_loss: 0.0296 - val_accuracy: 0.9609\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.0333 - accuracy: 0.9609 - val_loss: 0.0268 - val_accuracy: 0.9648\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0290 - accuracy: 0.9668 - val_loss: 0.0256 - val_accuracy: 0.9688\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0302 - accuracy: 0.9648 - val_loss: 0.0244 - val_accuracy: 0.9688\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0272 - accuracy: 0.9629 - val_loss: 0.0231 - val_accuracy: 0.9688\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0274 - accuracy: 0.9668 - val_loss: 0.0232 - val_accuracy: 0.9688\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0277 - accuracy: 0.9648 - val_loss: 0.0228 - val_accuracy: 0.9707\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0256 - accuracy: 0.9668 - val_loss: 0.0302 - val_accuracy: 0.9570\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0320 - accuracy: 0.9570 - val_loss: 0.0248 - val_accuracy: 0.9648\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0248 - val_accuracy: 0.9688\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0280 - accuracy: 0.9648 - val_loss: 0.0237 - val_accuracy: 0.9668\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0261 - accuracy: 0.9648 - val_loss: 0.0227 - val_accuracy: 0.9648\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0274 - accuracy: 0.9668 - val_loss: 0.0256 - val_accuracy: 0.9688\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0286 - accuracy: 0.9629 - val_loss: 0.0214 - val_accuracy: 0.9707\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0257 - accuracy: 0.9648 - val_loss: 0.0224 - val_accuracy: 0.9727\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0268 - accuracy: 0.9707 - val_loss: 0.0271 - val_accuracy: 0.9629\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0302 - accuracy: 0.9668 - val_loss: 0.0261 - val_accuracy: 0.9629\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0274 - accuracy: 0.9648 - val_loss: 0.0216 - val_accuracy: 0.9668\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0282 - accuracy: 0.9668 - val_loss: 0.0212 - val_accuracy: 0.9688\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0273 - accuracy: 0.9707 - val_loss: 0.0215 - val_accuracy: 0.9727\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.0245 - accuracy: 0.9727 - val_loss: 0.0203 - val_accuracy: 0.9727\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0258 - accuracy: 0.9727 - val_loss: 0.0206 - val_accuracy: 0.9727\n",
      "2/2 [==============================] - 2s 13ms/step\n",
      "GRU\n",
      "Epoch 1/60\n",
      "16/16 [==============================] - 8s 147ms/step - loss: 0.1360 - accuracy: 0.8535 - val_loss: 0.0865 - val_accuracy: 0.9219\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0887 - accuracy: 0.9141 - val_loss: 0.0819 - val_accuracy: 0.9277\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0837 - accuracy: 0.9199 - val_loss: 0.0753 - val_accuracy: 0.9277\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0779 - accuracy: 0.9258 - val_loss: 0.0727 - val_accuracy: 0.9316\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0765 - accuracy: 0.9355 - val_loss: 0.0661 - val_accuracy: 0.9375\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0710 - accuracy: 0.9473 - val_loss: 0.0600 - val_accuracy: 0.9531\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0690 - accuracy: 0.9473 - val_loss: 0.0579 - val_accuracy: 0.9648\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0625 - accuracy: 0.9590 - val_loss: 0.0575 - val_accuracy: 0.9570\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0583 - accuracy: 0.9453 - val_loss: 0.0502 - val_accuracy: 0.9648\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0592 - accuracy: 0.9512 - val_loss: 0.0474 - val_accuracy: 0.9590\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0544 - accuracy: 0.9590 - val_loss: 0.0485 - val_accuracy: 0.9629\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0523 - accuracy: 0.9629 - val_loss: 0.0439 - val_accuracy: 0.9629\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0542 - accuracy: 0.9531 - val_loss: 0.0418 - val_accuracy: 0.9570\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0500 - accuracy: 0.9590 - val_loss: 0.0379 - val_accuracy: 0.9590\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0437 - accuracy: 0.9609 - val_loss: 0.0366 - val_accuracy: 0.9668\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0431 - accuracy: 0.9648 - val_loss: 0.0317 - val_accuracy: 0.9668\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0370 - accuracy: 0.9668 - val_loss: 0.0288 - val_accuracy: 0.9707\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0376 - accuracy: 0.9668 - val_loss: 0.0301 - val_accuracy: 0.9688\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0368 - accuracy: 0.9648 - val_loss: 0.0317 - val_accuracy: 0.9707\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0348 - accuracy: 0.9707 - val_loss: 0.0267 - val_accuracy: 0.9707\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0336 - accuracy: 0.9668 - val_loss: 0.0244 - val_accuracy: 0.9727\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0321 - accuracy: 0.9746 - val_loss: 0.0244 - val_accuracy: 0.9707\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0339 - accuracy: 0.9727 - val_loss: 0.0248 - val_accuracy: 0.9746\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0304 - accuracy: 0.9688 - val_loss: 0.0239 - val_accuracy: 0.9727\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0293 - accuracy: 0.9688 - val_loss: 0.0234 - val_accuracy: 0.9727\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0300 - accuracy: 0.9746 - val_loss: 0.0244 - val_accuracy: 0.9746\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0309 - accuracy: 0.9727 - val_loss: 0.0244 - val_accuracy: 0.9746\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0311 - accuracy: 0.9746 - val_loss: 0.0220 - val_accuracy: 0.9746\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0298 - accuracy: 0.9727 - val_loss: 0.0225 - val_accuracy: 0.9707\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0307 - accuracy: 0.9727 - val_loss: 0.0232 - val_accuracy: 0.9727\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0292 - accuracy: 0.9727 - val_loss: 0.0211 - val_accuracy: 0.9707\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0281 - accuracy: 0.9688 - val_loss: 0.0228 - val_accuracy: 0.9766\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0282 - accuracy: 0.9746 - val_loss: 0.0224 - val_accuracy: 0.9785\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0312 - accuracy: 0.9707 - val_loss: 0.0214 - val_accuracy: 0.9746\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.0263 - accuracy: 0.9766 - val_loss: 0.0197 - val_accuracy: 0.9785\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0250 - accuracy: 0.9785 - val_loss: 0.0194 - val_accuracy: 0.9766\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0246 - accuracy: 0.9766 - val_loss: 0.0196 - val_accuracy: 0.9766\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0257 - accuracy: 0.9785 - val_loss: 0.0191 - val_accuracy: 0.9785\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0251 - accuracy: 0.9766 - val_loss: 0.0201 - val_accuracy: 0.9805\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0266 - accuracy: 0.9746 - val_loss: 0.0198 - val_accuracy: 0.9746\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0258 - accuracy: 0.9766 - val_loss: 0.0184 - val_accuracy: 0.9785\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0246 - accuracy: 0.9785 - val_loss: 0.0189 - val_accuracy: 0.9766\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0262 - accuracy: 0.9766 - val_loss: 0.0189 - val_accuracy: 0.9805\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0248 - accuracy: 0.9766 - val_loss: 0.0183 - val_accuracy: 0.9785\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0236 - accuracy: 0.9766 - val_loss: 0.0176 - val_accuracy: 0.9805\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0225 - accuracy: 0.9805 - val_loss: 0.0176 - val_accuracy: 0.9805\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0229 - accuracy: 0.9766 - val_loss: 0.0176 - val_accuracy: 0.9805\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0232 - accuracy: 0.9785 - val_loss: 0.0187 - val_accuracy: 0.9785\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0270 - accuracy: 0.9727 - val_loss: 0.0168 - val_accuracy: 0.9805\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0221 - accuracy: 0.9785 - val_loss: 0.0168 - val_accuracy: 0.9805\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0220 - accuracy: 0.9805 - val_loss: 0.0163 - val_accuracy: 0.9805\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0208 - accuracy: 0.9785 - val_loss: 0.0173 - val_accuracy: 0.9824\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0208 - accuracy: 0.9805 - val_loss: 0.0165 - val_accuracy: 0.9824\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0221 - accuracy: 0.9785 - val_loss: 0.0156 - val_accuracy: 0.9824\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0197 - accuracy: 0.9824 - val_loss: 0.0156 - val_accuracy: 0.9824\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0200 - accuracy: 0.9805 - val_loss: 0.0153 - val_accuracy: 0.9805\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0219 - accuracy: 0.9746 - val_loss: 0.0150 - val_accuracy: 0.9824\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0212 - accuracy: 0.9805 - val_loss: 0.0150 - val_accuracy: 0.9805\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0210 - accuracy: 0.9785 - val_loss: 0.0157 - val_accuracy: 0.9863\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0194 - accuracy: 0.9824 - val_loss: 0.0151 - val_accuracy: 0.9824\n",
      "2/2 [==============================] - 2s 14ms/step\n",
      "KNN\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 132\u001b[0m\n\u001b[0;32m    117\u001b[0m knn_parameters \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(knn__base_estimator__metric \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmanhattan\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminkowski\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    118\u001b[0m                 knn__base_estimator__weights \u001b[39m=\u001b[39m  [\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    119\u001b[0m                 knn__base_estimator__n_neighbors \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m15\u001b[39m),\n\u001b[0;32m    120\u001b[0m                 knn__bootstrap \u001b[39m=\u001b[39m [\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m],\n\u001b[0;32m    121\u001b[0m                 knn__bootstrap_features \u001b[39m=\u001b[39m [\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m],\n\u001b[0;32m    122\u001b[0m                 knn__n_estimators \u001b[39m=\u001b[39m [\u001b[39m5\u001b[39m])\n\u001b[0;32m    125\u001b[0m knn_cv \u001b[39m=\u001b[39m GridSearchCV(knn_pipeline,\n\u001b[0;32m    126\u001b[0m                 param_grid \u001b[39m=\u001b[39m knn_parameters,\n\u001b[0;32m    127\u001b[0m                 cv \u001b[39m=\u001b[39m epochs,\n\u001b[0;32m    128\u001b[0m                 scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    129\u001b[0m                 n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    130\u001b[0m                 )\n\u001b[1;32m--> 132\u001b[0m knn_cv\u001b[39m.\u001b[39;49mfit(inputs[train], targets[train])\n\u001b[0;32m    133\u001b[0m knn_targets_pred \u001b[39m=\u001b[39m knn_cv\u001b[39m.\u001b[39mpredict(inputs[test])\n\u001b[0;32m    134\u001b[0m knn_accuracy\u001b[39m=\u001b[39maccuracy_score(targets[test],knn_targets_pred)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_folds=10\n",
    "epochs = 60\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    print(\"Fold No:  \",fold_no)\n",
    "    print(\"CNN\")\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=32,kernel_size=2,activation='relu',input_shape=(30,1)))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(Dropout(0.2))\n",
    "\n",
    "    cnn_model.add(Conv1D(filters=64,kernel_size=2,activation='relu'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(Dropout(0.3))\n",
    "\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(64,activation='relu'))\n",
    "    cnn_model.add(Dropout(0.4))\n",
    "\n",
    "    cnn_model.add(Dense(1,activation='sigmoid'))\n",
    "    cnn_model.compile(optimizer=Adam(learning_rate=0.00005),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    cnn_history = cnn_model.fit(inputs[train], targets[train],epochs=epochs,validation_data=(inputs[train], targets[train]),verbose=1)\n",
    "    cnn_targets_pred = (cnn_model.predict(inputs[test]) > 0.5).astype(\"int32\")\n",
    "    cnn_accuracy=accuracy_score(targets[test],cnn_targets_pred)\n",
    "    cnn_precision = precision_score(targets[test],cnn_targets_pred)\n",
    "    cnn_recall = recall_score(targets[test],cnn_targets_pred)\n",
    "    cnn_f1=f1_score(targets[test],cnn_targets_pred)\n",
    "    cnn_accuracy1.append(cnn_accuracy)\n",
    "    cnn_precision1.append(cnn_precision)\n",
    "    cnn_recall1.append(cnn_recall)\n",
    "    cnn_f11.append(cnn_f1)\n",
    "\n",
    "\n",
    "    print(\"RNN\")\n",
    "    rnn_model = Sequential()\n",
    "\n",
    "    rnn_model.add(Dense(128, input_shape = (None,398,30)))\n",
    "    rnn_model.add(ReLU())\n",
    "    rnn_model.add(Dropout(0.1))\n",
    "\n",
    "    rnn_model.add(Dense(64))\n",
    "    rnn_model.add(ReLU())\n",
    "    rnn_model.add(Dropout(0.1))\n",
    "\n",
    "    rnn_model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    rnn_model.compile(loss = \"binary_crossentropy\",\n",
    "                optimizer = \"adam\",\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "    rnn_history = rnn_model.fit(inputs[train], targets[train],epochs = epochs, batch_size = 5,validation_data = (inputs[train], targets[train]))\n",
    "    rnn_targets_pred = (rnn_model.predict(inputs[test]) > 0.5).astype(\"int32\")\n",
    "    rnn_accuracy=accuracy_score(targets[test],rnn_targets_pred)\n",
    "    rnn_precision = precision_score(targets[test],rnn_targets_pred)\n",
    "    rnn_recall = recall_score(targets[test],rnn_targets_pred)\n",
    "    rnn_f1=f1_score(targets[test],rnn_targets_pred)\n",
    "    rnn_accuracy1.append(rnn_accuracy)\n",
    "    rnn_precision1.append(rnn_precision)\n",
    "    rnn_recall1.append(rnn_recall)\n",
    "    rnn_f11.append(rnn_f1)\n",
    "\n",
    "    print(\"LSTM\")\n",
    "\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(inputs[train].shape[1],1)))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "    lstm_model.add(Dense(units=1))\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    lstm_model.fit(inputs[train], targets[train], epochs=epochs, batch_size=32,verbose = 1,validation_data=(inputs[train], targets[train]))\n",
    "    lstm_targets_pred = (lstm_model.predict(inputs[test]) > 0.5).astype(\"int32\")\n",
    "    lstm_accuracy=accuracy_score(targets[test],lstm_targets_pred)\n",
    "    lstm_precision = precision_score(targets[test],lstm_targets_pred)\n",
    "    lstm_recall = recall_score(targets[test],lstm_targets_pred)\n",
    "    lstm_f1=f1_score(targets[test],lstm_targets_pred)\n",
    "    lstm_accuracy1.append(lstm_accuracy)\n",
    "    lstm_precision1.append(lstm_precision)\n",
    "    lstm_recall1.append(lstm_recall)\n",
    "    lstm_f11.append(lstm_f1)\n",
    "\n",
    "    print(\"GRU\")\n",
    "\n",
    "    gru_model = Sequential()\n",
    "    gru_model.add(GRU(units=50, return_sequences=True, input_shape=(inputs[train].shape[1],1)))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "    gru_model.add(GRU(units=50, return_sequences=True))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "    gru_model.add(GRU(units=50, return_sequences=True))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "    gru_model.add(GRU(units=50))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "    gru_model.add(Dense(units=1))\n",
    "    gru_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    gru_model.fit(inputs[train], targets[train], epochs=epochs, batch_size=32,verbose = 1,validation_data=(inputs[train], targets[train]))\n",
    "    gru_targets_pred = (gru_model.predict(inputs[test]) > 0.5).astype(\"int32\")\n",
    "    gru_accuracy=accuracy_score(targets[test],gru_targets_pred)\n",
    "    gru_precision = precision_score(targets[test],gru_targets_pred)\n",
    "    gru_recall = recall_score(targets[test],gru_targets_pred)\n",
    "    gru_f1=f1_score(targets[test],gru_targets_pred)\n",
    "    gru_accuracy1.append(gru_accuracy)\n",
    "    gru_precision1.append(gru_precision)\n",
    "    gru_recall1.append(gru_recall)\n",
    "    gru_f11.append(gru_f1)\n",
    "\n",
    "    print(\"KNN\")\n",
    "\n",
    "    knn_steps = [('scaler', StandardScaler()),\n",
    "         ('knn', BaggingClassifier(KNeighborsClassifier()))]\n",
    "    knn_pipeline = Pipeline(knn_steps)\n",
    "\n",
    "    knn_parameters = dict(knn__base_estimator__metric = ['euclidean', 'manhattan', 'minkowski'],\n",
    "                    knn__base_estimator__weights =  ['uniform', 'distance'],\n",
    "                    knn__base_estimator__n_neighbors = range(2,15),\n",
    "                    knn__bootstrap = [True, False],\n",
    "                    knn__bootstrap_features = [True, False],\n",
    "                    knn__n_estimators = [5])\n",
    "\n",
    "\n",
    "    knn_cv = GridSearchCV(knn_pipeline,\n",
    "                    param_grid = knn_parameters,\n",
    "                    cv = epochs,\n",
    "                    scoring = 'accuracy',\n",
    "                    n_jobs = -1,\n",
    "                    )\n",
    "\n",
    "    knn_cv.fit(inputs[train], targets[train])\n",
    "    knn_targets_pred = knn_cv.predict(inputs[test])\n",
    "    knn_accuracy=accuracy_score(targets[test],knn_targets_pred)\n",
    "    knn_precision = precision_score(targets[test],knn_targets_pred)\n",
    "    knn_recall = recall_score(targets[test],knn_targets_pred)\n",
    "    knn_f1=f1_score(targets[test],knn_targets_pred)\n",
    "    knn_accuracy1.append(knn_accuracy)\n",
    "    knn_precision1.append(knn_precision)\n",
    "    knn_recall1.append(knn_recall)\n",
    "    knn_f11.append(knn_f1)\n",
    "\n",
    "    print(\"SVC\")\n",
    "\n",
    "    svc_steps = [('scaler', StandardScaler()),\n",
    "         ('svc', SVC())]\n",
    "    svc_pipeline = Pipeline(svc_steps)\n",
    "\n",
    "    svc_parameters = dict(svc__kernel = ['poly', 'rbf', 'sigmoid'],\n",
    "                      svc__gamma =  [0.0001, 0.001, 0.01, 0.1],\n",
    "                      svc__C = [0.01, 0.05, 0.5, 0.1, 1, 10, 15, 20])\n",
    "\n",
    "\n",
    "    svc_cv = GridSearchCV(svc_pipeline,\n",
    "                      param_grid = svc_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1)\n",
    "\n",
    "    svc_cv.fit(inputs[train], targets[train])\n",
    "    svc_targets_pred = svc_cv.predict(inputs[test])\n",
    "    svc_accuracy=accuracy_score(targets[test],svc_targets_pred)\n",
    "    svc_precision = precision_score(targets[test],svc_targets_pred)\n",
    "    svc_recall = recall_score(targets[test],svc_targets_pred)\n",
    "    svc_f1=f1_score(targets[test],svc_targets_pred)\n",
    "    svc_accuracy1.append(svc_accuracy)\n",
    "    svc_precision1.append(svc_precision)\n",
    "    svc_recall1.append(svc_recall)\n",
    "    svc_f11.append(svc_f1)\n",
    "\n",
    "    print(\"Random Forest\")\n",
    "    \n",
    "\n",
    "    rf_steps = [('scaler', StandardScaler()),\n",
    "         ('rf', RandomForestClassifier(random_state = 0))]\n",
    "    rf_pipeline = Pipeline(rf_steps)\n",
    "\n",
    "    rf_parameters = dict(rf__n_estimators = [10,100],\n",
    "                      rf__max_features = ['sqrt', 'log2'],\n",
    "    )\n",
    "\n",
    "\n",
    "    rf_cv = GridSearchCV(rf_pipeline,\n",
    "                      param_grid = rf_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1)\n",
    "\n",
    "    rf_cv.fit(inputs[train], targets[train])\n",
    "    rf_targets_pred = rf_cv.predict(inputs[test])\n",
    "    rf_accuracy=accuracy_score(targets[test],rf_targets_pred)\n",
    "    rf_precision = precision_score(targets[test],rf_targets_pred)\n",
    "    rf_recall = recall_score(targets[test],rf_targets_pred)\n",
    "    rf_f1=f1_score(targets[test],rf_targets_pred)\n",
    "    rf_accuracy1.append(rf_accuracy)\n",
    "    rf_precision1.append(rf_precision)\n",
    "    rf_recall1.append(rf_recall)\n",
    "    rf_f11.append(rf_f1)\n",
    "\n",
    "    ##Start from here \n",
    "\n",
    "    print(\"Ridge Classifier\")\n",
    "\n",
    "    ridge_steps = [('scaler', StandardScaler()),\n",
    "         ('ridge', RidgeClassifier())]\n",
    "    ridge_pipeline = Pipeline(ridge_steps)\n",
    "\n",
    "    ridge_parameters = dict(ridge__alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "\n",
    "    ridge_cv = GridSearchCV(ridge_pipeline,\n",
    "                      param_grid = ridge_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0)\n",
    "\n",
    "    ridge_cv.fit(inputs[train], targets[train])\n",
    "    ridge_targets_pred = ridge_cv.predict(inputs[test])\n",
    "    ridge_accuracy=accuracy_score(targets[test],ridge_targets_pred)\n",
    "    ridge_precision = precision_score(targets[test],ridge_targets_pred)\n",
    "    ridge_recall = recall_score(targets[test],ridge_targets_pred)\n",
    "    ridge_f1=f1_score(targets[test],ridge_targets_pred)\n",
    "    ridge_accuracy1.append(ridge_accuracy)\n",
    "    ridge_precision1.append(ridge_precision)\n",
    "    ridge_recall1.append(ridge_recall)\n",
    "    ridge_f11.append(ridge_f1)\n",
    "\n",
    "    print(\"Gradient Boosting\")\n",
    "\n",
    "    gbc_steps = [('scaler', StandardScaler()),\n",
    "         ('gbc', GradientBoostingClassifier())]\n",
    "    gbc_pipeline = Pipeline(gbc_steps)\n",
    "\n",
    "    gbc_parameters = dict(gbc__n_estimators = [10,100,200],\n",
    "                      gbc__loss = ['deviance', 'exponential'],\n",
    "                      gbc__learning_rate = [0.001, 0.1, 1, 10]\n",
    "    )\n",
    "\n",
    "\n",
    "    gbc_cv = GridSearchCV(gbc_pipeline,\n",
    "                      param_grid = gbc_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0\n",
    "                      )\n",
    "\n",
    "    gbc_cv.fit(inputs[train], targets[train])\n",
    "    gbc_targets_pred = gbc_cv.predict(inputs[test])\n",
    "    gbc_accuracy=accuracy_score(targets[test],gbc_targets_pred)\n",
    "    gbc_precision = precision_score(targets[test],gbc_targets_pred)\n",
    "    gbc_recall = recall_score(targets[test],gbc_targets_pred)\n",
    "    gbc_f1=f1_score(targets[test],gbc_targets_pred)\n",
    "    gbc_accuracy1.append(gbc_accuracy)\n",
    "    gbc_precision1.append(gbc_precision)\n",
    "    gbc_recall1.append(gbc_recall)\n",
    "    gbc_f11.append(gbc_f1)\n",
    "\n",
    "    print(\"XGBoost\")\n",
    "\n",
    "    xgb = XGBClassifier(max_depth = 5,\n",
    "                        min_child_weight = 1,\n",
    "                        gamma = 0.3,\n",
    "                        subsample = 0.8,\n",
    "                        colsample_bytree = 0.8,\n",
    "                        learning_rate = 0.1,\n",
    "                        reg_alpha=0.05,\n",
    "                        disable_default_eval_metric = True)\n",
    "\n",
    "    xgb.fit(inputs[train], targets[train])\n",
    "    xgb_targets_pred = xgb.predict(inputs[test])\n",
    "\n",
    "    xgb_accuracy=accuracy_score(targets[test],xgb_targets_pred)\n",
    "    xgb_precision = precision_score(targets[test],xgb_targets_pred)\n",
    "    xgb_recall = recall_score(targets[test],xgb_targets_pred)\n",
    "    xgb_f1=f1_score(targets[test],xgb_targets_pred)\n",
    "    xgb_accuracy1.append(xgb_accuracy)\n",
    "    xgb_precision1.append(xgb_precision)\n",
    "    xgb_recall1.append(xgb_recall)\n",
    "    xgb_f11.append(xgb_f1)\n",
    "\n",
    "    print(\"Logistic Regression\")\n",
    "\n",
    "    lr_steps = [('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression())]\n",
    "\n",
    "    lr_pipeline = Pipeline(lr_steps)\n",
    "\n",
    "    lr_parameters = dict(lr__C = np.logspace(-3,3,7),                  \n",
    "                      lr__penalty = [\"l1\",\"l2\"])\n",
    "    lr_cv = GridSearchCV(lr_pipeline,\n",
    "                      param_grid = lr_parameters,\n",
    "                      cv = epochs,\n",
    "                      scoring = 'accuracy',\n",
    "                      n_jobs = -1,\n",
    "                      error_score = 0.0\n",
    "                      )\n",
    "    lr_cv.fit(inputs[train], targets[train])\n",
    "    lr_targets_pred = lr_cv.predict(inputs[test])\n",
    "\n",
    "    lr_accuracy=accuracy_score(targets[test],lr_targets_pred)\n",
    "    lr_precision = precision_score(targets[test],lr_targets_pred)\n",
    "    lr_recall = recall_score(targets[test],lr_targets_pred)\n",
    "    lr_f1=f1_score(targets[test],lr_targets_pred)\n",
    "    lr_accuracy1.append(lr_accuracy)\n",
    "    lr_precision1.append(lr_precision)\n",
    "    lr_recall1.append(lr_recall)\n",
    "    lr_f11.append(lr_f1)\n",
    "\n",
    "    print(\"Decision Tree\")\n",
    "\n",
    "    dt = DecisionTreeClassifier()\n",
    "\n",
    "    dt.fit(inputs[train], targets[train],sample_weight=None)\n",
    "    dt_targets_pred = dt.predict(inputs[test])\n",
    "\n",
    "    dt_accuracy=accuracy_score(targets[test],dt_targets_pred)\n",
    "    dt_precision = precision_score(targets[test],dt_targets_pred)\n",
    "    dt_recall = recall_score(targets[test],dt_targets_pred)\n",
    "    dt_f1=f1_score(targets[test],dt_targets_pred)\n",
    "    dt_accuracy1.append(dt_accuracy)\n",
    "    dt_precision1.append(dt_precision)\n",
    "    dt_recall1.append(dt_recall)\n",
    "    dt_f11.append(dt_f1)\n",
    "\n",
    "    print(\"Linear Discremental Analysis\")\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    lda.fit(inputs[train], targets[train])\n",
    "    lda_targets_pred = lda.predict(inputs[test])\n",
    "\n",
    "    lda_accuracy=accuracy_score(targets[test],lda_targets_pred)\n",
    "    lda_precision = precision_score(targets[test],lda_targets_pred)\n",
    "    lda_recall = recall_score(targets[test],lda_targets_pred)\n",
    "    lda_f1=f1_score(targets[test],lda_targets_pred)\n",
    "    lda_accuracy1.append(lda_accuracy)\n",
    "    lda_precision1.append(lda_precision)\n",
    "    lda_recall1.append(lda_recall)\n",
    "    lda_f11.append(lda_f1)\n",
    "\n",
    "    print(\"Quadratic Discremental Analysis\")\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "    qda.fit(inputs[train], targets[train])\n",
    "    qda_targets_pred = qda.predict(inputs[test])\n",
    "\n",
    "    qda_accuracy=accuracy_score(targets[test],qda_targets_pred)\n",
    "    qda_precision = precision_score(targets[test],qda_targets_pred)\n",
    "    qda_recall = recall_score(targets[test],qda_targets_pred)\n",
    "    qda_f1=f1_score(targets[test],qda_targets_pred)\n",
    "    qda_accuracy1.append(qda_accuracy)\n",
    "    qda_precision1.append(qda_precision)\n",
    "    qda_recall1.append(qda_recall)\n",
    "    qda_f11.append(qda_f1)\n",
    "\n",
    "    print(\"Naive Bayes\")\n",
    "\n",
    "    nb= GaussianNB()\n",
    "\n",
    "    nb.fit(inputs[train], targets[train])\n",
    "    nb_targets_pred = nb.predict(inputs[test])\n",
    "\n",
    "    nb_accuracy=accuracy_score(targets[test],nb_targets_pred)\n",
    "    nb_precision = precision_score(targets[test],nb_targets_pred)\n",
    "    nb_recall = recall_score(targets[test],nb_targets_pred)\n",
    "    nb_f1=f1_score(targets[test],nb_targets_pred)\n",
    "    nb_accuracy1.append(nb_accuracy)\n",
    "    nb_precision1.append(nb_precision)\n",
    "    nb_recall1.append(nb_recall)\n",
    "    nb_f11.append(nb_f1)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCnnAccuracy =  mean(cnn_accuracy1)\n",
    "avgCnnPrecision=mean(cnn_precision1)\n",
    "avgCnnRecall=mean(cnn_recall1)\n",
    "avgCnnF1=mean(cnn_f11)\n",
    "avgRnnAccuracy = mean(rnn_accuracy1)\n",
    "avgRnnPrecision = mean(rnn_precision1)\n",
    "avgRnnRecall = mean(rnn_recall1)\n",
    "avgRnnF1 = mean(rnn_f11)\n",
    "avgLstmAccuracy = mean(lstm_accuracy1)\n",
    "avgLstmPrecision = mean(lstm_precision1)\n",
    "avgLstmRecall = mean(lstm_recall1)\n",
    "avgLstmF1 = mean(lstm_f11)\n",
    "avgGruAccuracy = mean(gru_accuracy1)\n",
    "avgGruPrecision = mean(gru_precision1)\n",
    "avgGruRecall = mean(gru_recall1)\n",
    "avgGruF1 = mean(gru_f11)\n",
    "avgKnnAccuracy = mean(knn_accuracy1)\n",
    "avgKnnPrecision = mean(knn_precision1)\n",
    "avgKnnRecall = mean(knn_recall1)\n",
    "avgKnnF1 = mean(knn_f11)\n",
    "avgSvcAccuracy = mean(svc_accuracy1)\n",
    "avgSvcPrecision = mean(svc_precision1)\n",
    "avgSvcRecall = mean(svc_recall1)\n",
    "avgSvcF1 = mean(svc_f11)\n",
    "avgRfAccuracy = mean(rf_accuracy1)\n",
    "avgRfPrecision = mean(rf_precision1)\n",
    "avgRfRecall = mean(rf_recall1)\n",
    "avgRfF1 = mean(rf_f11)\n",
    "avgRidgeAccuracy = mean(ridge_accuracy1)\n",
    "avgRidgePrecision = mean(ridge_precision1)\n",
    "avgRidgeRecall = mean(ridge_recall1)\n",
    "avgRidgeF1 = mean(ridge_f11)\n",
    "avgGbcAccuracy = mean(gbc_accuracy1)\n",
    "avgGbcPrecision = mean(gbc_precision1)\n",
    "avgGbcRecall = mean(gbc_recall1)\n",
    "avgGbcF1 = mean(gbc_f11)\n",
    "avgXgbAccuracy = mean(xgb_accuracy1)\n",
    "avgXgbPrecision = mean(xgb_precision1)\n",
    "avgXgbRecall = mean(xgb_recall1)\n",
    "avgXgbF1 = mean(xgb_f11)\n",
    "avgLrAccuracy = mean(lr_accuracy1)\n",
    "avgLrPrecision = mean(lr_precision1)\n",
    "avgLrRecall = mean(lr_recall1)\n",
    "avgLrF1 = mean(lr_f11)\n",
    "avgDtAccuracy = mean(dt_accuracy1)\n",
    "avgDtPrecision = mean(dt_precision1)\n",
    "avgDtRecall = mean(dt_recall1)\n",
    "avgDtF1 = mean(dt_f11)\n",
    "avgLdaAccuracy = mean(lda_accuracy1)\n",
    "avgLdaPrecision = mean(lda_precision1)\n",
    "avgLdaRecall = mean(lda_recall1)\n",
    "avgLdaF1 = mean(lda_f11)\n",
    "avgQdaAccuracy = mean(qda_accuracy1)\n",
    "avgQdaPrecision = mean(qda_precision1)\n",
    "avgQdaRecall = mean(qda_recall1)\n",
    "avgQdaF1 = mean(qda_f11)\n",
    "avgNbAccuracy = mean(nb_accuracy1)\n",
    "avgNbPrecision = mean(nb_precision1)\n",
    "avgNbRecall = mean(nb_recall1)\n",
    "avgNbF1 = mean(nb_f11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avgCnnAccuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\2018-1-60-048@std.ewubd.edu\\CSE 497\\ThesisKfoldCombined.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=0'>1</a>\u001b[0m models_ensembling \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m       : [\u001b[39m'\u001b[39m\u001b[39mCNN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRNN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mGRU\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLSTM\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mKNN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSupport Vector Classifier\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRandom Forest\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRidge Classifier\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mGradient Boosting Classifier\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mXGBoost\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLogistic Regression\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDecision Tree\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLiner Discriminant Analysis\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mQuadratic Discremenant Analysis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNaive Baies\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m    : [avgCnnAccuracy,avgRnnAccuracy,avgGruAccuracy,avgLstmAccuracy,avgKnnAccuracy,avgSvcAccuracy,avgRfAccuracy,avgRidgeAccuracy,avgGbcAccuracy,avgXgbAccuracy,avgLrAccuracy,avgDtAccuracy,avgLdaAccuracy,avgQdaAccuracy,avgNbAccuracy],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m   : [avgCnnPrecision,avgRnnPrecision,avgGruPrecision,avgLstmPrecision,avgKnnPrecision,avgSvcPrecision,avgRfPrecision,avgRidgePrecision,avgGbcPrecision,avgXgbPrecision,avgLrPrecision,avgDtPrecision,avgLdaPrecision,avgQdaPrecision,avgNbPrecision],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m      : [avgCnnRecall,avgRnnRecall,avgGruRecall,avgLstmRecall,avgKnnRecall,avgSvcRecall,avgRfRecall,avgRidgeRecall,avgGbcRecall,avgXgbRecall,avgLrRecall,avgDtRecall,avgLdaRecall,avgQdaRecall,avgNbRecall],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mF1_score\u001b[39m\u001b[39m'\u001b[39m    : [avgCnnF1,avgRnnF1,avgGruF1,avgLstmF1,avgKnnF1,avgSvcF1,avgRfF1,avgRidgeF1,avgGbcF1,avgXgbF1,avgLrF1,avgDtF1,avgLdaF1,avgQdaF1,avgNbF1],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=6'>7</a>\u001b[0m     }, columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF1_score\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/2018-1-60-048%40std.ewubd.edu/CSE%20497/ThesisKfoldCombined.ipynb#ch0000003?line=8'>9</a>\u001b[0m models_ensembling\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'avgCnnAccuracy' is not defined"
     ]
    }
   ],
   "source": [
    "models_ensembling = pd.DataFrame({\n",
    "    'Model'       : ['CNN','RNN','GRU','LSTM','KNN','Support Vector Classifier','Random Forest','Ridge Classifier','Gradient Boosting Classifier','XGBoost','Logistic Regression','Decision Tree','Liner Discriminant Analysis','Quadratic Discremenant Analysis', 'Naive Baies'],\n",
    "    'Accuracy'    : [avgCnnAccuracy,avgRnnAccuracy,avgGruAccuracy,avgLstmAccuracy,avgKnnAccuracy,avgSvcAccuracy,avgRfAccuracy,avgRidgeAccuracy,avgGbcAccuracy,avgXgbAccuracy,avgLrAccuracy,avgDtAccuracy,avgLdaAccuracy,avgQdaAccuracy,avgNbAccuracy],\n",
    "    'Precision'   : [avgCnnPrecision,avgRnnPrecision,avgGruPrecision,avgLstmPrecision,avgKnnPrecision,avgSvcPrecision,avgRfPrecision,avgRidgePrecision,avgGbcPrecision,avgXgbPrecision,avgLrPrecision,avgDtPrecision,avgLdaPrecision,avgQdaPrecision,avgNbPrecision],\n",
    "    'Recall'      : [avgCnnRecall,avgRnnRecall,avgGruRecall,avgLstmRecall,avgKnnRecall,avgSvcRecall,avgRfRecall,avgRidgeRecall,avgGbcRecall,avgXgbRecall,avgLrRecall,avgDtRecall,avgLdaRecall,avgQdaRecall,avgNbRecall],\n",
    "    'F1_score'    : [avgCnnF1,avgRnnF1,avgGruF1,avgLstmF1,avgKnnF1,avgSvcF1,avgRfF1,avgRidgeF1,avgGbcF1,avgXgbF1,avgLrF1,avgDtF1,avgLdaF1,avgQdaF1,avgNbF1],\n",
    "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "models_ensembling.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "         DecisionTreeClassifier(),\n",
    "         SVC(probability = True),\n",
    "         LinearDiscriminantAnalysis(),\n",
    "         QuadraticDiscriminantAnalysis(),\n",
    "         RandomForestClassifier(),\n",
    "         KNeighborsClassifier(),XGBClassifier(),\n",
    "         GaussianNB(),GradientBoostingClassifier(),\n",
    "         ]\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    scores = cross_validate(model, inputs[train], targets[train], scoring=scoring, cv=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ens = list(zip(['lr', 'dt','gbc', 'svc', 'lda', 'qda', 'rf', 'knn', 'nb','xgb'], models))\n",
    "\n",
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'hard')\n",
    "model_ens.fit(inputs[train], targets[train])\n",
    "pred = model_ens.predict(inputs[test])\n",
    "\n",
    "acc_hard = accuracy_score(targets[test], pred)\n",
    "prec_hard = precision_score(targets[test], pred)\n",
    "recall_hard = recall_score(targets[test], pred)\n",
    "f1_hard = f1_score(targets[test], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'soft')\n",
    "model_ens.fit(inputs[train], targets[train])\n",
    "pred = model_ens.predict(inputs[test])\n",
    "prob = model_ens.predict_proba(inputs[test])[:,1]\n",
    "\n",
    "acc_soft = accuracy_score(targets[test], pred)\n",
    "prec_soft = precision_score(targets[test], pred)\n",
    "recall_soft = recall_score(targets[test], pred)\n",
    "f1_soft = f1_score(targets[test], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensebling_hard</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensembling_soft</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy  Precision  Recall  F1_score\n",
       "0   Ensebling_hard  0.982143   0.933333     1.0  0.965517\n",
       "1  Ensembling_soft  0.982143   0.933333     1.0  0.965517"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ensembling = pd.DataFrame({\n",
    "    'Model'       : ['Ensebling_hard', 'Ensembling_soft'],\n",
    "    'Accuracy'    : [acc_hard, acc_soft],\n",
    "    'Precision'   : [prec_hard, prec_soft],\n",
    "    'Recall'      : [recall_hard, recall_soft],\n",
    "    'F1_score'    : [f1_hard, f1_soft],\n",
    "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "models_ensembling.sort_values(by='Accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
